"""
Chatbot AI Service - Simplificado
================================

Servicio de IA que se enfoca √∫nicamente en procesamiento de IA.
Recibe configuraci√≥n del proyecto Political Referrals via HTTP.
"""

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
import os
import httpx
from dotenv import load_dotenv
import logging

from chatbot_ai_service.controllers.chat_controller import router as chat_router
from chatbot_ai_service.controllers.city_normalization_controller import router as city_router
from chatbot_ai_service.controllers.preprocessing_controller import router as preprocessing_router

# Cargar variables de entorno
# Buscar .env en el directorio ra√≠z del proyecto (3 niveles arriba)
import pathlib
project_root = pathlib.Path(__file__).parent.parent.parent.parent.parent
env_path = project_root / ".env"
print(f"üìÅ Archivo .env existe: {env_path.exists()}")
load_dotenv(env_path)

# Verificar que POLITICAL_REFERRALS_SERVICE_URL se carg√≥
political_url = os.getenv("POLITICAL_REFERRALS_SERVICE_URL")
if political_url:
    print(f"‚úÖ POLITICAL_REFERRALS_SERVICE_URL cargada: {political_url}")
else:
    print("‚ùå POLITICAL_REFERRALS_SERVICE_URL no encontrada")

# Configurar logging global para que se vean logs de controllers/servicios
log_level_str = os.getenv("LOG_LEVEL", "DEBUG").upper()
log_level = getattr(logging, log_level_str, logging.DEBUG)
logging.basicConfig(
    level=log_level,
    format="%(asctime)s [%(levelname)s] %(name)s - %(message)s"
)
logging.getLogger(__name__).info(f"Logging configurado en nivel: {log_level_str}")

# Verificar que la API key se carg√≥ correctamente
api_key = os.getenv("GEMINI_API_KEY")
if api_key:
    print(f"‚úÖ GEMINI_API_KEY cargada correctamente")
else:
    print("‚ùå GEMINI_API_KEY no encontrada")

# üöÄ DEBUG: Verificar variables de optimizaci√≥n
local_dev = os.getenv("LOCAL_DEVELOPMENT", "false").lower() == "true"
ultra_fast = os.getenv("ULTRA_FAST_MODE", "false").lower() == "true"
print(f"üöÄ DEBUG - LOCAL_DEVELOPMENT: {local_dev}")
print(f"üöÄ DEBUG - ULTRA_FAST_MODE: {ultra_fast}")

# üöÄ OPTIMIZACI√ìN: Pre-cargar modelos de IA despu√©s de cargar variables de entorno
try:
    print("üöÄ Iniciando pre-carga de modelos de IA...")
    from chatbot_ai_service.services.ai_service import ai_service
    ai_service.preload_models_on_startup()
    print("‚úÖ Pre-carga de modelos completada")
except Exception as e:
    print(f"‚ùå Error durante pre-carga: {e}")
    # No fallar el startup si hay error en la pre-carga

# üöÄ PRECARGA AUTOM√ÅTICA DE DOCUMENTOS
async def preload_documents_on_startup_optimized():
    """Precargar documentos autom√°ticamente al inicio del servicio usando el servicio optimizado"""
    try:
        print("üöÄ Iniciando precarga optimizada de documentos...")
        
        # Importar servicios optimizados
        from chatbot_ai_service.services.document_preprocessor_service import document_preprocessor_service
        from chatbot_ai_service.services.tenant_memory_service import tenant_memory_service
        
        # üóÑÔ∏è NUEVO: Solo inicializar memoria si no est√° ya cargada desde Firestore
        if len(tenant_memory_service._tenant_memories) > 0:
            print(f"‚úÖ {len(tenant_memory_service._tenant_memories)} memorias ya cargadas desde Firestore - saltando inicializaci√≥n")
            return
        
        # Obtener configuraci√≥n de tenants desde Firestore
        response_data = await get_tenant_configs_from_firestore()
        
        if not response_data or not isinstance(response_data, dict):
            print("‚ö†Ô∏è No se pudieron obtener configuraciones de tenants desde Firestore")
            return
        
        # Extraer la lista de tenants de la respuesta
        tenant_configs = response_data.get("tenants", {})
        
        if not tenant_configs:
            print("‚ö†Ô∏è No se encontraron configuraciones de tenants en la respuesta")
            return
        
        print(f"üìä Encontrados {len(tenant_configs)} tenants para precargar")
        
        # Inicializar memoria para cada tenant (r√°pido)
        for tenant_id, tenant_config in tenant_configs.items():
            print(f"üß† Inicializando memoria para tenant {tenant_id}...")
            memory_success = tenant_memory_service.initialize_tenant_memory(
                tenant_id=tenant_id,
                tenant_config=tenant_config,
                document_summary=""  # Se llenar√° despu√©s si hay documentos
            )
            
            if memory_success:
                print(f"‚úÖ Memoria inicializada para tenant {tenant_id}")
            else:
                print(f"‚ö†Ô∏è No se pudo inicializar memoria para tenant {tenant_id}")
        
        # Hacer preprocesamiento S√çNCRONO usando asyncio.run() en un hilo separado
        print("üöÄ Iniciando preprocesamiento S√çNCRONO...")
        import asyncio
        import threading
        
        def run_sync_preprocessing():
            async def synchronous_preprocessing():
                try:
                    print("üìö [SYNC] Iniciando preprocesamiento de documentos...")
                    results = await document_preprocessor_service.preprocess_all_tenants()
                    
                    successful_tenants = sum(1 for success in results.values() if success)
                    print(f"‚úÖ [SYNC] Preprocesamiento completado: {successful_tenants}/{len(results)} tenants exitosos")
                    
                    # Mostrar estad√≠sticas de memoria
                    memory_stats = tenant_memory_service.get_memory_stats()
                    print(f"üß† [SYNC] Estad√≠sticas de memoria:")
                    print(f"  - Memorias de tenants: {memory_stats['tenant_memories']}")
                    print(f"  - Conciencias de usuarios: {memory_stats['user_consciousness']}")
                    
                    print("üéâ [SYNC] ¬°Preprocesamiento completado! El servicio est√° completamente optimizado.")
                    return True
                    
                except Exception as e:
                    print(f"‚ùå [SYNC] Error en preprocesamiento: {e}")
                    return False
            
            # Ejecutar en un nuevo event loop
            return asyncio.run(synchronous_preprocessing())
        
        # Ejecutar preprocesamiento en un hilo separado para evitar conflictos con el event loop principal
        preprocessing_thread = threading.Thread(target=run_sync_preprocessing)
        preprocessing_thread.start()
        preprocessing_thread.join()  # Esperar a que termine
        
        print("‚úÖ Servicio completamente listo - todos los documentos preprocesados")
    except Exception as e:
        print(f"‚ùå Error durante precarga optimizada de documentos: {e}")
        # No fallar el startup si hay error en la precarga

async def get_tenant_configs_from_firestore():
    """Obtener configuraci√≥n de todos los tenants directamente desde Firestore"""
    try:
        from chatbot_ai_service.services.firestore_tenant_service import firestore_tenant_service
        
        print("üîç Obteniendo configuraciones de tenants desde Firestore...")
        tenant_configs = await firestore_tenant_service.get_all_tenant_configs()
        
        if tenant_configs:
            print(f"‚úÖ Configuraciones obtenidas desde Firestore: {len(tenant_configs)} tenants")
            return {
                "status": "success",
                "tenants": tenant_configs,
                "total_tenants": len(tenant_configs)
            }
        else:
            print("‚ö†Ô∏è No se encontraron configuraciones de tenants en Firestore")
            return {
                "status": "success",
                "tenants": {},
                "total_tenants": 0
            }
            
    except Exception as e:
        print(f"‚ùå Error obteniendo configuraci√≥n de tenants desde Firestore: {e}")
        return {
            "status": "error",
            "tenants": {},
            "total_tenants": 0,
            "error": str(e)
        }

# Configuraci√≥n de la aplicaci√≥n
app = FastAPI(
    title="Chatbot AI Service",
    description="Servicio de IA para chatbots pol√≠ticos - Solo procesamiento de IA",
    version="1.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    openapi_url="/openapi.json",
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Incluir routers
app.include_router(chat_router)
app.include_router(city_router)
app.include_router(preprocessing_router)

# Importar y agregar el nuevo controlador de clasificaci√≥n de intenciones
from chatbot_ai_service.controllers.intent_classification_controller import router as intent_classification_router
app.include_router(intent_classification_router)

# üß† FUNCI√ìN: Generar variaciones con IA si es necesario
async def _generate_ai_welcome_variations_if_needed(tenant_id: str, tenant_memory):
    """Genera variaciones de saludo con IA si no existen o son pocas"""
    try:
        from chatbot_ai_service.services.optimized_ai_service import OptimizedAIService
        from chatbot_ai_service.services.document_index_persistence_service import document_index_persistence_service
        from chatbot_ai_service.services.ai_service import ai_service
        
        # Verificar cu√°ntas variaciones hay (cache por tenant)
        cache_key = f'{tenant_id}_welcome_variations'
        existing_variations = OptimizedAIService._prompts_cache.get(cache_key, [])
        num_existing = len(existing_variations) if existing_variations else 0
        
        # Si ya hay suficientes variaciones (3+), no generar
        if num_existing >= 3:
            return
        
        print(f"      ‚Ä¢ üß† Generando {3 - num_existing} variaciones nuevas con IA...")
        
        # Obtener contexto del tenant para generar variaciones relevantes
        campaign_context = tenant_memory.campaign_context if tenant_memory and hasattr(tenant_memory, 'campaign_context') else ""
        common_questions = tenant_memory.common_questions[:3] if tenant_memory and hasattr(tenant_memory, 'common_questions') and tenant_memory.common_questions else []
        
        # Obtener configuraci√≥n del tenant
        from chatbot_ai_service.services.firestore_tenant_service import firestore_tenant_service
        tenant_config = await firestore_tenant_service.get_tenant_config(tenant_id)
        contact_name = "el candidato"
        if tenant_config and tenant_config.get('branding'):
            contact_name = tenant_config['branding'].get('contactName', 'el candidato')
        
        # Crear prompt ULTRA CORTO para generaci√≥n r√°pida
        generation_prompt = f"""Genera 3 saludos para campa√±a pol√≠tica, m√°ximo 100 caracteres cada uno. Separar con "---".

1:
2:
3:"""
        
        # Generar con IA con TIMEOUT CORTO (3 segundos m√°ximo)
        try:
            import asyncio
            generated_text = await asyncio.wait_for(
                ai_service._generate_content_optimized(generation_prompt),
                timeout=3.0
            )
        except asyncio.TimeoutError:
            print(f"      ‚Ä¢ ‚ö†Ô∏è Timeout generando con IA (3s) - usando variaciones b√°sicas")
            generated_text = None
        
        if generated_text:
            # Parsear las variaciones (splitting por l√≠neas o separadores)
            variations = generated_text.split("---")
            variations = [v.strip() for v in variations if v.strip() and len(v.strip()) > 10]
            
            # Si no funcion√≥, intentar por n√∫meros
            if len(variations) < 3:
                parts = generated_text.split("\n")
                variations = [p.strip() for p in parts if p.strip() and len(p.strip()) > 10 and not p.strip().isdigit()]
            
            # Filtrar por longitud razonable
            variations = [v for v in variations if 15 <= len(v) <= 200]
            
            # Agregar a las existentes
            if num_existing > 0:
                all_variations = existing_variations + variations
            else:
                all_variations = variations
            
            # Limitar a 5 variaciones
            all_variations = all_variations[:5]
            
            # Guardar en cache por tenant
            OptimizedAIService._prompts_cache[cache_key] = all_variations
            print(f"      ‚Ä¢ ‚úÖ Generadas {len(variations)} variaciones nuevas ({len(all_variations)} total)")
            
            # Opcional: Guardar en DB para persistencia
            if tenant_memory:
                prompts = document_index_persistence_service.get_tenant_prompts(tenant_id)
                if not prompts:
                    prompts = {}
                prompts['welcome_variations'] = all_variations
                await document_index_persistence_service.save_tenant_prompts(tenant_id, prompts)
                print(f"      ‚Ä¢ üíæ Variaciones guardadas en DB para persistencia")
        else:
            print(f"      ‚Ä¢ ‚ö†Ô∏è No se pudieron generar variaciones con IA")
            
    except Exception as e:
        print(f"      ‚Ä¢ ‚ùå Error generando variaciones: {e}")

# üöÄ EVENTO DE STARTUP: Carga lazy desde DB
@app.on_event("startup")
async def startup_event():
    """Evento de startup - carga lazy desde DB"""
    # üóÑÔ∏è NUEVO: Cargar metadatos de √≠ndices desde DB
    from chatbot_ai_service.services.document_index_persistence_service import document_index_persistence_service
    
    print("üóÑÔ∏è Cargando metadatos de √≠ndices desde Firestore...")
    
    try:
        # Verificar si Firestore est√° disponible
        db = document_index_persistence_service.db
        if db is None:
            print("‚ö†Ô∏è Firestore no disponible en este momento - saltando carga de metadatos")
            print("‚ÑπÔ∏è Los √≠ndices se cargar√°n de forma lazy cuando sea necesario")
            all_indexes = []
        else:
            # Obtener todos los √≠ndices guardados
            all_indexes = []
            indexes_ref = db.collection("document_indexes").get()
            for doc in indexes_ref:
                index_data = doc.to_dict()
                if index_data:
                    all_indexes.append(index_data)
        
        if all_indexes:
            print(f"‚úÖ {len(all_indexes)} √≠ndices encontrados en DB:")
            for idx in all_indexes:
                print(f"  - Tenant {idx.get('tenant_id')}: {idx.get('documents_count', 0)} documentos")
                
                # üöÄ Carga SINCR√ìNICA al inicio con persistencia en disco
                tenant_id = idx.get('tenant_id')
                bucket_url = idx.get('bucket_url')
                if bucket_url:
                    print(f"      ‚Ä¢ ‚úÖ URL configurada: {bucket_url[:50]}...")
                    
                    # Importar servicio de documentos
                    from chatbot_ai_service.services.document_context_service import document_context_service
                    
                    try:
                        print(f"      ‚Ä¢ üìö Cargando √≠ndice (desde disco si existe, sino desde bucket)...")
                        # Este m√©todo ahora carga desde disco si existe (r√°pido ~1s)
                        # Si no existe, carga desde bucket y guarda en disco (lento ~10-30s la primera vez)
                        success = await document_context_service.load_tenant_documents(tenant_id, bucket_url)
                        if success:
                            print(f"      ‚Ä¢ ‚úÖ √çndice listo - {idx.get('documents_count', 0)} documentos disponibles")
                        else:
                            print(f"      ‚Ä¢ ‚ö†Ô∏è No se pudo cargar √≠ndice")
                    except Exception as e:
                        print(f"      ‚Ä¢ ‚ùå Error cargando: {e}")
        else:
            print("‚ÑπÔ∏è No hay √≠ndices guardados en DB a√∫n")
        
        # üß† NUEVO: Cargar memorias de tenants desde Firestore
        from chatbot_ai_service.services.tenant_memory_service import tenant_memory_service
        
        print("üß† Cargando memorias de tenants desde Firestore...")
        if db is None:
            print("‚ö†Ô∏è Firestore no disponible - saltando carga de memorias")
            tenant_ids = []
        else:
            # üîß FIX: Obtener tenant IDs desde la colecci√≥n 'tenants' (configuraciones reales)
            # en lugar de 'tenant_memory_cache' (que puede tener documentos viejos o de prueba)
            try:
                print("üîç Obteniendo tenant IDs desde colecci√≥n 'tenants' (configuraciones reales)...")
                tenants_ref = db.collection('tenants')
                tenant_docs = tenants_ref.get()
                
                # Extraer tenant_ids de las configuraciones reales
                tenant_ids = []
                for doc in tenant_docs:
                    data = doc.to_dict()
                    tenant_id = data.get('tenant_id')
                    if tenant_id:
                        tenant_ids.append(str(tenant_id))
                
                print(f"‚úÖ {len(tenant_ids)} tenants encontrados en configuraci√≥n: {tenant_ids}")
                
                # Opcional: Tambi√©n verificar si hay memorias guardadas para estos tenants
                # pero NO usar documentos que no est√©n en la lista de tenants v√°lidos
                memory_docs = db.collection('tenant_memory_cache').get()
                memory_tenant_ids = [doc.id for doc in memory_docs]
                
                # Filtrar solo los tenant IDs que est√°n en la configuraci√≥n real
                valid_memory_ids = [tid for tid in memory_tenant_ids if tid in tenant_ids]
                
                if len(valid_memory_ids) < len(memory_tenant_ids):
                    skipped = set(memory_tenant_ids) - set(tenant_ids)
                    if skipped:
                        print(f"‚ö†Ô∏è Se encontraron {len(skipped)} documentos de memoria no v√°lidos (ser√°n ignorados): {list(skipped)}")
                
                # Usar los tenant_ids de configuraci√≥n, no los de memoria
                # tenant_ids ya tiene los IDs v√°lidos
                
            except Exception as e:
                print(f"‚ö†Ô∏è Error obteniendo tenant IDs desde configuraci√≥n: {e}")
                print("‚ö†Ô∏è Usando m√©todo anterior (puede incluir documentos inv√°lidos)...")
                tenant_ids = tenant_memory_service.get_all_tenant_memories_from_firestore()
        
        if tenant_ids:
            print(f"‚úÖ {len(tenant_ids)} memorias encontradas en Firestore:")
            
            # üîß FIX: Obtener configuraciones de tenants para usar las bases de datos correctas
            tenant_configs_map = {}
            try:
                print("üîç Obteniendo configuraciones de tenants para usar bases de datos correctas...")
                from chatbot_ai_service.services.firestore_tenant_service import firestore_tenant_service
                import asyncio
                
                # Obtener todas las configuraciones
                all_configs = await firestore_tenant_service.get_all_tenant_configs()
                for tid, config in all_configs.items():
                    tenant_configs_map[str(tid)] = config
                
                print(f"‚úÖ {len(tenant_configs_map)} configuraciones obtenidas para cargar memoria")
            except Exception as e:
                print(f"‚ö†Ô∏è Error obteniendo configuraciones: {e} - se usar√° base de datos por defecto")
            
            for tenant_id in tenant_ids:
                # Intentar cargar memoria usando la configuraci√≥n del tenant si est√° disponible
                tenant_config = tenant_configs_map.get(tenant_id)
                memory_loaded = False
                
                if tenant_config:
                    client_project_id = tenant_config.get('client_project_id')
                    client_database_id = tenant_config.get('client_database_id', '(default)')
                    print(f"üîç Cargando memoria para tenant {tenant_id} desde proyecto: {client_project_id}, database: {client_database_id}")
                    
                    # Usar el nuevo servicio de memoria que soporta conexiones espec√≠ficas
                    try:
                        from chatbot_ai_service.memory import get_tenant_memory_service
                        new_memory_service = get_tenant_memory_service()
                        
                        # Cargar usando la configuraci√≥n correcta (await ya que estamos en contexto async)
                        memory = await new_memory_service.get_tenant_memory(tenant_id, tenant_config)
                        
                        if memory:
                            print(f"‚úÖ Memoria cargada para tenant {tenant_id} desde su base de datos espec√≠fica")
                            memory_loaded = True
                            # Continuar con el resto del procesamiento...
                        else:
                            print(f"‚ö†Ô∏è No se encontr√≥ memoria para tenant {tenant_id} en su base de datos espec√≠fica")
                            # Intentar con el m√©todo anterior como fallback
                            if tenant_memory_service.load_tenant_memory_from_firestore(tenant_id):
                                print(f"‚úÖ Memoria cargada para tenant {tenant_id} desde base de datos por defecto (fallback)")
                                memory_loaded = True
                            else:
                                print(f"‚ö†Ô∏è Tenant {tenant_id}: no se pudo cargar memoria ni desde su base espec√≠fica ni desde la por defecto")
                                continue
                    except Exception as e:
                        print(f"‚ö†Ô∏è Error cargando memoria con configuraci√≥n espec√≠fica para tenant {tenant_id}: {e}")
                        print(f"‚ö†Ô∏è Intentando con m√©todo anterior (base por defecto)...")
                        # Fallback al m√©todo anterior
                        if tenant_memory_service.load_tenant_memory_from_firestore(tenant_id):
                            memory_loaded = True
                else:
                    print(f"‚ö†Ô∏è No se encontr√≥ configuraci√≥n para tenant {tenant_id}, usando base de datos por defecto")
                    # Usar m√©todo anterior sin configuraci√≥n
                    if tenant_memory_service.load_tenant_memory_from_firestore(tenant_id):
                        memory_loaded = True
                
                # Si la memoria se carg√≥ exitosamente, mostrar datos
                if memory_loaded:
                    # Mostrar datos cargados para cada tenant
                    precomputed = tenant_memory_service.get_tenant_precomputed_responses(tenant_id)
                    questions = tenant_memory_service.get_tenant_common_questions(tenant_id)
                    context = tenant_memory_service.get_tenant_campaign_context(tenant_id)
                    
                    # üóÑÔ∏è NUEVO: Cargar prompts desde DB y cachearlos en OptimizedAIService
                    prompts = document_index_persistence_service.get_tenant_prompts(tenant_id)
                    
                    if prompts:
                        # Cachear en el servicio optimizado para acceso r√°pido
                        from chatbot_ai_service.services.optimized_ai_service import OptimizedAIService
                        if not hasattr(OptimizedAIService, '_prompts_cache'):
                            OptimizedAIService._prompts_cache = {}
                        OptimizedAIService._prompts_cache[tenant_id] = prompts
                        
                        # Cargar variaciones de 'welcome' si existen
                        num_existing = 0
                        if 'welcome_variations' in prompts:
                            variations = prompts['welcome_variations']
                            # Cachear por tenant
                            OptimizedAIService._prompts_cache[f'{tenant_id}_welcome_variations'] = variations
                            num_existing = len(variations)
                            print(f"      ‚Ä¢ ‚úÖ {num_existing} variaciones de saludo cargadas desde DB")
                        else:
                            print(f"      ‚Ä¢ ‚ö†Ô∏è No hay variaciones de saludo en DB - se generar√°n al primer uso")
                        
                        # üß† NUEVO: Precargar variaciones generadas por IA (si no existen o son pocas)
                        # ‚ö° Hacerlo en background para no bloquear startup
                        if num_existing < 3:
                            print(f"      ‚Ä¢ ‚ö° Generando variaciones en background (no bloquea startup)")
                            import asyncio
                            loaded_memory = tenant_memory_service._tenant_memories.get(tenant_id)
                            if loaded_memory:
                                # Crear tarea en background
                                asyncio.create_task(_generate_ai_welcome_variations_if_needed(tenant_id, loaded_memory))
                            else:
                                print(f"      ‚Ä¢ ‚ö†Ô∏è No hay memoria cargada")
                        else:
                            print(f"      ‚Ä¢ ‚úÖ Ya hay {num_existing} variaciones - no necesita generar m√°s")
                    
                    print(f"  - ‚úÖ Tenant {tenant_id}:")
                    print(f"      ‚Ä¢ {len(precomputed) if precomputed else 0} respuestas precomputadas")
                    print(f"      ‚Ä¢ {len(questions)} preguntas comunes")
                    print(f"      ‚Ä¢ Contexto: {len(context) if context else 0} caracteres")
                    print(f"      ‚Ä¢ {'‚úÖ Prompts cargados y cacheados' if prompts else '‚ö†Ô∏è No prompts'} desde DB")
                else:
                    print(f"  - ‚ö†Ô∏è Tenant {tenant_id}: no se pudo cargar")
        else:
            print("‚ÑπÔ∏è No hay memorias guardadas en Firestore a√∫n")
        
        # üîß OPTIMIZACI√ìN: Hacer el preprocesamiento opcional para inicio r√°pido
        enable_preprocessing = os.getenv("ENABLE_DOCUMENT_PREPROCESSING", "false").lower() == "true"
        
        # üóÑÔ∏è Si ya hay datos en DB, saltar preprocesamiento autom√°ticamente
        has_indexes = len(all_indexes) > 0
        has_memories = len(tenant_ids) > 0
        
        if has_indexes or has_memories:
            print(f"‚úÖ Sistema ya optimizado - {len(all_indexes)} √≠ndices y {len(tenant_ids)} memorias en DB")
            print("‚ö° Saltando preprocesamiento autom√°tico (inicio r√°pido)")
            
            if enable_preprocessing:
                print("üí° Para forzar reprocesamiento: reiniciar con ENABLE_DOCUMENT_PREPROCESSING=true")
            
        elif enable_preprocessing:
            print("üöÄ Preprocesamiento de documentos HABILITADO - procesando nuevos documentos...")
            await preload_documents_on_startup_optimized()
        else:
            print("‚ö° Preprocesamiento DESHABILITADO - usando √≠ndices de DB (inicio r√°pido)")
            print("üí° Para reprocesar: set ENABLE_DOCUMENT_PREPROCESSING=true")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Error cargando metadatos desde DB: {e}")
        print("‚ÑπÔ∏è El servicio funcionar√° normalmente con carga lazy")

@app.get("/")
async def root():
    """Endpoint ra√≠z"""
    return {
        "service": "chatbot-ai-service",
        "version": "1.0.0",
        "description": "Servicio de IA para chatbots pol√≠ticos",
        "status": "running"
    }

@app.get("/health")
async def health_check():
    """Health check del servicio con verificaci√≥n de preprocesamiento"""
    try:
        from chatbot_ai_service.services.document_preprocessor_service import document_preprocessor_service
        from chatbot_ai_service.services.document_context_service import document_context_service
        
        # Obtener estado del preprocesamiento
        cache_stats = document_preprocessor_service.get_cache_stats()
        processing_statuses = cache_stats.get("processing_status", {})
        
        # Verificar si hay tenants en procesamiento o fallidos
        processing_tenants = [tenant for tenant, status in processing_statuses.items() 
                            if status in ["processing"]]
        failed_tenants = [tenant for tenant, status in processing_statuses.items() 
                        if status in ["failed", "timeout"]]
        completed_tenants = [tenant for tenant, status in processing_statuses.items() 
                            if status == "completed"]
        
        # üîß FIX: Verificar tambi√©n si hay documentos cargados directamente en document_context_service
        # Esto ocurre cuando los documentos se cargan desde Firestore en el startup
        # sin pasar por el preprocesador
        loaded_tenants_from_context = set()
        try:
            if hasattr(document_context_service, '_index_cache') and document_context_service._index_cache:
                loaded_tenants_from_context.update(document_context_service._index_cache.keys())
            if hasattr(document_context_service, '_document_cache') and document_context_service._document_cache:
                loaded_tenants_from_context.update(document_context_service._document_cache.keys())
        except Exception:
            # Si hay error accediendo a los caches, asumir que no hay documentos cargados
            pass
        
        # Si hay documentos cargados en document_context_service, considerarlos como "ready"
        # incluso si no est√°n en el preprocesador
        has_loaded_documents = len(loaded_tenants_from_context) > 0
        
        # Determinar estado de salud
        # CR√çTICO: Considerar "healthy" si:
        # 1. Hay tenants completados en el preprocesador, O
        # 2. Hay documentos cargados directamente en document_context_service
        if processing_tenants:
            health_status = "preprocessing"  # Cloud Run NO enviar√° tr√°fico
        elif failed_tenants and not has_loaded_documents:
            health_status = "degraded"      # Cloud Run NO enviar√° tr√°fico
        elif completed_tenants or has_loaded_documents:
            health_status = "healthy"       # Cloud Run S√ç enviar√° tr√°fico
        else:
            health_status = "starting"      # Cloud Run NO enviar√° tr√°fico
        
        return {
            "status": health_status,
            "service": "chatbot-ai-service",
            "version": "1.0.0",
            "preprocessing": {
                "completed_tenants": len(completed_tenants),
                "processing_tenants": len(processing_tenants),
                "failed_tenants": len(failed_tenants),
                "total_tenants": cache_stats.get("total_tenants", 0),
                "loaded_from_context": len(loaded_tenants_from_context),
                "loaded_tenant_ids": list(loaded_tenants_from_context)
            }
        }
        
    except Exception as e:
        return {
            "status": "error",
            "service": "chatbot-ai-service",
            "version": "1.0.0",
            "error": str(e)
        }

@app.get("/ready")
async def readiness_check():
    """Readiness check - Con preprocesamiento s√≠ncrono, si el servicio est√° disponible ya est√° listo"""
    return {"status": "ready"}

# Nota: La aplicaci√≥n se ejecuta con Granian (servidor ASGI en Rust)
# Ver run_server.sh (local) o Dockerfile (producci√≥n) para configuraci√≥n del servidor