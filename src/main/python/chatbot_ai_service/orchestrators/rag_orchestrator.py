"""
RAG Orchestrator - Cerebro del sistema RAG

Orquesta el flujo completo de Retrieval-Augmented Generation:
1. Query Rewriting (reformular preguntas)
2. Document Retrieval (buscar documentos relevantes)
3. Context Building (construir contexto)
4. Response Generation (generar respuesta)
5. Verification (verificar respuesta)
6. Citation (agregar citas)

Este es el componente central del sistema RAG, coordinando todos
los demÃ¡s componentes para producir respuestas verificadas y fundamentadas.
"""

import logging
from typing import Dict, Any, List, Optional
from dataclasses import dataclass

from chatbot_ai_service.retrievers.smart_retriever import SmartRetriever, SearchResult
from chatbot_ai_service.verifiers.source_verifier import SourceVerifier, VerificationResult
from chatbot_ai_service.prompts.system_prompts import PromptBuilder, PromptType
from chatbot_ai_service.guardrails.guardrail_verifier import GuardrailVerifier, GuardrailVerificationResult
from chatbot_ai_service.guardrails.response_sanitizer import ResponseSanitizer

logger = logging.getLogger(__name__)


@dataclass
class RAGResponse:
    """Respuesta completa del RAGOrchestrator"""
    response: str
    response_with_citations: str
    verification: VerificationResult
    retrieved_documents: List[SearchResult]
    metadata: Dict[str, Any]
    guardrail_result: Optional[GuardrailVerificationResult] = None
    sanitization_applied: bool = False


class RAGOrchestrator:
    """
    Orquestador principal del sistema RAG
    
    Coordina todo el flujo desde la pregunta del usuario hasta
    la respuesta verificada con citas de fuentes.
    
    CaracterÃ­sticas:
    - Query rewriting para mejor bÃºsqueda
    - Hybrid retrieval (semÃ¡ntica + keywords)
    - Context building inteligente
    - Response generation con documentos
    - Source verification
    - Automatic citations
    """
    
    def __init__(
        self, 
        gemini_client=None,
        document_service=None,
        enable_verification: bool = True,
        enable_citations: bool = True,
        enable_guardrails: bool = True,
        strict_guardrails: bool = True
    ):
        """
        Inicializa el RAGOrchestrator
        
        Args:
            gemini_client: Cliente de Gemini para generaciÃ³n
            document_service: Servicio de documentos
            enable_verification: Si True, verifica respuestas
            enable_citations: Si True, agrega citas
            enable_guardrails: Si True, aplica guardrails estrictos
            strict_guardrails: Si True, fallos crÃ­ticos invalidan respuesta
        """
        self.gemini_client = gemini_client
        self.document_service = document_service
        self.enable_verification = enable_verification
        self.enable_citations = enable_citations
        self.enable_guardrails = enable_guardrails
        self.strict_guardrails = strict_guardrails
        
        # Inicializar componentes
        self.retriever = SmartRetriever()
        self.verifier = SourceVerifier()
        
        # ğŸ›¡ï¸ FASE 5: Guardrails
        self.prompt_builder = PromptBuilder()
        self.guardrail_verifier = GuardrailVerifier(strict_mode=strict_guardrails)
        self.response_sanitizer = ResponseSanitizer(aggressive_mode=strict_guardrails)
        
        logger.info(
            f"ğŸš€ RAGOrchestrator inicializado "
            f"(verification={enable_verification}, citations={enable_citations}, "
            f"guardrails={enable_guardrails}, strict={strict_guardrails})"
        )
    
    async def _rewrite_query(self, query: str) -> List[str]:
        """
        Reescribe el query para mejorar la bÃºsqueda
        
        Genera variaciones del query original para capturar
        mÃ¡s documentos relevantes.
        
        Args:
            query: Query original del usuario
            
        Returns:
            Lista de queries (incluyendo el original)
        """
        # Por ahora, solo retornamos el query original
        # En futuras versiones, usaremos Gemini para generar variaciones
        
        queries = [query]
        
        # Agregar variaciÃ³n con palabras clave adicionales
        if "propuesta" in query.lower() or "propone" in query.lower():
            queries.append(f"{query} plan gobierno programa")
        
        if "candidato" in query.lower():
            queries.append(f"{query} trayectoria biografia perfil")
        
        logger.debug(f"Query rewriting: {len(queries)} variaciones generadas")
        return queries
    
    async def _retrieve_documents(
        self, 
        queries: List[str], 
        tenant_id: str,
        max_results: int = 5
    ) -> List[SearchResult]:
        """
        Recupera documentos relevantes para los queries
        
        Args:
            queries: Lista de queries
            tenant_id: ID del tenant
            max_results: MÃ¡ximo de documentos a recuperar
            
        Returns:
            Lista de documentos recuperados
        """
        all_docs = []
        
        for query in queries:
            docs = await self.retriever.retrieve(
                query=query,
                tenant_id=tenant_id,
                max_results=max_results
            )
            all_docs.extend(docs)
        
        # Deduplicar por doc_id
        unique_docs = {}
        for doc in all_docs:
            if doc.doc_id not in unique_docs:
                unique_docs[doc.doc_id] = doc
            else:
                # Si ya existe, mantener el de mayor score
                if doc.score > unique_docs[doc.doc_id].score:
                    unique_docs[doc.doc_id] = doc
        
        # Ordenar por score y retornar top N
        final_docs = sorted(
            unique_docs.values(), 
            key=lambda x: x.score, 
            reverse=True
        )[:max_results]
        
        logger.info(f"Recuperados {len(final_docs)} documentos Ãºnicos")
        return final_docs
    
    def _build_rag_context(
        self, 
        documents: List[SearchResult],
        max_context_length: int = 3000
    ) -> str:
        """
        Construye el contexto para Gemini a partir de los documentos
        
        Args:
            documents: Documentos recuperados
            max_context_length: Longitud mÃ¡xima del contexto
            
        Returns:
            Contexto formateado para el prompt
        """
        if not documents:
            return "No se encontraron documentos relevantes."
        
        context_parts = []
        current_length = 0
        
        for i, doc in enumerate(documents, 1):
            doc_text = f"[Documento {i}] {doc.filename}\n{doc.content}\n"
            
            # Verificar si agregar este documento excede el lÃ­mite
            if current_length + len(doc_text) > max_context_length:
                # Truncar el documento si es necesario
                remaining_space = max_context_length - current_length
                if remaining_space > 200:  # Solo agregar si queda espacio razonable
                    doc_text = doc_text[:remaining_space] + "...\n"
                    context_parts.append(doc_text)
                break
            
            context_parts.append(doc_text)
            current_length += len(doc_text)
        
        context = "\n".join(context_parts)
        
        logger.debug(f"Contexto construido: {len(context)} caracteres de {len(documents)} documentos")
        return context
    
    def _build_rag_prompt(
        self, 
        query: str, 
        context: str,
        user_context: Dict[str, Any] = None,
        tenant_config: Dict[str, Any] = None
    ) -> str:
        """
        Construye el prompt completo para RAG con guardrails y personalidad especÃ­fica del tenant
        INCLUYE contexto de sesiÃ³n para continuidad
        
        Args:
            query: Pregunta del usuario
            context: Contexto de documentos
            user_context: Contexto adicional del usuario (puede incluir session_context)
            tenant_config: ConfiguraciÃ³n del tenant para personalizaciÃ³n
            
        Returns:
            Prompt formateado con guardrails y personalidad
        """
        # Extraer informaciÃ³n de branding del tenant
        # Primero intentar obtener de branding_config (si existe)
        contact_name = None
        candidate_name = "Asistente"
        
        if tenant_config:
            # Intentar obtener de branding_config primero (formato comÃºn)
            branding_config = tenant_config.get('branding_config', {})
            if isinstance(branding_config, dict):
                contact_name = branding_config.get('contactName') or branding_config.get('contact_name')
            
            # Si no se encontrÃ³, intentar desde branding directo
            if not contact_name:
                branding = tenant_config.get('branding', {})
                if isinstance(branding, dict):
                    contact_name = branding.get('contact_name') or branding.get('contactName')
            
            # Si aÃºn no se encontrÃ³, buscar en nivel raÃ­z
            if not contact_name:
                contact_name = tenant_config.get('contact_name') or tenant_config.get('contactName')
            
            # Si branding existe, obtener candidate_name
            branding = tenant_config.get('branding', {})
            if isinstance(branding, dict):
                candidate_name = branding.get('candidate_name', candidate_name)
        
        # Si NO se encontrÃ³ ningÃºn contact_name, usar valor por defecto
        if not contact_name:
            contact_name = "el candidato"
        
        # Log para debug
        logger.info(f"ğŸ‘¤ [RAG] contact_name extraÃ­do: '{contact_name}'")
        if contact_name == "el candidato":
            logger.warning(f"âš ï¸ [RAG] Usando valor por defecto 'el candidato'. tenant_config keys: {list(tenant_config.keys()) if tenant_config else 'None'}")
        
        # ğŸ”§ FIX: Incluir contexto de sesiÃ³n si estÃ¡ disponible
        session_context = ""
        if user_context and "session_context" in user_context:
            session_context = user_context["session_context"]
            logger.debug(f"Contexto de sesiÃ³n incluido en prompt: {len(session_context)} chars")
        
        # ğŸ›¡ï¸ FASE 5: Usar PromptBuilder con guardrails
        if self.enable_guardrails:
            # Detectar automÃ¡ticamente el tipo de prompt
            prompt_type = self.prompt_builder.detect_prompt_type(query)
            
            logger.debug(f"Tipo de prompt detectado: {prompt_type.value}")
            
            # Construir prompt con guardrails y personalidad
            prompt = self.prompt_builder.build_prompt(
                query=query,
                documents=context,
                prompt_type=prompt_type,
                user_context=user_context,
                tenant_config=tenant_config
            )
            
            return prompt
        
        # Fallback: Prompt original con personalidad
        user_info = ""
        if user_context and user_context.get("user_name"):
            user_info = f"El usuario se llama {user_context['user_name']}. "
        
        prompt = f"""
Asistente virtual {candidate_name} de la campaÃ±a polÃ­tica de {contact_name}.

**PERSONALIDAD Y TONO:**
- Habla como representante de {contact_name} y su campaÃ±a
- SÃ© amigable, cercano y autÃ©ntico
- Usa un tono conversacional pero profesional
- Muestra pasiÃ³n por los temas de la campaÃ±a
- Si no tienes informaciÃ³n especÃ­fica, ofrece conectar con el equipo de {contact_name}

**REGLAS FUNDAMENTALES:**
1. SOLO responde con informaciÃ³n de los DOCUMENTOS proporcionados
2. Si la informaciÃ³n estÃ¡ en los documentos, Ãºsala pero NO cites la fuente
3. Si NO estÃ¡ en los documentos, di explÃ­citamente "No tengo esa informaciÃ³n en nuestros documentos de campaÃ±a"
4. NUNCA inventes datos, nÃºmeros, fechas o detalles que no estÃ©n en los documentos
5. Si la pregunta requiere informaciÃ³n no disponible, sugiere contactar al equipo de {contact_name}

**CONTEXTO DEL USUARIO:**
{user_info}

**DOCUMENTOS DISPONIBLES:**
{context}

**PREGUNTA DEL USUARIO:**
{query}

**INSTRUCCIONES PARA LA RESPUESTA:**
- SÃ© claro, conciso y directo
- Usa la informaciÃ³n de los documentos
- Si no hay informaciÃ³n, sÃ© honesto al respecto
- MantÃ©n un tono profesional y amigable como representante de {contact_name}

**TU RESPUESTA:**
"""
        return prompt
    
    async def _generate_response(
        self, 
        prompt: str,
        task_type: str = "rag_generation"
    ) -> str:
        """
        Genera la respuesta usando Gemini
        
        Args:
            prompt: Prompt completo
            task_type: Tipo de tarea para configuraciÃ³n
            
        Returns:
            Respuesta generada
        """
        logger.info(f"ğŸ” [GENERATE_RESPONSE] Iniciando generaciÃ³n de respuesta...")
        logger.info(f"ğŸ” [GENERATE_RESPONSE] Â¿gemini_client disponible? {self.gemini_client is not None}")
        logger.info(f"ğŸ” [GENERATE_RESPONSE] Longitud del prompt: {len(prompt)} caracteres")
        logger.info(f"ğŸ” [GENERATE_RESPONSE] Primeros 500 chars del prompt: {prompt[:500]}")
        
        if not self.gemini_client:
            logger.error("âŒ [GENERATE_RESPONSE] GeminiClient no disponible")
            return "Lo siento, el servicio de IA no estÃ¡ disponible en este momento."
        
        try:
            logger.info(f"ğŸ” [GENERATE_RESPONSE] Llamando a gemini_client.generate_content...")
            response = await self.gemini_client.generate_content(
                prompt=prompt,
                task_type=task_type,
                use_custom_config=True
            )
            
            logger.info(f"âœ… [GENERATE_RESPONSE] Respuesta generada ({len(response) if response else 0} caracteres)")
            if response:
                logger.info(f"âœ… [GENERATE_RESPONSE] Primeros 200 chars: {response[:200]}")
            else:
                logger.warning(f"âš ï¸ [GENERATE_RESPONSE] Respuesta vacÃ­a o None")
            
            return response if response else "No pude generar una respuesta. Por favor intenta de nuevo."
            
        except Exception as e:
            logger.error(f"âŒ [GENERATE_RESPONSE] Error generando respuesta: {str(e)}")
            import traceback
            logger.error(f"âŒ [GENERATE_RESPONSE] Traceback: {traceback.format_exc()}")
            return f"Lo siento, hubo un error al procesar tu consulta: {str(e)}"
    
    async def process_query(
        self, 
        query: str, 
        tenant_id: str,
        user_context: Dict[str, Any] = None,
        max_docs: int = 3,
        tenant_config: Dict[str, Any] = None
    ) -> RAGResponse:
        """
        Procesa un query completo usando RAG
        
        Este es el mÃ©todo principal que orquesta todo el flujo:
        1. Rewrite query
        2. Retrieve documents
        3. Build context
        4. Generate response
        5. Verify response
        6. Add citations
        
        Args:
            query: Pregunta del usuario
            tenant_id: ID del tenant
            user_context: Contexto adicional del usuario
            max_docs: MÃ¡ximo nÃºmero de documentos a usar
            
        Returns:
            RAGResponse con respuesta completa y metadata
        """
        logger.info(f"Procesando query RAG: '{query}' para tenant {tenant_id}")
        
        start_time = None
        try:
            import time
            start_time = time.time()
        except:
            pass
        
        # 1. Query Rewriting
        logger.info("1ï¸âƒ£ Reescribiendo query...")
        queries = await self._rewrite_query(query)
        
        # 2. Document Retrieval
        logger.info("2ï¸âƒ£ Recuperando documentos...")
        documents = await self._retrieve_documents(queries, tenant_id, max_docs)
        
        if not documents:
            logger.warning("âš ï¸ No se encontraron documentos relevantes")
            return RAGResponse(
                response="Lo siento, no encontrÃ© informaciÃ³n relevante en los documentos disponibles para responder tu pregunta. Â¿PodrÃ­as reformularla o hacer una pregunta mÃ¡s especÃ­fica?",
                response_with_citations="",
                verification=VerificationResult(
                    is_verified=False,
                    confidence=0.0,
                    unsupported_claims=[],
                    sources_used=[],
                    hallucination_risk=0.0,
                    recommendation="No hay documentos disponibles"
                ),
                retrieved_documents=[],
                metadata={"query": query, "tenant_id": tenant_id},
                guardrail_result=None,
                sanitization_applied=False
            )
        
        # 3. Build Context
        logger.info("3ï¸âƒ£ Construyendo contexto...")
        context = self._build_rag_context(documents)
        
        # 4. Build Prompt
        logger.info("4ï¸âƒ£ Construyendo prompt...")
        prompt = self._build_rag_prompt(query, context, user_context, tenant_config)
        
        # 5. Generate Response
        logger.info("5ï¸âƒ£ Generando respuesta...")
        logger.info(f"ğŸ” [PROCESS_QUERY] Prompt length: {len(prompt)} chars")
        logger.info(f"ğŸ” [PROCESS_QUERY] Prompt first 500 chars: {prompt[:500]}")
        response = await self._generate_response(prompt)
        logger.info(f"ğŸ” [PROCESS_QUERY] Response received: {len(response) if response else 0} chars")
        logger.info(f"ğŸ” [PROCESS_QUERY] Response content: {response[:200] if response else 'None'}")
        
        # ğŸ›¡ï¸ FASE 5: VerificaciÃ³n con Guardrails
        guardrail_result = None
        sanitization_applied = False
        
        if self.enable_guardrails:
            logger.info("6ï¸âƒ£ Verificando guardrails...")
            guardrail_result = self.guardrail_verifier.verify(
                response=response,
                documents=documents,
                query=query
            )
            
            logger.info(
                f"   â””â”€ Score: {guardrail_result.score:.0%}, "
                f"Critical: {guardrail_result.critical_failures}, "
                f"Warnings: {guardrail_result.warnings}"
            )
            
            # Si falla guardrails, sanitizar
            if not guardrail_result.all_passed:
                logger.warning(f"âš ï¸ Guardrails no pasados: {guardrail_result.recommendation}")
                
                if self.strict_guardrails and guardrail_result.critical_failures > 0:
                    logger.info("7ï¸âƒ£ Sanitizando respuesta...")
                    response, changes = self.response_sanitizer.sanitize(
                        response=response,
                        documents=documents,
                        guardrail_result=guardrail_result
                    )
                    sanitization_applied = True
                    logger.info(f"   â””â”€ Cambios aplicados: {len(changes)}")
        
        # 8. Verify Response (SourceVerifier)
        verification = None
        if self.enable_verification:
            logger.info("8ï¸âƒ£ Verificando fuentes...")
            verification = self.verifier.verify_response(response, documents)
        else:
            verification = VerificationResult(
                is_verified=True,
                confidence=1.0,
                unsupported_claims=[],
                sources_used=[],
                hallucination_risk=0.0,
                recommendation="VerificaciÃ³n deshabilitada"
            )
        
        # 9. Add Citations
        response_with_citations = response
        if self.enable_citations:
            logger.info("9ï¸âƒ£ Agregando citas...")
            response_with_citations = self.verifier.add_citations(response, documents)
        
        # Calculate processing time
        processing_time = None
        if start_time:
            try:
                processing_time = time.time() - start_time
            except:
                pass
        
        # Build metadata
        metadata = {
            "query": query,
            "tenant_id": tenant_id,
            "num_documents_retrieved": len(documents),
            "num_queries_generated": len(queries),
            "verification_enabled": self.enable_verification,
            "citations_enabled": self.enable_citations,
            "guardrails_enabled": self.enable_guardrails,
            "processing_time_seconds": processing_time
        }
        
        # Agregar metadata de guardrails si estÃ¡ habilitado
        if guardrail_result:
            metadata["guardrail_score"] = guardrail_result.score
            metadata["guardrail_passed"] = guardrail_result.all_passed
            metadata["critical_failures"] = guardrail_result.critical_failures
            metadata["warnings"] = guardrail_result.warnings
            metadata["sanitization_applied"] = sanitization_applied
        
        # Log de documentos utilizados para la respuesta
        if documents:
            doc_names = [doc.filename for doc in documents]
            logger.info(f"DOCUMENTOS UTILIZADOS PARA LA RESPUESTA: {doc_names}")
        else:
            logger.info("RESPUESTA GENERADA SIN DOCUMENTOS (informaciÃ³n general)")
        
        logger.info(
            f"Query RAG procesado exitosamente "
            f"({len(documents)} docs, {processing_time:.2f}s)" if processing_time else ""
        )
        
        return RAGResponse(
            response=response,
            response_with_citations=response_with_citations,
            verification=verification,
            retrieved_documents=documents,
            metadata=metadata,
            guardrail_result=guardrail_result,
            sanitization_applied=sanitization_applied
        )
    
    async def process_query_simple(
        self, 
        query: str, 
        tenant_id: str,
        user_context: Dict[str, Any] = None,
        session_id: str = None,
        tenant_config: Dict[str, Any] = None
    ) -> str:
        """
        VersiÃ³n simplificada que solo retorna la respuesta con citas
        INCLUYE contexto de sesiÃ³n para mantener continuidad
        
        Args:
            query: Pregunta del usuario
            tenant_id: ID del tenant
            user_context: Contexto del usuario
            session_id: ID de sesiÃ³n para contexto persistente
            tenant_config: ConfiguraciÃ³n del tenant para personalizaciÃ³n
            
        Returns:
            Respuesta con citas (string)
        """
        # ğŸ”§ FIX: Incluir contexto de sesiÃ³n si estÃ¡ disponible
        if session_id:
            try:
                from chatbot_ai_service.services.session_context_service import session_context_service
                session_context = session_context_service.build_context_for_ai(session_id)
                if session_context:
                    # Agregar contexto de sesiÃ³n al user_context
                    if not user_context:
                        user_context = {}
                    user_context["session_context"] = session_context
                    logger.info(f"âœ… Contexto de sesiÃ³n incluido en RAG: {len(session_context)} chars")
            except Exception as e:
                logger.warning(f"âš ï¸ Error obteniendo contexto de sesiÃ³n: {str(e)}")
        
        logger.info(f"ğŸ” [RAG_SIMPLE] Procesando query: '{query[:100]}...'")
        rag_response = await self.process_query(query, tenant_id, user_context, tenant_config=tenant_config)
        
        logger.info(f"ğŸ” [RAG_SIMPLE] Respuesta recibida: {len(rag_response.response) if rag_response.response else 0} caracteres")
        if rag_response.response:
            logger.info(f"ğŸ” [RAG_SIMPLE] Primeros 200 chars: {rag_response.response[:200]}")
        else:
            logger.warning(f"ğŸ” [RAG_SIMPLE] Respuesta vacÃ­a o None")
        
        if self.enable_citations:
            logger.info(f"ğŸ” [RAG_SIMPLE] Devolviendo respuesta con citas")
            return rag_response.response_with_citations
        else:
            logger.info(f"ğŸ” [RAG_SIMPLE] Devolviendo respuesta sin citas")
            return rag_response.response

