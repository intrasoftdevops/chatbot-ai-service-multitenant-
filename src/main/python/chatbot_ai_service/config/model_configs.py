"""
Configuraciones de modelo Gemini por tipo de tarea

Este mÃ³dulo define configuraciones especÃ­ficas para diferentes tipos de tareas,
optimizando temperatura, top_p, y otros parÃ¡metros segÃºn el caso de uso.

Estrategia:
- Tareas determinÃ­sticas (clasificaciÃ³n, extracciÃ³n): temperature=0.0
- Tareas conversacionales: temperature=0.7
- Tareas analÃ­ticas complejas: modelos mÃ¡s potentes

Impacto esperado:
- +5-10% precisiÃ³n en clasificaciÃ³n
- Respuestas JSON mÃ¡s confiables
- Menos retries por respuestas invÃ¡lidas
"""

from typing import Dict, Any

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURACIONES POR TIPO DE TAREA
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

MODEL_CONFIGS: Dict[str, Dict[str, Any]] = {
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CHAT CONVERSACIONAL
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "chat_conversational": {
        "model_name": "gemini-2.5-flash",  # âœ… Modelo oficial disponible segÃºn Google
        "temperature": 0.7,  # Respuestas naturales y variadas
        "top_p": 0.8,
        "top_k": 40,
        "max_output_tokens": 1024,
        "description": "Para conversaciones naturales con el usuario",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # CLASIFICACIÃ“N DE INTENCIONES
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "intent_classification": {
        "model_name": "gemini-2.5-flash",  # âœ… Modelo oficial disponible segÃºn Google
        "temperature": 0.0,  # Completamente determinÃ­stico
        "top_p": 0.1,  # Muy restrictivo
        "top_k": 1,  # Solo la mejor opciÃ³n
        "max_output_tokens": 100,  # Respuestas cortas
        # "response_mime_type": "application/json",  # No soportado en 0.3.2
        "description": "Para clasificar intenciones con alta precisiÃ³n",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # EXTRACCIÃ“N DE DATOS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "data_extraction": {
        "model_name": "gemini-2.0-flash",  # ðŸ”§ FIX: Cambiar a modelo disponible
        "temperature": 0.0,  # DeterminÃ­stico
        "top_p": 0.1,
        "top_k": 1,
        "max_output_tokens": 512,
        # "response_mime_type": "application/json",  # No soportado en 0.3.2
        "description": "Para extraer datos estructurados (nombre, ciudad, telÃ©fono)",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # VALIDACIÃ“N DE DATOS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "data_validation": {
        "model_name": "gemini-2.0-flash",  # ðŸ”§ FIX: Cambiar a modelo disponible
        "temperature": 0.0,  # DeterminÃ­stico
        "top_p": 0.1,
        "top_k": 1,
        "max_output_tokens": 256,
        # "response_mime_type": "application/json",  # No soportado en 0.3.2
        "description": "Para validar datos con criterios estrictos",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ANÃLISIS DE DOCUMENTOS
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "document_analysis": {
        "model_name": "gemini-2.0-flash",  # ðŸ”§ FIX: Cambiar a modelo disponible
        "temperature": 0.1,  # Casi determinÃ­stico, pero con algo de creatividad
        "top_p": 0.9,
        "top_k": 40,
        "max_output_tokens": 2048,  # Respuestas mÃ¡s largas
        "description": "Para anÃ¡lisis profundo de documentos complejos",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # DETECCIÃ“N DE COMPORTAMIENTO MALICIOSO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "malicious_detection": {
        "model_name": "gemini-2.0-flash",  # ðŸ”§ FIX: Cambiar a modelo disponible
        "temperature": 0.0,  # Muy estricto
        "top_p": 0.1,
        "top_k": 1,
        "max_output_tokens": 200,
        # "response_mime_type": "application/json",  # No soportado en 0.3.2
        "description": "Para detectar intentos maliciosos con alta precisiÃ³n",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ANÃLISIS DE REGISTRO
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "registration_analysis": {
        "model_name": "gemini-2.0-flash",  # ðŸ”§ FIX: Cambiar a modelo disponible
        "temperature": 0.1,  # Casi determinÃ­stico
        "top_p": 0.2,
        "top_k": 5,
        "max_output_tokens": 512,
        # "response_mime_type": "application/json",  # No soportado en 0.3.2
        "description": "Para analizar respuestas en flujo de registro",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # NORMALIZACIÃ“N DE UBICACIONES
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "location_normalization": {
        "model_name": "gemini-2.0-flash",
        "temperature": 0.0,  # Completamente determinÃ­stico
        "top_p": 0.1,
        "top_k": 1,
        "max_output_tokens": 100,
        # "response_mime_type": "application/json",  # No soportado en 0.3.2
        "description": "Para normalizar nombres de ciudades con precisiÃ³n",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # GENERACIÃ“N DE RESPUESTAS CON SESIÃ“N
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "chat_with_session": {
        "model_name": "gemini-2.0-flash",
        "temperature": 0.6,  # Balanceado entre consistencia y naturalidad
        "top_p": 0.8,
        "top_k": 40,
        "max_output_tokens": 1024,
        "description": "Para respuestas que consideran contexto de sesiÃ³n",
    },
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RAG (Retrieval-Augmented Generation)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    "rag_generation": {
        "model_name": "gemini-1.5-pro",  # Modelo potente para RAG
        "temperature": 0.3,  # Balance entre precisiÃ³n y naturalidad
        "top_p": 0.9,
        "top_k": 40,
        "max_output_tokens": 2048,
        "description": "Para generar respuestas basadas en documentos (RAG)",
    },
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNCIONES PÃšBLICAS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_config_for_task(task_type: str) -> Dict[str, Any]:
    """
    Obtiene la configuraciÃ³n Ã³ptima para un tipo de tarea
    
    Args:
        task_type: Tipo de tarea (ej: "intent_classification", "chat_conversational")
        
    Returns:
        Diccionario con la configuraciÃ³n del modelo
        
    Ejemplo:
        >>> config = get_config_for_task("intent_classification")
        >>> print(config["temperature"])  # 0.0
        >>> print(config["model_name"])   # "gemini-2.0-flash"
    """
    # Si la tarea no existe, usar configuraciÃ³n conversacional por defecto
    if task_type not in MODEL_CONFIGS:
        return MODEL_CONFIGS["chat_conversational"].copy()
    
    return MODEL_CONFIGS[task_type].copy()


def list_available_tasks() -> list:
    """
    Lista todas las tareas disponibles con sus descripciones
    
    Returns:
        Lista de tuplas (task_type, description)
        
    Ejemplo:
        >>> tasks = list_available_tasks()
        >>> for task, desc in tasks:
        ...     print(f"{task}: {desc}")
    """
    return [
        (task, config.get("description", "Sin descripciÃ³n"))
        for task, config in MODEL_CONFIGS.items()
    ]


def get_task_summary() -> Dict[str, str]:
    """
    Obtiene un resumen de todas las tareas y sus modelos
    
    Returns:
        Diccionario con task_type -> model_name
        
    Ejemplo:
        >>> summary = get_task_summary()
        >>> print(summary["intent_classification"])  # "gemini-2.0-flash"
    """
    return {
        task: config.get("model_name", "unknown")
        for task, config in MODEL_CONFIGS.items()
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAPEO DE MÃ‰TODOS A TASK TYPES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

METHOD_TO_TASK_TYPE = {
    "classify_intent": "intent_classification",
    "_classify_with_ai": "intent_classification",
    "_detect_malicious_intent": "malicious_detection",
    "extract_data": "data_extraction",
    "_extract_with_ai": "data_extraction",
    "validate_data": "data_validation",
    "_validate_with_ai": "data_validation",
    "normalize_location": "location_normalization",
    "_analyze_city_with_ai": "location_normalization",
    "analyze_registration": "registration_analysis",
    "_analyze_registration_with_ai": "registration_analysis",
    "process_chat_message": "chat_with_session",
    "_generate_ai_response_with_session": "chat_with_session",
    "_generate_ai_response": "chat_conversational",
    "_build_chat_prompt": "chat_conversational",
}


def get_task_type_for_method(method_name: str) -> str:
    """
    Obtiene el task_type apropiado para un mÃ©todo de AIService
    
    Args:
        method_name: Nombre del mÃ©todo (ej: "classify_intent")
        
    Returns:
        Task type correspondiente
        
    Ejemplo:
        >>> task = get_task_type_for_method("classify_intent")
        >>> print(task)  # "intent_classification"
    """
    return METHOD_TO_TASK_TYPE.get(method_name, "chat_conversational")

