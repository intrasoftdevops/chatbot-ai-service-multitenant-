"""
Servicio de IA optimizado con timeout y logging mejorado
"""
import logging
import time
from typing import Dict, Any, Optional
from chatbot_ai_service.config.optimization_config import optimization_config

logger = logging.getLogger(__name__)

class OptimizedAIService:
    """Servicio de IA optimizado con timeout y logging mejorado"""
    
    # Cache global de prompts cargados al arrancar
    _prompts_cache = {}
    
    def __init__(self, base_ai_service):
        self.base_ai_service = base_ai_service
        self.logger = logging.getLogger(__name__)
    
    async def process_chat_message_optimized(self, tenant_id: str, query: str, 
                                           user_context: Dict[str, Any], 
                                           session_id: str = None, 
                                           tenant_config: Dict[str, Any] = None,
                                           conversation_history: str = None) -> Dict[str, Any]:
        """
        Procesa mensaje de chat con optimizaciones simplificadas
        
        Args:
            tenant_id: ID del tenant
            query: Mensaje del usuario (SIN historial - solo para clasificaci√≥n)
            user_context: Contexto del usuario
            session_id: ID de la sesi√≥n
            tenant_config: Configuraci√≥n del tenant
            conversation_history: Historial de conversaci√≥n (para procesamiento, NO para clasificaci√≥n)
            
        Returns:
            Respuesta optimizada
        """
        print(f"üöÄ [OPTIMIZED] M√âTODO INICIADO - tenant: {tenant_id}, query: '{query[:50]}...'")
        self.logger.info(f"üöÄ [OPTIMIZED] M√âTODO INICIADO - tenant: {tenant_id}, query: '{query[:50]}...'")
        
        start_time = time.time()
        
        try:
            # 1. VERIFICAR CONFIGURACI√ìN DEL TENANT
            # üîç DEBUG CR√çTICO: Ver qu√© tenant_config estamos recibiendo
            if tenant_config:
                self.logger.info(f"‚úÖ [OPTIMIZED] tenant_config RECIBIDO - keys: {list(tenant_config.keys())}")
                if 'numero_whatsapp' in tenant_config:
                    self.logger.info(f"‚úÖ [OPTIMIZED] numero_whatsapp PRESENTE: '{tenant_config['numero_whatsapp']}'")
                else:
                    self.logger.warning(f"‚ùå [OPTIMIZED] numero_whatsapp NO PRESENTE en tenant_config")
            else:
                self.logger.warning(f"‚ö†Ô∏è No se recibi√≥ tenant_config en el request, obteniendo desde servicio Java...")
                tenant_config = self._get_tenant_config(tenant_id)
                if not tenant_config:
                    return self._create_error_response("Tenant no encontrado", start_time)
                # üîç DEBUG: Ver qu√© devolvi√≥ _get_tenant_config
                self.logger.info(f"‚úÖ [OPTIMIZED] tenant_config desde GET - keys: {list(tenant_config.keys())}")
                if 'numero_whatsapp' in tenant_config:
                    self.logger.info(f"‚úÖ [OPTIMIZED] numero_whatsapp desde GET: '{tenant_config['numero_whatsapp']}'")
                else:
                    self.logger.warning(f"‚ùå [OPTIMIZED] numero_whatsapp NO en tenant_config desde GET")
            
            # 2. CLASIFICAR INTENCI√ìN
            print(f"üéØ [OPTIMIZED] Clasificando intenci√≥n...")
            self.logger.info(f"üéØ [OPTIMIZED] Clasificando intenci√≥n...")
            try:
                # üîß AGREGAR HISTORIAL AL USER_CONTEXT ANTES DE CLASIFICAR
                classification_user_context = user_context.copy() if user_context else {}
                if conversation_history:
                    classification_user_context['conversation_history'] = conversation_history
                    self.logger.info(f"üìö [CLASIFICACI√ìN] Historial incluido en user_context ({len(conversation_history)} chars)")
                
                intent_result = await self._classify_intent_optimized(tenant_id, query, classification_user_context)
                intent = intent_result.get("category", "saludo_apoyo")
                confidence = intent_result.get("confidence", 0.0)
                
                # üìä IMPRIMIR CLASIFICACI√ìN DETALLADA
                print(f"üìä [CLASIFICACI√ìN] Mensaje: '{query[:100]}...'")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Mensaje: '{query[:100]}...'")
                print(f"üìä [CLASIFICACI√ìN] Categor√≠a: '{intent}'")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Categor√≠a: '{intent}'")
                print(f"üìä [CLASIFICACI√ìN] Confianza: {confidence:.2f}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Confianza: {confidence:.2f}")
                print(f"üìä [CLASIFICACI√ìN] Tenant: {tenant_id}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Tenant: {tenant_id}")
                print(f"üìä [CLASIFICACI√ìN] Session: {session_id}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Session: {session_id}")
                print(f"üìä [CLASIFICACI√ìN] {'='*50}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] {'='*50}")
                
                # üéØ DEBUG: Verificar si es saludo antes del bloque de malicia
                print(f"üéØ [DEBUG] Intent despu√©s de clasificaci√≥n: '{intent}'")
                print(f"üéØ [DEBUG] ¬øEs saludo_apoyo? {intent == 'saludo_apoyo'}")
                print(f"üéØ [DEBUG] ¬øEs queja_detalle_select? {intent == 'queja_detalle_select'}")
                
                # üö´ PRIORIDAD CR√çTICA: Si es malicioso, BLOQUEAR INMEDIATAMENTE y NO procesar
                if intent == "malicioso":
                    self.logger.warning(f"üö´üö´üö´ MALICIA DETECTADA - BLOQUEANDO INMEDIATAMENTE")
                    self.logger.warning(f"üö´ Intent: '{intent}'")
                    self.logger.warning(f"üö´ Mensaje: '{query}'")
                    self.logger.warning(f"üö´ Confianza: {confidence:.2f}")
                    self.logger.warning(f"üö´ Tenant: {tenant_id}")
                    print(f"üö´üö´üö´ MALICIA DETECTADA EN PYTHON - BLOQUEANDO")
                    
                    # Obtener informaci√≥n del usuario para logging
                    user_id = user_context.get("user_id", "unknown")
                    phone_number = user_id if user_id != "unknown" else "unknown"
                    
                    self.logger.info(f"üîî Informaci√≥n de usuario para bloqueo:")
                    self.logger.info(f"   - user_id: {user_id}")
                    self.logger.info(f"   - phone_number: {phone_number}")
                    
                    # Importar el servicio de notificaci√≥n
                    from chatbot_ai_service.services.blocking_notification_service import BlockingNotificationService
                    
                    # Inicializar servicio de notificaci√≥n si no existe
                    if not hasattr(self.base_ai_service, 'blocking_notification_service') or not self.base_ai_service.blocking_notification_service:
                        blocking_service = BlockingNotificationService()
                        import os
                        java_url = os.getenv("POLITICAL_REFERRALS_SERVICE_URL", "http://localhost:8080")
                        blocking_service.set_java_service_url(java_url)
                        self.base_ai_service.blocking_notification_service = blocking_service
                    
                    # Notificar al servicio Java para bloquear en WATI
                    self.logger.info(f"üîî Enviando notificaci√≥n de bloqueo al servicio Java")
                    try:
                        notification_result = await self.base_ai_service.blocking_notification_service.notify_user_blocked(
                            tenant_id=tenant_id,
                            user_id=user_id,
                            phone_number=phone_number,
                            malicious_message=query,
                            classification_confidence=confidence
                        )
                        self.logger.info(f"üîî Resultado de notificaci√≥n: {notification_result}")
                        
                        if notification_result.get("success"):
                            self.logger.info(f"‚úÖ Usuario {user_id} bloqueado en WATI y base de datos")
                        else:
                            self.logger.error(f"‚ùå Error bloqueando usuario: {notification_result.get('error')}")
                    except Exception as notif_error:
                        self.logger.error(f"‚ùå Excepci√≥n notificando bloqueo: {str(notif_error)}")
                    
                    # NO enviar respuesta - bloquear silenciosamente
                    self.logger.warning(f"üö´ Usuario {user_id} bloqueado - NO enviando respuesta")
                    return {
                        "response": "",  # Respuesta vac√≠a = no responder
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": time.time() - start_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": "malicioso",
                        "confidence": confidence,
                        "user_blocked": True,
                        "optimized": True
                    }
            except Exception as classify_error:
                print(f"‚ùå [CLASIFICACI√ìN] ERROR EN CLASIFICACI√ìN: {classify_error}")
                self.logger.error(f"‚ùå [CLASIFICACI√ìN] ERROR EN CLASIFICACI√ìN: {classify_error}")
                self.logger.exception(classify_error)
                intent = "saludo_apoyo"
                confidence = 0.5
            
            # üöÄ ENFOQUE OPTIMIZADO: Primero intenta responder con documentos si el saludo contiene una pregunta o tema informativo
            if intent == "saludo_apoyo":
                # Siempre intentar responder con documentos
                try:
                    from chatbot_ai_service.clients.gemini_client import GeminiClient
                    from chatbot_ai_service.orchestrators.rag_orchestrator import RAGOrchestrator
                    rag = RAGOrchestrator(gemini_client=GeminiClient())
                    rag_response = await rag.process_query_simple(
                        query=query,
                        tenant_id=str(tenant_id),
                        user_context=user_context,
                        tenant_config=tenant_config
                    )
                    if rag_response and isinstance(rag_response, str) and len(rag_response.strip()) > 10:
                        processing_time = time.time() - start_time
                        self.logger.info(f"‚úÖ Respuesta informativa desde documentos ({processing_time:.4f}s)")
                        return {
                            "response": rag_response.strip(),
                            "followup_message": "",
                            "from_cache": False,
                            "processing_time": processing_time,
                            "tenant_id": tenant_id,
                            "session_id": session_id,
                            "intent": intent,
                            "confidence": confidence,
                            "user_blocked": False,
                            "optimized": True
                        }
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è RAG en saludo_apoyo fall√≥: {e}")

                # Fallback coherente basado en branding si RAG no devuelve
                try:
                    brand_cfg = (tenant_config or {}).get("branding", {})
                    contact_name = brand_cfg.get("contactName", brand_cfg.get("contact_name", "el candidato"))
                    response = f"Hola, estoy para ayudarte en lo que necesites sobre {contact_name}. ¬øQu√© te gustar√≠a saber?"
                except Exception:
                    response = "Hola, estoy para ayudarte. ¬øQu√© te gustar√≠a saber?"

                processing_time = time.time() - start_time
                return {
                    "response": response,
                    "followup_message": "",
                    "from_cache": False,
                    "processing_time": processing_time,
                    "tenant_id": tenant_id,
                    "session_id": session_id,
                    "intent": intent,
                    "confidence": confidence,
                    "optimized": True
                }
            
            # üéØ NUEVO: Manejar citas directamente (R√ÅPIDO)
            if intent == "cita_campa√±a":
                self.logger.info(f"üîç Intent es cita_campa√±a - generando respuesta con IA")
                print(f"üéØ [DEBUG] Intent detectado como cita_campa√±a")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Obtener link de Calendly desde DB del tenant
                    calendly_link = tenant_config.get("link_calendly", "") if tenant_config else ""
                    
                    # Generar respuesta con IA basada en si hay link disponible o no
                    if calendly_link:
                        self.logger.info(f"‚úÖ Link de Calendly disponible: {calendly_link}")
                        # Generar respuesta con IA que incluya el link
                        prompt = f"""Eres un asistente virtual de campa√±a pol√≠tica. El usuario quiere agendar una cita.

Informaci√≥n:
- Candidato: {contact_name}
- Link: {calendly_link}

CR√çTICO - FORMATO EXACTO REQUERIDO:
1. Escribe m√°ximo 2-3 oraciones cortas y completas
2. La √∫ltima oraci√≥n NO debe mencionar el link, solo debe ser una oraci√≥n completa y terminada con punto
3. NUNCA cortes una oraci√≥n a la mitad (ejemplo MALO: "el enlace que te compartimos a.")
4. Despu√©s de la √∫ltima oraci√≥n completa, escribe un salto de l√≠nea y luego el link
5. NO uses corchetes, NO uses "Link de Calendly:", NO uses markdown

FORMATO EXACTO A USAR:
[2-3 oraciones completas]

{calendly_link}

Ejemplo CORRECTO:
¬°Claro! Te ayudo a coordinar una cita con Daniel Quintero Presidente. Es una excelente oportunidad para conocerse y hablar sobre la campa√±a. Puedes agendar tu espacio usando el siguiente enlace.

{calendly_link}
"""

                        response = await self._generate_quick_ai_response(prompt)
                        
                        # Post-procesamiento: limpiar enlaces truncados o corruptos
                        import re
                        # Remover patrones como [Link de Calendly: https://...] si la IA los incluyera
                        response = re.sub(r'\[Link de Calendly:?\s*', '', response)
                        response = re.sub(r'\]\s*', '', response)
                        
                        # Remover enlaces truncados (que terminan con ...)
                        response = re.sub(rf'{re.escape(calendly_link[:20])}\.\.\.', '', response)
                        response = re.sub(r'https?://[^\s]+\.\.\.', '', response)
                        
                        # Si hay duplicados del link, consolidar
                        response = re.sub(rf'{re.escape(calendly_link)}\s+{re.escape(calendly_link)}', calendly_link, response)
                        
                        # Verificar si la respuesta incluye el enlace completo
                        has_full_link = calendly_link in response
                        
                        # Limpiar espacios m√∫ltiples
                        response = re.sub(r'\s+', ' ', response).strip()
                        
                        # Asegurar que el enlace est√© al final si existe, si no agregarlo
                        if has_full_link:
                            # Remover todas las ocurrencias del link del texto
                            response = response.replace(calendly_link, '')
                            response = response.strip()
                            # Agregar el link al final
                            if not response.endswith('.') and not response.endswith(':'):
                                response += "."
                            response += f"\n\n{calendly_link}"
                        else:
                            self.logger.warning(f"‚ö†Ô∏è La IA no incluy√≥ el enlace. Agreg√°ndolo ahora...")
                            # Si no incluye el enlace, agregarlo al final
                            if not response.endswith('.') and not response.endswith(':'):
                                response += "."
                            response += f"\n\n{calendly_link}"
                        
                        if not response or len(response.strip()) < 10:
                            # Fallback si IA no genera buena respuesta
                            response = f"""¬°Perfecto! Te ayudo a agendar una cita con alguien de la campa√±a.

Puedes reservar tu cita directamente aqu√≠: {calendly_link}

En la reuni√≥n podr√°s conocer m√°s sobre {contact_name}, hablar sobre oportunidades de voluntariado o coordinar actividades en tu regi√≥n. Si necesitas ayuda, preg√∫ntame."""
                    else:
                        self.logger.info(f"‚ö†Ô∏è Link de Calendly NO disponible para tenant {tenant_id}")
                        # Generar respuesta con IA indicando que pronto estar√° disponible
                        prompt = f"""Genera una respuesta natural y amigable en espa√±ol para un chatbot de campa√±a pol√≠tica. El usuario quiere agendar una cita pero el sistema de citas a√∫n no est√° disponible.

Informaci√≥n:
- Nombre del candidato: {contact_name}

Genera una respuesta breve que indique que el sistema de citas estar√° disponible muy pronto, pero ofreciendo alternativas como contactar por WhatsApp o esperar a que el sistema est√© listo."""

                        response = await self._generate_quick_ai_response(prompt)
                        
                        if not response or len(response.strip()) < 10:
                            # Fallback si IA no genera buena respuesta
                            response = f"""¬°Hola! Me alegra tu inter√©s en agendar una cita con {contact_name}. 

El sistema de citas estar√° disponible muy pronto. Mientras tanto, puedes contactarnos directamente por WhatsApp o esperar a que est√© listo.

¬øTe gustar√≠a que te notifique cuando el sistema de citas est√© disponible?"""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de cita generada con IA ({processing_time:.4f}s)")
                    print(f"üéØ [CITA] Respuesta generada por IA")
                    
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True
                    }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando cita: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar publicidad_info directamente (R√ÅPIDO)
            if intent == "publicidad_info":
                self.logger.info(f"üîç Intent es publicidad_info - generando respuesta con IA")
                print(f"üéØ [DEBUG] Intent detectado como publicidad_info")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Obtener link de Forms desde DB del tenant
                    forms_link = tenant_config.get("link_forms", "") if tenant_config else ""
                    
                    # Generar respuesta con IA basada en si hay link disponible o no
                    if forms_link:
                        self.logger.info(f"‚úÖ Link de Forms disponible: {forms_link}")
                        # Generar respuesta con IA que incluya el link
                        prompt = f"""Eres un asistente virtual de campa√±a pol√≠tica. El usuario quiere solicitar materiales publicitarios.

Informaci√≥n:
- Candidato: {contact_name}
- Link: {forms_link}

CR√çTICO - FORMATO EXACTO REQUERIDO:
1. Escribe m√°ximo 2-3 oraciones cortas y completas
2. La √∫ltima oraci√≥n NO debe mencionar el link, solo debe ser una oraci√≥n completa y terminada con punto
3. NUNCA cortes una oraci√≥n a la mitad (ejemplo MALO: "material de difusi√≥n y.")
4. Despu√©s de la √∫ltima oraci√≥n completa, escribe un salto de l√≠nea y luego el link
5. NO uses corchetes, NO uses "Link de Forms:", NO uses markdown
6. Aseg√∫rate de que TODAS las oraciones est√©n completas antes del link

FORMATO EXACTO A USAR:
[2-3 oraciones completas]

{forms_link}

Ejemplo CORRECTO:
¬°Hola! Qu√© excelente que quieras solicitar materiales publicitarios para la campa√±a de {contact_name}. En el formulario podr√°s solicitar folletos, material de difusi√≥n y propaganda de la campa√±a.

{forms_link}"""

                        response = await self._generate_quick_ai_response(prompt)
                        
                        # Post-procesamiento: limpiar enlaces truncados o corruptos
                        import re
                        
                        # Detectar y corregir oraciones cortadas antes del enlace
                        # Buscar patrones como "material de difusi√≥n y." o "material de difusi√≥n y"
                        if forms_link in response:
                            # Si el enlace est√° en medio, moverlo al final
                            link_pos = response.find(forms_link)
                            text_before_link = response[:link_pos].strip()
                            text_after_link = response[link_pos + len(forms_link):].strip()
                            
                            # Si hay texto antes del enlace que termina mal, corregirlo
                            if text_before_link and not text_before_link.endswith(('.', '!', '?', ':')):
                                # Buscar si la √∫ltima oraci√≥n est√° incompleta
                                last_sentence = text_before_link.split('.')[-1].strip() if '.' in text_before_link else text_before_link
                                if last_sentence and not last_sentence.endswith(('.', '!', '?')):
                                    # Completar la oraci√≥n o removerla si est√° cortada
                                    if last_sentence.endswith(('y', 'y.', 'y,', 'y ')):
                                        # Remover la √∫ltima palabra incompleta
                                        words = text_before_link.split()
                                        if words:
                                            # Remover la √∫ltima palabra si es "y" o similar
                                            if words[-1].lower() in ['y', 'y.', 'y,']:
                                                words.pop()
                                            text_before_link = ' '.join(words)
                                            if text_before_link and not text_before_link.endswith(('.', '!', '?')):
                                                text_before_link += "."
                            
                            # Reconstruir respuesta: texto antes del link + link al final
                            response = text_before_link.strip()
                            if text_after_link:
                                response += " " + text_after_link.strip()
                            
                            # Asegurar que termine con punto antes del link
                            if response and not response.endswith(('.', '!', '?', ':')):
                                response += "."
                        
                        # Remover patrones como [Link de Forms: https://...] si la IA los incluyera
                        response = re.sub(r'\[Link de Forms:?\s*', '', response)
                        response = re.sub(r'\]\s*', '', response)
                        
                        # Remover enlaces truncados (que terminan con ...)
                        response = re.sub(rf'{re.escape(forms_link[:20])}\.\.\.', '', response)
                        response = re.sub(r'https?://[^\s]+\.\.\.', '', response)
                        
                        # Si hay duplicados del link, consolidar
                        response = re.sub(rf'{re.escape(forms_link)}\s+{re.escape(forms_link)}', forms_link, response)
                        
                        # Verificar si la respuesta incluye el enlace completo
                        has_full_link = forms_link in response
                        
                        # Limpiar espacios m√∫ltiples (pero mantener saltos de l√≠nea)
                        response = re.sub(r'[ \t]+', ' ', response)  # Solo espacios horizontales
                        response = re.sub(r'\n\n\n+', '\n\n', response)  # M√°ximo 2 saltos de l√≠nea
                        response = response.strip()
                        
                        # Asegurar que el enlace est√© al final si existe, si no agregarlo
                        if has_full_link:
                            # Remover todas las ocurrencias del link del texto
                            response = response.replace(forms_link, '')
                            response = response.strip()
                            # Remover puntos o comas finales si est√°n solos
                            response = re.sub(r'[.,]+$', '.', response)
                            # Agregar el link al final
                            if not response.endswith(('.', '!', '?', ':')):
                                response += "."
                            response += f"\n\n{forms_link}"
                        else:
                            self.logger.warning(f"‚ö†Ô∏è La IA no incluy√≥ el enlace. Agreg√°ndolo ahora...")
                            # Si no incluye el enlace, agregarlo al final
                            # Asegurar que la √∫ltima oraci√≥n est√© completa
                            if response and not response.endswith(('.', '!', '?', ':')):
                                response += "."
                            response += f"\n\nPuedes solicitar materiales publicitarios aqu√≠: {forms_link}"
                        
                        if not response or len(response.strip()) < 10:
                            # Fallback si IA no genera buena respuesta
                            response = f"""¬°Perfecto! Te ayudo a solicitar materiales publicitarios de la campa√±a.

Puedes solicitar materiales publicitarios aqu√≠: {forms_link}

En el formulario podr√°s solicitar folletos, material de difusi√≥n y propaganda de {contact_name}. Si necesitas ayuda, preg√∫ntame."""
                    else:
                        self.logger.info(f"‚ö†Ô∏è Link de Forms NO disponible para tenant {tenant_id}")
                        # Generar respuesta con IA indicando que pronto estar√° disponible
                        prompt = f"""Genera una respuesta natural y amigable en espa√±ol para un chatbot de campa√±a pol√≠tica. El usuario quiere solicitar materiales publicitarios pero el sistema a√∫n no est√° disponible.

Informaci√≥n:
- Nombre del candidato: {contact_name}

Genera una respuesta breve que indique que el sistema para solicitar materiales estar√° disponible muy pronto, pero ofreciendo alternativas como contactar por WhatsApp o esperar a que el sistema est√© listo."""

                        response = await self._generate_quick_ai_response(prompt)
                        
                        if not response or len(response.strip()) < 10:
                            # Fallback si IA no genera buena respuesta
                            response = f"""¬°Hola! Me alegra tu inter√©s en solicitar materiales publicitarios de {contact_name}. 

El sistema para solicitar materiales estar√° disponible muy pronto. Mientras tanto, puedes contactarnos directamente por WhatsApp o esperar a que est√© listo.

¬øTe gustar√≠a que te notifique cuando el sistema est√© disponible?"""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de publicidad generada con IA ({processing_time:.4f}s)")
                    print(f"üéØ [PUBLICIDAD] Respuesta generada por IA")
                    
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True
                    }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando publicidad: {e}")
                    self.logger.exception(e)
            
            # ü§ù NUEVO: Manejar atencion_humano directamente (R√ÅPIDO)
            if intent == "atencion_humano":
                self.logger.info(f"ü§ù Intent es atencion_humano - procesando solicitud de atenci√≥n humana")
                print(f"üéØ [DEBUG] Intent detectado como atencion_humano")
                
                try:
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    brand_cfg = tenant_config.get("branding", {})
                    
                    # Llamar al handler de atenci√≥n humana
                    response = await self.base_ai_service._handle_human_assistance_request(
                        brand_cfg, tenant_config, user_context, ""
                    )
                    
                    processing_time = time.time() - start_time
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True,
                        "needs_human_assistance": user_context.get("_needs_human_assistance", False)
                    }
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando atencion_humano: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar actualizacion_datos directamente (R√ÅPIDO)
            if intent == "actualizacion_datos":
                self.logger.info(f"üîç Intent es actualizacion_datos - llamando al handler espec√≠fico")
                print(f"üéØ [DEBUG] Intent detectado como actualizacion_datos")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Llamar al handler del base_ai_service que maneja actualizacion_datos
                    self.logger.info(f"üìû Llamando a _handle_data_update_request desde optimized service")
                    result = await self.base_ai_service._handle_data_update_request(
                        query, user_context, "", tenant_id=tenant_id
                    )
                    
                    # El m√©todo retorna (response_message, update_data_dict)
                    if isinstance(result, tuple):
                        response, update_data = result
                        # Guardar datos para que Java los procese
                        if update_data:
                            user_context["data_to_update"] = update_data
                            self.logger.info(f"üìù Datos para actualizar: {update_data}")
                        
                        processing_time = time.time() - start_time
                        self.logger.info(f"‚úÖ Respuesta de actualizaci√≥n generada ({processing_time:.4f}s)")
                        
                        return {
                            "response": response,
                            "followup_message": "",
                            "from_cache": False,
                            "processing_time": processing_time,
                            "tenant_id": tenant_id,
                            "session_id": session_id,
                            "intent": intent,
                            "confidence": confidence,
                            "user_blocked": False,
                            "optimized": True,
                            "data_to_update": update_data  # Incluir datos para Java
                        }
                    else:
                        # Fallback si no retorna tupla
                        return {
                            "response": result if result else "Entiendo que quieres actualizar datos. Por favor, especifica qu√© informaci√≥n deseas cambiar.",
                            "followup_message": "",
                            "from_cache": False,
                            "processing_time": time.time() - start_time,
                            "tenant_id": tenant_id,
                            "session_id": session_id,
                            "intent": intent,
                            "confidence": confidence,
                            "optimized": True
                        }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando actualizacion_datos: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar colaboracion_voluntariado directamente (R√ÅPIDO)
            if intent == "colaboracion_voluntariado":
                self.logger.info(f"üîç Intent es colaboracion_voluntariado - generando respuesta con opciones de √°rea")
                print(f"üéØ [DEBUG] Intent detectado como colaboracion_voluntariado")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Generar respuesta con opciones de colaboraci√≥n
                    response = f"""¬°Excelente que quieras apoyarnos! {contact_name} valora mucho la colaboraci√≥n de personas comprometidas como t√∫.

¬øEn qu√© √°rea te gustar√≠a colaborar?

1. Redes sociales
2. Comunicaciones
3. Temas program√°ticos
4. Log√≠stica
5. Temas jur√≠dicos
6. Trabajo territorial
7. D√≠a de elecciones
8. Call center
9. Otro (¬øcu√°l?)

Elige una opci√≥n o cu√©ntame directamente en qu√© te gustar√≠a ayudar."""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de colaboracion generada ({processing_time:.4f}s)")
                    print(f"üéØ [COLABORACION] Respuesta generada")
                    
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True
                    }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando colaboracion: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar selecci√≥n de √°rea de colaboraci√≥n (R√ÅPIDO)
            if intent == "area_colaboracion_select":
                self.logger.info(f"üîç Intent es area_colaboracion_select - confirmando selecci√≥n de √°rea")
                print(f"üéØ [DEBUG] Intent detectado como area_colaboracion_select")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Extraer el √°rea de colaboraci√≥n del mensaje
                    area = self._extract_collaboration_area(query)
                    self.logger.info(f"üîç √Årea extra√≠da del mensaje: '{area}'")
                    print(f"üîç [AREA_SELECT] √Årea extra√≠da: '{area}'")
                    
                    # Mapear el √°rea a formato consistente
                    area_mapped = self._map_collaboration_area(area)
                    self.logger.info(f"üîç √Årea mapeada para BD: '{area_mapped}'")
                    print(f"üîç [AREA_SELECT] √Årea mapeada: '{area_mapped}'")
                    
                    # Generar respuesta de confirmaci√≥n
                    response = f"""¬°Perfecto! Has seleccionado: **{area.title()}**

Tu informaci√≥n ha sido registrada. {contact_name} y el equipo de campa√±a estar√°n en contacto contigo pronto para coordinar tu participaci√≥n en esta √°rea.

¬°Gracias por tu compromiso y por querer ser parte del cambio! üôå"""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de confirmaci√≥n de √°rea generada ({processing_time:.4f}s)")
                    print(f"üéØ [AREA_SELECT] Respuesta generada para √°rea: {area_mapped}")
                    self.logger.info(f"üéØ [AREA_SELECT] Enviando collaboration_area: '{area_mapped}' en respuesta")
                    print(f"üéØ [AREA_SELECT] collaboration_area que se enviar√°: '{area_mapped}'")
                    
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True,
                        "collaboration_area": area_mapped  # Informaci√≥n extra para que Java actualice el usuario
                    }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando selecci√≥n de √°rea: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar quejas directamente (R√ÅPIDO)
            if intent == "quejas":
                self.logger.info(f"üîç Intent es quejas - generando respuesta solicitando m√°s detalles")
                print(f"üéØ [DEBUG] Intent detectado como quejas")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Generar respuesta solicitando m√°s detalles
                    response = f"""Entiendo que tienes una inquietud o queja. Tu opini√≥n es muy importante para {contact_name} y queremos ayudarte.

Por favor, comp√°rteme m√°s detalles sobre tu queja o reclamo. Puedes contarme:
‚Ä¢ ¬øQu√© sucedi√≥?
‚Ä¢ ¬øCu√°ndo pas√≥?
‚Ä¢ ¬øQui√©n estuvo involucrado?

Describe tu situaci√≥n y con gusto te ayudar√© a resolverla o la transmitir√© al equipo correspondiente."""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de quejas generada ({processing_time:.4f}s)")
                    print(f"üéØ [QUEJAS] Respuesta generada")
                    
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True
                    }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando quejas: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar queja_detalle_select (R√ÅPIDO)
            print(f"üéØ [DEBUG PRE-QUEJA_DETALLE] Intent: '{intent}', ¬øEs queja_detalle_select? {intent == 'queja_detalle_select'}")
            if intent == "queja_detalle_select":
                self.logger.info(f"üîç Intent es queja_detalle_select - confirmando registro de queja")
                print(f"üéØ [DEBUG] Intent detectado como queja_detalle_select - ENTRANDO AL BLOQUE")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Generar respuesta de confirmaci√≥n
                    response = f"""Gracias por compartir los detalles de tu queja o reclamo. He registrado la informaci√≥n y la he enviado al equipo correspondiente de la campa√±a.

{contact_name} y su equipo tomar√°n cartas en el asunto para resolver tu inquietud lo antes posible.

Tu opini√≥n es muy valiosa para nosotros. ¬øHay algo m√°s en lo que pueda ayudarte?"""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de confirmaci√≥n de queja generada ({processing_time:.4f}s)")
                    print(f"üéØ [QUEJA_DETALLE] Respuesta generada")
                    
                    # üéØ Clasificar el tipo de queja bas√°ndose en el contenido del mensaje
                    complaint_type = self._classify_complaint_type(query)
                    
                    result_dict = {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True,
                        "complaint_registered": True,  # Informaci√≥n extra para que Java sepa que se registr√≥ la queja
                        "complaint_type": complaint_type  # Tipo de queja (servicio, atencion, tecnica, lentitud, etc.)
                    }
                    
                    print(f"üéØ [QUEJA_DETALLE] RESULTADO FINAL: {result_dict}")
                    self.logger.info(f"üéØ [QUEJA_DETALLE] Keys en resultado: {list(result_dict.keys())}")
                    self.logger.info(f"üéØ [QUEJA_DETALLE] complaint_registered: {result_dict.get('complaint_registered')}")
                    self.logger.info(f"üéØ [QUEJA_DETALLE] complaint_type: {complaint_type}")
                    
                    return result_dict
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando queja_detalle: {e}")
                    self.logger.exception(e)
            
            # 3. PROCESAR CON SERVICIO BASE (con timeout)
            self.logger.info(f"üìö [OPTIMIZED] Procesando con servicio base...")
            import asyncio
            
            # üîß FIX: Pasar historial en user_context en lugar de incluirlo en el query
            processing_user_context = user_context.copy() if user_context else {}
            processing_query = query
            
            if conversation_history:
                # Agregar historial al contexto para que est√© disponible en el prompt
                processing_user_context['conversation_history'] = conversation_history
                self.logger.info(f"üìö [OPTIMIZED] Agregando historial al user_context (NO al query)")
                self.logger.info(f"üìö [OPTIMIZED] Query puro: '{query}'")
            
            # üîç DEBUG CR√çTICO: Ver qu√© tenant_config vamos a pasar a base_ai_service
            self.logger.info(f"üîç [OPTIMIZED] PREPARANDO para llamar a base_ai_service con tenant_config keys: {list(tenant_config.keys()) if tenant_config else 'None'}")
            if tenant_config and 'numero_whatsapp' in tenant_config:
                self.logger.info(f"‚úÖ [OPTIMIZED] numero_whatsapp VA A PASARSE A base_ai_service: '{tenant_config['numero_whatsapp']}'")
            else:
                self.logger.warning(f"‚ùå [OPTIMIZED] numero_whatsapp NO VA A PASARSE A base_ai_service")
            
            try:
                result = await asyncio.wait_for(
                    self.base_ai_service.process_chat_message(
                        tenant_id, processing_query, processing_user_context, session_id, tenant_config
                    ),
                    timeout=optimization_config.AI_RESPONSE_TIMEOUT
                )
                
                # Agregar informaci√≥n de optimizaci√≥n al resultado
                result["intent"] = intent
                result["confidence"] = confidence
                result["optimized"] = True
                
                processing_time = time.time() - start_time
                result["processing_time"] = processing_time
                
                self.logger.info(f"‚úÖ [OPTIMIZED] Procesamiento completado en {processing_time:.2f}s")
                self.logger.info(f"‚úÖ [OPTIMIZED] INTENT FINAL: {intent} (confianza: {confidence})")
                
                return result
                
            except asyncio.TimeoutError:
                self.logger.error(f"‚è∞ Timeout generando respuesta (>10s) - retornando men√∫")
                # Retornar se√±al de timeout para que Java muestre men√∫
                processing_time = time.time() - start_time
                return {
                    "response": "",
                    "followup_message": "",
                    "from_cache": False,
                    "processing_time": processing_time,
                    "timeout": True,
                    "show_menu": True,
                    "menu_options": [
                        {"text": "¬øC√≥mo voy?", "payload": "como_voy"},
                        {"text": "Compartir mi link", "payload": "compartir_link"}
                    ],
                    "tenant_id": tenant_id,
                    "session_id": session_id,
                    "intent": intent,
                    "confidence": confidence,
                    "optimized": True
                }
            
        except Exception as e:
            self.logger.error(f"‚ùå [OPTIMIZED] Error en procesamiento optimizado: {str(e)}")
            self.logger.error(f"‚ùå [OPTIMIZED] Traceback: {e}", exc_info=True)
            
            # Fallback al servicio base
            self.logger.info(f"üîÑ [OPTIMIZED] Fallback al servicio base...")
            try:
                result = await self.base_ai_service.process_chat_message(
                    tenant_id, query, user_context, session_id, tenant_config
                )
                result["optimized"] = False  # Marcar como no optimizado
                return result
            except Exception as fallback_error:
                self.logger.error(f"‚ùå [OPTIMIZED] Error en fallback: {str(fallback_error)}")
                # Si todo falla, mostrar men√∫
                processing_time = time.time() - start_time
                return {
                    "response": "",
                    "followup_message": "",
                    "from_cache": False,
                    "processing_time": processing_time,
                    "timeout": True,
                    "show_menu": True,
                    "menu_options": [
                        {"text": "¬øC√≥mo voy?", "payload": "como_voy"},
                        {"text": "Compartir mi link", "payload": "compartir_link"}
                    ],
                    "tenant_id": tenant_id,
                    "session_id": session_id,
                    "optimized": True
                }
    
    def _extract_collaboration_area(self, message: str) -> str:
        """Extrae el √°rea de colaboraci√≥n del mensaje del usuario"""
        message_lower = message.lower().strip()
        
        # Mapeo de patrones a √°reas
        area_patterns = {
            "redes sociales": ["redes sociales", "redes", "1"],
            "comunicaciones": ["comunicaciones", "2"],
            "temas program√°ticos": ["temas program√°ticos", "programaticos", "3"],
            "log√≠stica": ["logistica", "log√≠stica", "4"],
            "temas jur√≠dicos": ["temas jur√≠dicos", "juridicos", "5"],
            "trabajo territorial": ["trabajo territorial", "territorial", "6"],
            "d√≠a de elecciones": ["dia de elecciones", "elecciones", "7"],
            "call center": ["call center", "callcenter", "8"],
            "otro": ["otro", "otra", "9"]
        }
        
        # Buscar coincidencias
        for area, patterns in area_patterns.items():
            for pattern in patterns:
                if pattern in message_lower:
                    return area
        
        # Si no encuentra nada espec√≠fico, retornar el mensaje original
        return message.strip()
    
    def _map_collaboration_area(self, area: str) -> str:
        """Mapea el √°rea a un formato consistente para la base de datos"""
        area_lower = area.lower().strip()
        
        # Mapeo a formato snake_case
        mapping = {
            "redes sociales": "redes_sociales",
            "comunicaciones": "comunicaciones",
            "temas program√°ticos": "temas_programaticos",
            "log√≠stica": "logistica",
            "logistica": "logistica",
            "temas jur√≠dicos": "temas_juridicos",
            "juridicos": "temas_juridicos",
            "trabajo territorial": "trabajo_territorial",
            "territorial": "trabajo_territorial",
            "d√≠a de elecciones": "dia_elecciones",
            "elecciones": "dia_elecciones",
            "call center": "call_center",
            "callcenter": "call_center",
            "otro": "otro"
        }
        
        return mapping.get(area_lower, "otro")
    
    def _get_tenant_config(self, tenant_id: str) -> Optional[Dict[str, Any]]:
        """Obtiene configuraci√≥n del tenant"""
        try:
            from chatbot_ai_service.services.configuration_service import configuration_service
            config = configuration_service.get_tenant_config(tenant_id)
            if config:
                self.logger.info(f"‚úÖ Configuraci√≥n obtenida para tenant {tenant_id}")
            else:
                self.logger.warning(f"‚ö†Ô∏è No se encontr√≥ configuraci√≥n para tenant {tenant_id}")
            return config
        except Exception as e:
            self.logger.error(f"Error obteniendo configuraci√≥n del tenant {tenant_id}: {str(e)}")
            return None
    
    
    async def _classify_intent_optimized(self, tenant_id: str, query: str, 
                                       user_context: Dict[str, Any]) -> Dict[str, Any]:
        """Clasifica intenci√≥n de forma optimizada"""
        try:
            self.logger.info(f"üéØ [CLASIFICACI√ìN] Iniciando clasificaci√≥n para: '{query[:50]}...'")
            self.logger.info(f"üéØ [CLASIFICACI√ìN] Tenant ID: {tenant_id}")
            
            # Usar el m√©todo de clasificaci√≥n del servicio base
            result = await self.base_ai_service.classify_intent(tenant_id, query, user_context)
            
            if result and result.get("category"):
                self.logger.info(f"‚úÖ [CLASIFICACI√ìN] Clasificaci√≥n exitosa: {result['category']} (confianza: {result.get('confidence', 0):.2f})")
                return result
            else:
                self.logger.warning("‚ö†Ô∏è [CLASIFICACI√ìN] Clasificaci√≥n fall√≥, usando fallback")
                return {"category": "saludo_apoyo", "confidence": 0.5}
                
        except Exception as e:
            self.logger.error(f"‚ùå [CLASIFICACI√ìN] Error en clasificaci√≥n: {str(e)}")
            return {"category": "saludo_apoyo", "confidence": 0.5}
    
    def _create_error_response(self, error_message: str, start_time: float) -> Dict[str, Any]:
        """Crea respuesta de error"""
        return {
            "response": f"Lo siento, {error_message.lower()}.",
            "followup_message": "",
            "processing_time": time.time() - start_time,
            "error": error_message,
            "optimized": True
        }
    
    async def _generate_quick_ai_response(self, prompt: str) -> str:
        """Genera respuesta r√°pida con IA usando Gemini directamente"""
        try:
            print(f"üîç DEBUG: _generate_quick_ai_response - Iniciando")
            import time as time_module
            start_gen = time_module.time()
            
            # Usar directamente el modelo Gemini del base_ai_service
            if hasattr(self.base_ai_service, 'model') and self.base_ai_service.model:
                response_obj = self.base_ai_service.model.generate_content(prompt)
                response = response_obj.text.strip()
            else:
                # Fallback: generar respuesta simple
                response = "¬°Hola! Bienvenido a la campa√±a. ¬øEn qu√© puedo ayudarte?"
            
            elapsed = time_module.time() - start_gen
            print(f"üîç DEBUG: _generate_quick_ai_response - Completado en {elapsed:.2f}s")
            
            if response:
                # Limitar longitud
                response = response.strip()
                if len(response) > 250:
                    last_space = response[:250].rfind(' ')
                    if last_space > 200:
                        response = response[:last_space]
                    else:
                        response = response[:247] + "..."
            
            return response if response else ""
            
        except Exception as e:
            print(f"üîç DEBUG: _generate_quick_ai_response - ERROR: {e}")
            self.logger.warning(f"‚ö†Ô∏è Error generando con IA: {e}")
            return ""
    
    def _classify_complaint_type(self, message: str) -> str:
        """Clasifica el tipo de queja bas√°ndose en el contenido del mensaje"""
        message_lower = message.lower()
        
        # Tipo 1: Lentitud / demoras
        if any(word in message_lower for word in ["demorado", "lento", "tarda", "demasiado", "tard√≠o", "retrasado"]):
            return "lentitud"
        
        # Tipo 2: Mala atenci√≥n
        if any(phrase in message_lower for phrase in ["mala atenci√≥n", "p√©sima atenci√≥n", "horrible atenci√≥n", "no hay buena atenci√≥n", "atenci√≥n deficiente"]):
            return "atencion"
        
        # Tipo 3: Problemas t√©cnicos
        if any(word in message_lower for word in ["no funciona", "no sirve", "error", "bug", "falla", "t√©cnico"]):
            return "tecnica"
        
        # Tipo 4: Calidad del servicio
        if any(phrase in message_lower for phrase in ["mal servicio", "servicio malo", "no se presta", "no presta", "p√©simo servicio", "horrible servicio"]):
            return "servicio"
        
        # Tipo 5: Problemas generales (fallback)
        if any(word in message_lower for word in ["malo", "mala", "mal", "deficiente", "terrible", "horrible", "p√©simo", "inadecuado"]):
            return "general"
        
        # Por defecto
        return "general"
