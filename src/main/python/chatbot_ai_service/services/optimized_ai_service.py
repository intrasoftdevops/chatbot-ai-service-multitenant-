"""
Servicio de IA optimizado con timeout y logging mejorado
"""
import logging
import time
from typing import Dict, Any, Optional
from chatbot_ai_service.config.optimization_config import optimization_config

logger = logging.getLogger(__name__)

class OptimizedAIService:
    """Servicio de IA optimizado con timeout y logging mejorado"""
    
    # Cache global de prompts cargados al arrancar
    _prompts_cache = {}
    
    def __init__(self, base_ai_service):
        self.base_ai_service = base_ai_service
        self.logger = logging.getLogger(__name__)
    
    async def process_chat_message_optimized(self, tenant_id: str, query: str, 
                                           user_context: Dict[str, Any], 
                                           session_id: str = None, 
                                           tenant_config: Dict[str, Any] = None,
                                           conversation_history: str = None) -> Dict[str, Any]:
        """
        Procesa mensaje de chat con optimizaciones simplificadas
        
        Args:
            tenant_id: ID del tenant
            query: Mensaje del usuario (SIN historial - solo para clasificaci√≥n)
            user_context: Contexto del usuario
            session_id: ID de la sesi√≥n
            tenant_config: Configuraci√≥n del tenant
            conversation_history: Historial de conversaci√≥n (para procesamiento, NO para clasificaci√≥n)
            
        Returns:
            Respuesta optimizada
        """
        print(f"üöÄ [OPTIMIZED] M√âTODO INICIADO - tenant: {tenant_id}, query: '{query[:50]}...'")
        self.logger.info(f"üöÄ [OPTIMIZED] M√âTODO INICIADO - tenant: {tenant_id}, query: '{query[:50]}...'")
        
        start_time = time.time()
        
        try:
            # 1. VERIFICAR CONFIGURACI√ìN DEL TENANT
            # üîç DEBUG CR√çTICO: Ver qu√© tenant_config estamos recibiendo
            if tenant_config:
                self.logger.info(f"‚úÖ [OPTIMIZED] tenant_config RECIBIDO - keys: {list(tenant_config.keys())}")
                if 'numero_whatsapp' in tenant_config:
                    self.logger.info(f"‚úÖ [OPTIMIZED] numero_whatsapp PRESENTE: '{tenant_config['numero_whatsapp']}'")
                else:
                    self.logger.warning(f"‚ùå [OPTIMIZED] numero_whatsapp NO PRESENTE en tenant_config")
            else:
                self.logger.warning(f"‚ö†Ô∏è No se recibi√≥ tenant_config en el request, obteniendo desde servicio Java...")
                tenant_config = self._get_tenant_config(tenant_id)
                if not tenant_config:
                    return self._create_error_response("Tenant no encontrado", start_time)
                # üîç DEBUG: Ver qu√© devolvi√≥ _get_tenant_config
                self.logger.info(f"‚úÖ [OPTIMIZED] tenant_config desde GET - keys: {list(tenant_config.keys())}")
                if 'numero_whatsapp' in tenant_config:
                    self.logger.info(f"‚úÖ [OPTIMIZED] numero_whatsapp desde GET: '{tenant_config['numero_whatsapp']}'")
                else:
                    self.logger.warning(f"‚ùå [OPTIMIZED] numero_whatsapp NO en tenant_config desde GET")
            
            # 2. CLASIFICAR INTENCI√ìN
            print(f"üéØ [OPTIMIZED] Clasificando intenci√≥n...")
            self.logger.info(f"üéØ [OPTIMIZED] Clasificando intenci√≥n...")
            try:
                intent_result = await self._classify_intent_optimized(tenant_id, query, user_context)
                intent = intent_result.get("category", "saludo_apoyo")
                confidence = intent_result.get("confidence", 0.0)
                
                # üìä IMPRIMIR CLASIFICACI√ìN DETALLADA
                print(f"üìä [CLASIFICACI√ìN] Mensaje: '{query[:100]}...'")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Mensaje: '{query[:100]}...'")
                print(f"üìä [CLASIFICACI√ìN] Categor√≠a: '{intent}'")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Categor√≠a: '{intent}'")
                print(f"üìä [CLASIFICACI√ìN] Confianza: {confidence:.2f}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Confianza: {confidence:.2f}")
                print(f"üìä [CLASIFICACI√ìN] Tenant: {tenant_id}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Tenant: {tenant_id}")
                print(f"üìä [CLASIFICACI√ìN] Session: {session_id}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] Session: {session_id}")
                print(f"üìä [CLASIFICACI√ìN] {'='*50}")
                self.logger.info(f"üìä [CLASIFICACI√ìN] {'='*50}")
                
                # üéØ DEBUG: Verificar si es saludo antes del bloque de malicia
                print(f"üéØ [DEBUG] Intent despu√©s de clasificaci√≥n: '{intent}'")
                print(f"üéØ [DEBUG] ¬øEs saludo_apoyo? {intent == 'saludo_apoyo'}")
                
                # üö´ PRIORIDAD CR√çTICA: Si es malicioso, BLOQUEAR INMEDIATAMENTE y NO procesar
                if intent == "malicioso":
                    self.logger.warning(f"üö´üö´üö´ MALICIA DETECTADA - BLOQUEANDO INMEDIATAMENTE")
                    self.logger.warning(f"üö´ Intent: '{intent}'")
                    self.logger.warning(f"üö´ Mensaje: '{query}'")
                    self.logger.warning(f"üö´ Confianza: {confidence:.2f}")
                    self.logger.warning(f"üö´ Tenant: {tenant_id}")
                    print(f"üö´üö´üö´ MALICIA DETECTADA EN PYTHON - BLOQUEANDO")
                    
                    # Obtener informaci√≥n del usuario para logging
                    user_id = user_context.get("user_id", "unknown")
                    phone_number = user_id if user_id != "unknown" else "unknown"
                    
                    self.logger.info(f"üîî Informaci√≥n de usuario para bloqueo:")
                    self.logger.info(f"   - user_id: {user_id}")
                    self.logger.info(f"   - phone_number: {phone_number}")
                    
                    # Importar el servicio de notificaci√≥n
                    from chatbot_ai_service.services.blocking_notification_service import BlockingNotificationService
                    
                    # Inicializar servicio de notificaci√≥n si no existe
                    if not hasattr(self.base_ai_service, 'blocking_notification_service') or not self.base_ai_service.blocking_notification_service:
                        blocking_service = BlockingNotificationService()
                        import os
                        java_url = os.getenv("POLITICAL_REFERRALS_SERVICE_URL", "http://localhost:8080")
                        blocking_service.set_java_service_url(java_url)
                        self.base_ai_service.blocking_notification_service = blocking_service
                    
                    # Notificar al servicio Java para bloquear en WATI
                    self.logger.info(f"üîî Enviando notificaci√≥n de bloqueo al servicio Java")
                    try:
                        notification_result = await self.base_ai_service.blocking_notification_service.notify_user_blocked(
                            tenant_id=tenant_id,
                            user_id=user_id,
                            phone_number=phone_number,
                            malicious_message=query,
                            classification_confidence=confidence
                        )
                        self.logger.info(f"üîî Resultado de notificaci√≥n: {notification_result}")
                        
                        if notification_result.get("success"):
                            self.logger.info(f"‚úÖ Usuario {user_id} bloqueado en WATI y base de datos")
                        else:
                            self.logger.error(f"‚ùå Error bloqueando usuario: {notification_result.get('error')}")
                    except Exception as notif_error:
                        self.logger.error(f"‚ùå Excepci√≥n notificando bloqueo: {str(notif_error)}")
                    
                    # NO enviar respuesta - bloquear silenciosamente
                    self.logger.warning(f"üö´ Usuario {user_id} bloqueado - NO enviando respuesta")
                    return {
                        "response": "",  # Respuesta vac√≠a = no responder
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": time.time() - start_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": "malicioso",
                        "confidence": confidence,
                        "user_blocked": True,
                        "optimized": True
                    }
            except Exception as classify_error:
                print(f"‚ùå [CLASIFICACI√ìN] ERROR EN CLASIFICACI√ìN: {classify_error}")
                self.logger.error(f"‚ùå [CLASIFICACI√ìN] ERROR EN CLASIFICACI√ìN: {classify_error}")
                self.logger.exception(classify_error)
                intent = "saludo_apoyo"
                confidence = 0.5
            
            # üöÄ ENFOQUE OPTIMIZADO: Variaciones pre-generadas para saludos (R√ÅPIDO)
            # Si es saludo, usar variaciones precargadas desde DB
            if intent == "saludo_apoyo":
                self.logger.info(f"üîç Intent es saludo_apoyo - usando variaciones pre-generadas")
                print(f"üéØ [DEBUG] Intent detectado como saludo_apoyo")
                print(f"üéØ [DEBUG] Tenants en cache: {list(OptimizedAIService._prompts_cache.keys())}")
                try:
                    # Obtener variaciones desde el cache global
                    cache_key = f'{tenant_id}_welcome_variations'
                    variations = OptimizedAIService._prompts_cache.get(cache_key, [])
                    print(f"üéØ [DEBUG] Cache key: {cache_key}")
                    print(f"üéØ [DEBUG] Variaciones encontradas: {len(variations)}")
                    print(f"üéØ [DEBUG] Variaciones: {variations}")
                    
                    if variations and len(variations) > 0:
                        # Seleccionar una variaci√≥n aleatoria
                        import random
                        selected_response = random.choice(variations)
                        
                        # Limpiar n√∫meros al inicio (ej: "2: texto" -> "texto")
                        import re
                        selected_response = re.sub(r'^\d+:\s*', '', selected_response).strip()
                        
                        # Personalizar con nombre del usuario si est√° disponible
                        session_context = user_context.get('session_context', {})
                        user_name = session_context.get('user_name') or session_context.get('name') or ""
                        
                        if user_name and "{user_name}" in selected_response:
                            selected_response = selected_response.replace("{user_name}", user_name)
                        
                        processing_time = time.time() - start_time
                        self.logger.info(f"‚úÖ Respuesta desde variaciones pre-generadas ({processing_time:.4f}s)")
                        print(f"üéØ [SALUDO] Variaci√≥n seleccionada: {selected_response[:100]}")
                        return {
                            "response": selected_response,
                            "followup_message": "",
                            "from_cache": True,
                            "processing_time": processing_time,
                            "tenant_id": tenant_id,
                            "session_id": session_id,
                            "intent": intent,
                            "confidence": confidence,
                            "user_blocked": False,
                            "optimized": True
                        }
                    else:
                        # Fallback si no hay variaciones
                        self.logger.warning(f"‚ö†Ô∏è No hay variaciones para tenant {tenant_id}")
                        return {
                            "response": "¬°Hola! Bienvenido a la campa√±a. ¬øEn qu√© puedo ayudarte?",
                            "followup_message": "",
                            "from_cache": False,
                            "processing_time": 0.001,
                            "tenant_id": tenant_id,
                            "session_id": session_id,
                            "intent": intent,
                            "confidence": confidence,
                            "optimized": True
                        }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando saludo: {e}")
                    self.logger.exception(e)
            
            # üéØ NUEVO: Manejar citas directamente (R√ÅPIDO)
            if intent == "cita_campa√±a":
                self.logger.info(f"üîç Intent es cita_campa√±a - generando respuesta con IA")
                print(f"üéØ [DEBUG] Intent detectado como cita_campa√±a")
                
                try:
                    # Obtener configuraci√≥n del tenant
                    if not tenant_config:
                        tenant_config = self._get_tenant_config(tenant_id)
                    
                    # Obtener branding y configuraci√≥n
                    branding_config = tenant_config.get("branding", {}) if tenant_config else {}
                    contact_name = branding_config.get("contactName", branding_config.get("contact_name", "el candidato"))
                    
                    # Obtener link de Calendly desde DB del tenant
                    calendly_link = tenant_config.get("link_calendly", "") if tenant_config else ""
                    
                    # Generar respuesta con IA basada en si hay link disponible o no
                    if calendly_link:
                        self.logger.info(f"‚úÖ Link de Calendly disponible: {calendly_link}")
                        # Generar respuesta con IA que incluya el link
                        prompt = f"""Genera una respuesta natural y amigable en espa√±ol para un chatbot de campa√±a pol√≠tica. El usuario quiere agendar una cita. 

Informaci√≥n:
- Nombre del candidato: {contact_name}
- Link de Calendly: {calendly_link}

Genera una respuesta breve, natural y conversacional que incluya el link de Calendly. La respuesta debe ser c√°lida y profesional, destacando que pueden agendar cita, conocerse con el candidato, hablar de oportunidades de voluntariado y coordenar actividades."""

                        response = await self._generate_quick_ai_response(prompt)
                        
                        # Verificar si la respuesta incluye el enlace
                        if calendly_link not in response:
                            self.logger.warning(f"‚ö†Ô∏è La IA no incluy√≥ el enlace. Agreg√°ndolo ahora...")
                            # Si no incluye el enlace, agregarlo al final
                            if not response.endswith('.'):
                                response += "."
                            response += f"\n\nPuedes reservar tu cita directamente aqu√≠: {calendly_link}"
                        
                        if not response or len(response.strip()) < 10:
                            # Fallback si IA no genera buena respuesta
                            response = f"""¬°Perfecto! Te ayudo a agendar una cita con alguien de la campa√±a.

Puedes reservar tu cita directamente aqu√≠: {calendly_link}

En la reuni√≥n podr√°s conocer m√°s sobre {contact_name}, hablar sobre oportunidades de voluntariado o coordinar actividades en tu regi√≥n. Si necesitas ayuda, preg√∫ntame."""
                    else:
                        self.logger.info(f"‚ö†Ô∏è Link de Calendly NO disponible para tenant {tenant_id}")
                        # Generar respuesta con IA indicando que pronto estar√° disponible
                        prompt = f"""Genera una respuesta natural y amigable en espa√±ol para un chatbot de campa√±a pol√≠tica. El usuario quiere agendar una cita pero el sistema de citas a√∫n no est√° disponible.

Informaci√≥n:
- Nombre del candidato: {contact_name}

Genera una respuesta breve que indique que el sistema de citas estar√° disponible muy pronto, pero ofreciendo alternativas como contactar por WhatsApp o esperar a que el sistema est√© listo."""

                        response = await self._generate_quick_ai_response(prompt)
                        
                        if not response or len(response.strip()) < 10:
                            # Fallback si IA no genera buena respuesta
                            response = f"""¬°Hola! Me alegra tu inter√©s en agendar una cita con {contact_name}. 

El sistema de citas estar√° disponible muy pronto. Mientras tanto, puedes contactarnos directamente por WhatsApp o esperar a que est√© listo.

¬øTe gustar√≠a que te notifique cuando el sistema de citas est√© disponible?"""
                    
                    processing_time = time.time() - start_time
                    self.logger.info(f"‚úÖ Respuesta de cita generada con IA ({processing_time:.4f}s)")
                    print(f"üéØ [CITA] Respuesta generada por IA")
                    
                    return {
                        "response": response,
                        "followup_message": "",
                        "from_cache": False,
                        "processing_time": processing_time,
                        "tenant_id": tenant_id,
                        "session_id": session_id,
                        "intent": intent,
                        "confidence": confidence,
                        "user_blocked": False,
                        "optimized": True
                    }
                        
                except Exception as e:
                    self.logger.warning(f"‚ö†Ô∏è Error procesando cita: {e}")
                    self.logger.exception(e)
            
            # 3. PROCESAR CON SERVICIO BASE (con timeout)
            self.logger.info(f"üìö [OPTIMIZED] Procesando con servicio base...")
            import asyncio
            
            # üîß FIX: Pasar historial en user_context en lugar de incluirlo en el query
            processing_user_context = user_context.copy() if user_context else {}
            processing_query = query
            
            if conversation_history:
                # Agregar historial al contexto para que est√© disponible en el prompt
                processing_user_context['conversation_history'] = conversation_history
                self.logger.info(f"üìö [OPTIMIZED] Agregando historial al user_context (NO al query)")
                self.logger.info(f"üìö [OPTIMIZED] Query puro: '{query}'")
            
            # üîç DEBUG CR√çTICO: Ver qu√© tenant_config vamos a pasar a base_ai_service
            self.logger.info(f"üîç [OPTIMIZED] PREPARANDO para llamar a base_ai_service con tenant_config keys: {list(tenant_config.keys()) if tenant_config else 'None'}")
            if tenant_config and 'numero_whatsapp' in tenant_config:
                self.logger.info(f"‚úÖ [OPTIMIZED] numero_whatsapp VA A PASARSE A base_ai_service: '{tenant_config['numero_whatsapp']}'")
            else:
                self.logger.warning(f"‚ùå [OPTIMIZED] numero_whatsapp NO VA A PASARSE A base_ai_service")
            
            try:
                result = await asyncio.wait_for(
                    self.base_ai_service.process_chat_message(
                        tenant_id, processing_query, processing_user_context, session_id, tenant_config
                    ),
                    timeout=optimization_config.AI_RESPONSE_TIMEOUT
                )
                
                # Agregar informaci√≥n de optimizaci√≥n al resultado
                result["intent"] = intent
                result["confidence"] = confidence
                result["optimized"] = True
                
                processing_time = time.time() - start_time
                result["processing_time"] = processing_time
                
                self.logger.info(f"‚úÖ [OPTIMIZED] Procesamiento completado en {processing_time:.2f}s")
                self.logger.info(f"‚úÖ [OPTIMIZED] INTENT FINAL: {intent} (confianza: {confidence})")
                
                return result
                
            except asyncio.TimeoutError:
                self.logger.error(f"‚è∞ Timeout generando respuesta (>10s) - retornando men√∫")
                # Retornar se√±al de timeout para que Java muestre men√∫
                processing_time = time.time() - start_time
                return {
                    "response": "",
                    "followup_message": "",
                    "from_cache": False,
                    "processing_time": processing_time,
                    "timeout": True,
                    "show_menu": True,
                    "menu_options": [
                        {"text": "¬øC√≥mo voy?", "payload": "como_voy"},
                        {"text": "Compartir mi link", "payload": "compartir_link"}
                    ],
                    "tenant_id": tenant_id,
                    "session_id": session_id,
                    "intent": intent,
                    "confidence": confidence,
                    "optimized": True
                }
            
        except Exception as e:
            self.logger.error(f"‚ùå [OPTIMIZED] Error en procesamiento optimizado: {str(e)}")
            self.logger.error(f"‚ùå [OPTIMIZED] Traceback: {e}", exc_info=True)
            
            # Fallback al servicio base
            self.logger.info(f"üîÑ [OPTIMIZED] Fallback al servicio base...")
            try:
                result = await self.base_ai_service.process_chat_message(
                    tenant_id, query, user_context, session_id, tenant_config
                )
                result["optimized"] = False  # Marcar como no optimizado
                return result
            except Exception as fallback_error:
                self.logger.error(f"‚ùå [OPTIMIZED] Error en fallback: {str(fallback_error)}")
                # Si todo falla, mostrar men√∫
                processing_time = time.time() - start_time
                return {
                    "response": "",
                    "followup_message": "",
                    "from_cache": False,
                    "processing_time": processing_time,
                    "timeout": True,
                    "show_menu": True,
                    "menu_options": [
                        {"text": "¬øC√≥mo voy?", "payload": "como_voy"},
                        {"text": "Compartir mi link", "payload": "compartir_link"}
                    ],
                    "tenant_id": tenant_id,
                    "session_id": session_id,
                    "optimized": True
                }
    
    def _get_tenant_config(self, tenant_id: str) -> Optional[Dict[str, Any]]:
        """Obtiene configuraci√≥n del tenant"""
        try:
            from chatbot_ai_service.services.configuration_service import configuration_service
            config = configuration_service.get_tenant_config(tenant_id)
            if config:
                self.logger.info(f"‚úÖ Configuraci√≥n obtenida para tenant {tenant_id}")
            else:
                self.logger.warning(f"‚ö†Ô∏è No se encontr√≥ configuraci√≥n para tenant {tenant_id}")
            return config
        except Exception as e:
            self.logger.error(f"Error obteniendo configuraci√≥n del tenant {tenant_id}: {str(e)}")
            return None
    
    
    async def _classify_intent_optimized(self, tenant_id: str, query: str, 
                                       user_context: Dict[str, Any]) -> Dict[str, Any]:
        """Clasifica intenci√≥n de forma optimizada"""
        try:
            self.logger.info(f"üéØ [CLASIFICACI√ìN] Iniciando clasificaci√≥n para: '{query[:50]}...'")
            self.logger.info(f"üéØ [CLASIFICACI√ìN] Tenant ID: {tenant_id}")
            
            # Usar el m√©todo de clasificaci√≥n del servicio base
            result = await self.base_ai_service.classify_intent(tenant_id, query, user_context)
            
            if result and result.get("category"):
                self.logger.info(f"‚úÖ [CLASIFICACI√ìN] Clasificaci√≥n exitosa: {result['category']} (confianza: {result.get('confidence', 0):.2f})")
                return result
            else:
                self.logger.warning("‚ö†Ô∏è [CLASIFICACI√ìN] Clasificaci√≥n fall√≥, usando fallback")
                return {"category": "saludo_apoyo", "confidence": 0.5}
                
        except Exception as e:
            self.logger.error(f"‚ùå [CLASIFICACI√ìN] Error en clasificaci√≥n: {str(e)}")
            return {"category": "saludo_apoyo", "confidence": 0.5}
    
    def _create_error_response(self, error_message: str, start_time: float) -> Dict[str, Any]:
        """Crea respuesta de error"""
        return {
            "response": f"Lo siento, {error_message.lower()}.",
            "followup_message": "",
            "processing_time": time.time() - start_time,
            "error": error_message,
            "optimized": True
        }
    
    async def _generate_quick_ai_response(self, prompt: str) -> str:
        """Genera respuesta r√°pida con IA usando Gemini directamente"""
        try:
            print(f"üîç DEBUG: _generate_quick_ai_response - Iniciando")
            import time as time_module
            start_gen = time_module.time()
            
            # Usar directamente el modelo Gemini del base_ai_service
            if hasattr(self.base_ai_service, 'model') and self.base_ai_service.model:
                response_obj = self.base_ai_service.model.generate_content(prompt)
                response = response_obj.text.strip()
            else:
                # Fallback: generar respuesta simple
                response = "¬°Hola! Bienvenido a la campa√±a. ¬øEn qu√© puedo ayudarte?"
            
            elapsed = time_module.time() - start_gen
            print(f"üîç DEBUG: _generate_quick_ai_response - Completado en {elapsed:.2f}s")
            
            if response:
                # Limitar longitud
                response = response.strip()
                if len(response) > 250:
                    last_space = response[:250].rfind(' ')
                    if last_space > 200:
                        response = response[:last_space]
                    else:
                        response = response[:247] + "..."
            
            return response if response else ""
            
        except Exception as e:
            print(f"üîç DEBUG: _generate_quick_ai_response - ERROR: {e}")
            self.logger.warning(f"‚ö†Ô∏è Error generando con IA: {e}")
            return ""
