"""
Servicio de cach√© para respuestas de IA usando Redis

Este servicio proporciona:
- Cach√© de respuestas por tenant + query + intent
- TTL configurable por tipo de intenci√≥n
- Invalidaci√≥n de cach√© por tenant
- Estad√≠sticas de hit rate
- Fallback graceful si Redis no est√° disponible
"""

import hashlib
import json
import logging
from typing import Optional, Dict, Any
import os

logger = logging.getLogger(__name__)

class CacheService:
    """Servicio de cach√© para respuestas de IA"""
    
    def __init__(self):
        # üöÄ OPTIMIZACI√ìN CR√çTICA: Habilitar Redis por defecto para mejor rendimiento
        self.enabled = os.getenv("REDIS_ENABLED", "true").lower() == "true"
        self.client = None
        
        if self.enabled:
            try:
                import redis
                self.client = redis.Redis(
                    host=os.getenv("REDIS_HOST", "localhost"),
                    port=int(os.getenv("REDIS_PORT", "6379")),
                    db=int(os.getenv("REDIS_DB", "0")),
                    password=os.getenv("REDIS_PASSWORD", None) if os.getenv("REDIS_PASSWORD") else None,
                    decode_responses=True,
                    socket_connect_timeout=1,  # Reducido para conexi√≥n m√°s r√°pida
                    socket_timeout=1,          # Reducido para operaciones m√°s r√°pidas
                    retry_on_timeout=True,     # Reintentar en timeout
                    health_check_interval=30   # Verificar salud cada 30 segundos
                )
                # Test connection
                self.client.ping()
                logger.info("‚úÖ Redis conectado exitosamente - Cach√© habilitado para mejor rendimiento")
            except ImportError:
                logger.warning("‚ö†Ô∏è Redis no instalado, usando cach√© en memoria")
                self.enabled = False
                self._memory_cache = {}  # Fallback a cach√© en memoria
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Redis no disponible: {e}, usando cach√© en memoria")
                self.enabled = False
                self._memory_cache = {}  # Fallback a cach√© en memoria
        else:
            logger.info("‚ÑπÔ∏è Cach√© Redis deshabilitado, usando cach√© en memoria")
            self._memory_cache = {}  # Fallback a cach√© en memoria
    
    def _generate_cache_key(self, tenant_id: str, query: str, intent: str = None) -> str:
        """
        Genera una key √∫nica para el cach√©
        
        Args:
            tenant_id: ID del tenant
            query: Query del usuario
            intent: Intenci√≥n clasificada (opcional)
            
        Returns:
            Key √∫nica para Redis
        """
        # Normalizar query (lowercase, trim, remover espacios extras)
        normalized_query = ' '.join(query.lower().strip().split())
        
        # Crear hash para queries largas (>100 chars)
        if len(normalized_query) > 100:
            query_hash = hashlib.md5(normalized_query.encode()).hexdigest()
            key_parts = [tenant_id, intent or "general", query_hash]
        else:
            # Para queries cortas, usar directamente
            key_parts = [tenant_id, intent or "general", normalized_query]
        
        return f"chat_response:{':'.join(key_parts)}"
    
    def get_cached_response(
        self, 
        tenant_id: str, 
        query: str, 
        intent: str = None
    ) -> Optional[Dict[str, Any]]:
        """
        Obtiene una respuesta del cach√©
        
        Args:
            tenant_id: ID del tenant
            query: Query del usuario
            intent: Intenci√≥n clasificada
            
        Returns:
            Respuesta cacheada o None si no existe
        """
        if not self.enabled:
            return None
        
        try:
            key = self._generate_cache_key(tenant_id, query, intent)
            cached = self.client.get(key)
            
            if cached:
                logger.info(f"‚úÖ Cache HIT para tenant {tenant_id} | intent={intent}")
                return json.loads(cached)
            
            logger.debug(f"‚ùå Cache MISS para tenant {tenant_id} | intent={intent}")
            return None
            
        except Exception as e:
            logger.error(f"Error obteniendo del cach√©: {e}")
            return None
    
    def cache_response(
        self,
        tenant_id: str,
        query: str,
        response: Dict[str, Any],
        intent: str = None,
        ttl: int = None
    ):
        """
        Guarda una respuesta en cach√©
        
        Args:
            tenant_id: ID del tenant
            query: Query del usuario
            response: Respuesta a cachear
            intent: Intenci√≥n clasificada
            ttl: Time to live en segundos (opcional)
        """
        if not self.enabled:
            return
        
        try:
            key = self._generate_cache_key(tenant_id, query, intent)
            
            # TTL por tipo de intenci√≥n
            if ttl is None:
                ttl = self._get_ttl_for_intent(intent)
            
            # No cachear si TTL es 0
            if ttl == 0:
                logger.debug(f"‚è≠Ô∏è No cacheando intent={intent} (TTL=0)")
                return
            
            self.client.setex(
                key,
                ttl,
                json.dumps(response, ensure_ascii=False)
            )
            
            logger.debug(f"üíæ Respuesta cacheada para tenant {tenant_id} | intent={intent} | TTL={ttl}s")
            
        except Exception as e:
            logger.error(f"Error guardando en cach√©: {e}")
    
    def _get_ttl_for_intent(self, intent: str) -> int:
        """
        Determina el TTL seg√∫n el tipo de intenci√≥n
        
        Args:
            intent: Tipo de intenci√≥n
            
        Returns:
            TTL en segundos
        """
        ttl_map = {
            # Informaci√≥n est√°tica - cachear por m√°s tiempo
            "conocer_candidato": 3600,          # 1 hora
            "saludo_apoyo": 1800,               # 30 min
            "colaboracion_voluntariado": 1800,  # 30 min
            
            # Informaci√≥n semi-est√°tica
            "cita_campa√±a": 900,                # 15 min
            "solicitud_funcional": 600,         # 10 min
            
            # No cachear - requieren atenci√≥n personalizada
            "quejas": 0,
            "malicioso": 0,
            "atencion_humano": 0,
            "atencion_equipo_interno": 0,
            "registration_response": 0,
            "actualizacion_datos": 0,
        }
        
        return ttl_map.get(intent, 600)  # Default: 10 min
    
    def invalidate_tenant_cache(self, tenant_id: str):
        """
        Invalida todo el cach√© de un tenant
        
        Args:
            tenant_id: ID del tenant
        """
        if not self.enabled:
            return
        
        try:
            pattern = f"chat_response:{tenant_id}:*"
            keys = list(self.client.scan_iter(match=pattern))
            
            if keys:
                self.client.delete(*keys)
                logger.info(f"üóëÔ∏è Cache invalidado para tenant {tenant_id} ({len(keys)} keys)")
            else:
                logger.debug(f"‚ÑπÔ∏è No hay cache para invalidar en tenant {tenant_id}")
                
        except Exception as e:
            logger.error(f"Error invalidando cach√©: {e}")
    
    def invalidate_intent_cache(self, tenant_id: str, intent: str):
        """
        Invalida el cach√© de un intent espec√≠fico de un tenant
        
        Args:
            tenant_id: ID del tenant
            intent: Intenci√≥n a invalidar
        """
        if not self.enabled:
            return
        
        try:
            pattern = f"chat_response:{tenant_id}:{intent}:*"
            keys = list(self.client.scan_iter(match=pattern))
            
            if keys:
                self.client.delete(*keys)
                logger.info(f"üóëÔ∏è Cache invalidado para tenant {tenant_id} | intent={intent} ({len(keys)} keys)")
                
        except Exception as e:
            logger.error(f"Error invalidando cach√© de intent: {e}")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """
        Obtiene estad√≠sticas del cach√©
        
        Returns:
            Diccionario con estad√≠sticas
        """
        if not self.enabled:
            return {"enabled": False}
        
        try:
            info = self.client.info("stats")
            hits = info.get("keyspace_hits", 0)
            misses = info.get("keyspace_misses", 0)
            total = hits + misses
            
            hit_rate = round((hits / total) * 100, 2) if total > 0 else 0.0
            
            return {
                "enabled": True,
                "hits": hits,
                "misses": misses,
                "total_requests": total,
                "hit_rate_percent": hit_rate
            }
        except Exception as e:
            logger.error(f"Error obteniendo stats: {e}")
            return {"enabled": True, "error": str(e)}
    
    def clear_all_cache(self):
        """Limpia todo el cach√© (usar con precauci√≥n)"""
        if not self.enabled:
            return
        
        try:
            pattern = "chat_response:*"
            keys = list(self.client.scan_iter(match=pattern))
            
            if keys:
                self.client.delete(*keys)
                logger.warning(f"üóëÔ∏è TODO el cache limpiado ({len(keys)} keys)")
                
        except Exception as e:
            logger.error(f"Error limpiando todo el cach√©: {e}")


# Instancia global
cache_service = CacheService()

