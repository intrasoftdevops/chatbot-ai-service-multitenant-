"""
Servicio de IA simplificado para el Chatbot AI Service

Este servicio se enfoca √∫nicamente en procesamiento de IA y recibe
la configuraci√≥n del proyecto Political Referrals via HTTP.
"""
import logging
import time
import os
from typing import Dict, Any, Optional

import google.generativeai as genai
import httpx
from chatbot_ai_service.services.configuration_service import configuration_service
from chatbot_ai_service.services.document_context_service import document_context_service
from chatbot_ai_service.services.session_context_service import session_context_service
from chatbot_ai_service.services.blocking_notification_service import BlockingNotificationService
from chatbot_ai_service.services.cache_service import cache_service

logger = logging.getLogger(__name__)

class AIService:
    """Servicio de IA simplificado - solo procesamiento de IA"""
    
    def __init__(self):
        self.model = None
        self._initialized = False
        # Rate limiting: m√°ximo 15 requests por minuto para evitar exceder cuota
        self.request_times = []
        self.max_requests_per_minute = 15
        # Cola de requests para manejar alta carga
        self.request_queue = []
        self.processing_queue = False
        self.api_key = None
        # Servicio para notificar bloqueos
        self.blocking_notification_service = BlockingNotificationService()
        # Configurar URL del servicio Java
        self.blocking_notification_service.set_java_service_url("http://localhost:8080")
        
        # üöÄ FASE 1: Feature flag para usar GeminiClient
        # Permite migraci√≥n gradual sin romper funcionalidad existente
        self.use_gemini_client = os.getenv("USE_GEMINI_CLIENT", "f").lower() == "true"
        self.gemini_client = None
        
        if self.use_gemini_client:
            try:
                from chatbot_ai_service.clients.gemini_client import GeminiClient
                self.gemini_client = GeminiClient()
                logger.info("‚úÖ GeminiClient habilitado via feature flag USE_GEMINI_CLIENT=true")
            except Exception as e:
                logger.error(f"‚ùå Error inicializando GeminiClient: {e}")
                logger.warning("‚ö†Ô∏è Usando l√≥gica original de AIService como fallback")
                self.use_gemini_client = False
        
        # üöÄ FASE 2: Feature flag para usar configuraciones avanzadas por tarea
        # Permite optimizar temperatura, top_p, etc. seg√∫n el tipo de tarea
        self.use_advanced_model_configs = os.getenv("USE_ADVANCED_MODEL_CONFIGS", "false").lower() == "true"
        
        if self.use_advanced_model_configs and self.use_gemini_client:
            logger.info("‚úÖ Configuraciones avanzadas de modelo habilitadas (USE_ADVANCED_MODEL_CONFIGS=true)")
        elif self.use_advanced_model_configs and not self.use_gemini_client:
            logger.warning("‚ö†Ô∏è USE_ADVANCED_MODEL_CONFIGS=true pero USE_GEMINI_CLIENT=false. Las configs avanzadas requieren GeminiClient.")
            self.use_advanced_model_configs = False
        
        # üöÄ FASE 6: Feature flag para usar RAGOrchestrator
        # Habilita el sistema completo de RAG con b√∫squeda h√≠brida y verificaci√≥n
        self.use_rag_orchestrator = os.getenv("USE_RAG_ORCHESTRATOR", "false").lower() == "true"
        self.rag_orchestrator = None
        
        # üõ°Ô∏è FASE 5: Feature flag para guardrails estrictos
        # Habilita prompts especializados y verificaci√≥n estricta de respuestas
        self.use_guardrails = os.getenv("USE_GUARDRAILS", "true").lower() == "true"
        self.strict_guardrails = os.getenv("STRICT_GUARDRAILS", "true").lower() == "true"
        
        if self.use_rag_orchestrator:
            if not self.use_gemini_client:
                logger.warning("‚ö†Ô∏è USE_RAG_ORCHESTRATOR=true pero USE_GEMINI_CLIENT=false. RAG requiere GeminiClient.")
                self.use_rag_orchestrator = False
            else:
                try:
                    from chatbot_ai_service.orchestrators.rag_orchestrator import RAGOrchestrator
                    self.rag_orchestrator = RAGOrchestrator(
                        gemini_client=self.gemini_client,
                        document_service=document_context_service,
                        enable_verification=True,
                        enable_citations=True,
                        enable_guardrails=self.use_guardrails,
                        strict_guardrails=self.strict_guardrails
                    )
                    logger.info(
                        f"‚úÖ RAGOrchestrator habilitado (USE_RAG_ORCHESTRATOR=true) "
                        f"con guardrails={'ON' if self.use_guardrails else 'OFF'}"
                    )
                except Exception as e:
                    logger.error(f"‚ùå Error inicializando RAGOrchestrator: {e}")
                    logger.warning("‚ö†Ô∏è Usando l√≥gica original sin RAG")
                    self.use_rag_orchestrator = False
        
        # üìä Log resumen de features activadas
        features_status = {
            "GeminiClient": "‚úÖ" if self.use_gemini_client else "‚ùå",
            "Advanced Configs": "‚úÖ" if self.use_advanced_model_configs else "‚ùå",
            "RAG Orchestrator": "‚úÖ" if self.use_rag_orchestrator else "‚ùå",
            "Guardrails": "‚úÖ" if self.use_guardrails else "‚ùå",
            "Strict Guardrails": "‚úÖ" if self.strict_guardrails else "‚ùå"
        }
        logger.info(f"üéõÔ∏è AIService inicializado | Features: {features_status}")
    
    def _check_rate_limit(self):
        """Verifica y aplica rate limiting para evitar exceder cuota de API"""
        current_time = time.time()
        
        # Limpiar requests antiguos (m√°s de 1 minuto)
        self.request_times = [t for t in self.request_times if current_time - t < 60]
        
        # Si hemos excedido el l√≠mite, esperar
        if len(self.request_times) >= self.max_requests_per_minute:
            sleep_time = 60 - (current_time - self.request_times[0])
            if sleep_time > 0:
                logger.warning(f"Rate limit alcanzado. Esperando {sleep_time:.1f} segundos...")
                time.sleep(sleep_time)
                # Limpiar la lista despu√©s de esperar
                self.request_times = []
        
        # Registrar este request
        self.request_times.append(current_time)
    
    def _should_use_fallback(self) -> bool:
        """Determina si debemos usar fallback por alta carga o cuota excedida"""
        current_time = time.time()
        
        # Si tenemos muchos requests recientes, usar fallback
        recent_requests = [t for t in self.request_times if current_time - t < 60]
        if len(recent_requests) >= self.max_requests_per_minute * 0.9:  # 90% de la cuota (13.5 requests)
            logger.warning(f"Alta carga detectada: {len(recent_requests)} requests en el √∫ltimo minuto")
            return True
        
        # Si la cola est√° muy llena, usar fallback
        if len(self.request_queue) > 200:  # Aumentar umbral de cola
            logger.warning(f"Cola llena detectada: {len(self.request_queue)} requests en cola")
            return True
            
        return False
    
    def _get_fallback_response(self, prompt: str) -> str:
        """Genera respuesta de fallback inteligente sin usar IA"""
        # Analizar el prompt para dar respuesta contextual
        prompt_lower = prompt.lower()
        
        if "nombre" in prompt_lower or "llamo" in prompt_lower:
            return "Por favor, comparte tu nombre completo para continuar con el registro."
        elif "ciudad" in prompt_lower or "vives" in prompt_lower:
            return "¬øEn qu√© ciudad vives? Esto nos ayuda a conectar con promotores de tu regi√≥n."
        elif "apellido" in prompt_lower:
            return "Perfecto, ahora necesito tu apellido para completar tu informaci√≥n."
        elif "c√≥digo" in prompt_lower or "referido" in prompt_lower:
            return "Si tienes un c√≥digo de referido, comp√°rtelo. Si no, escribe 'no' para continuar."
        elif "t√©rminos" in prompt_lower or "condiciones" in prompt_lower:
            return "¬øAceptas los t√©rminos y condiciones? Responde 's√≠' o 'no'."
        elif "confirmar" in prompt_lower or "correcto" in prompt_lower:
            return "¬øConfirmas que esta informaci√≥n es correcta? Responde 's√≠' o 'no'."
        else:
            return "Gracias por tu mensaje. Te ayudo a completar tu registro paso a paso."
    
    def _get_general_fallback_response(self, prompt: str, tenant_config: dict = None) -> str:
        """Genera respuesta de fallback para conversaciones generales (usuarios registrados)"""
        prompt_lower = prompt.lower()
        
        # Obtener informaci√≥n del tenant para respuestas personalizadas
        contact_name = "Daniel Quintero Presidente"
        if tenant_config and tenant_config.get("branding", {}).get("contact_name"):
            contact_name = tenant_config["branding"]["contact_name"]
        
        # Categor√≠as de respuestas de fallback
        if any(word in prompt_lower for word in ["hola", "hi", "hello", "buenos d√≠as", "buenas tardes"]):
            return f"¬°Hola! Soy el asistente de {contact_name}. ¬øEn qu√© puedo ayudarte hoy?"
        
        elif any(word in prompt_lower for word in ["c√≥mo", "como", "funciona", "trabaja"]):
            return f"Te explico c√≥mo funciona: Somos la campa√±a de {contact_name}. Puedes registrarte como promotor, ganar puntos por referir personas y participar en nuestro ranking. ¬øTe gustar√≠a registrarte?"
        
        elif any(word in prompt_lower for word in ["puntos", "puntaje", "ranking", "posici√≥n"]):
            return "Los puntos se ganan refiriendo personas a la campa√±a. Cada referido te da puntos que se suman a tu ranking. ¬°Mientras m√°s refieras, m√°s alto est√°s en la lista!"
        
        elif any(word in prompt_lower for word in ["referir", "referido", "invitar", "compartir"]):
            return "Para referir personas, comparte tu c√≥digo √∫nico con amigos y familiares. Cuando se registren con tu c√≥digo, ambos ganan puntos. ¬°Es muy f√°cil!"
        
        elif any(word in prompt_lower for word in ["c√≥digo", "mi c√≥digo", "c√≥digo personal"]):
            return "Tu c√≥digo personal es √∫nico y te identifica como promotor. Lo puedes compartir con otras personas para que se registren y ambos ganen puntos."
        
        elif any(word in prompt_lower for word in ["premio", "ganar", "ganancia", "recompensa"]):
            return "Los promotores m√°s activos pueden ganar premios y reconocimientos especiales. ¬°Mientras m√°s personas refieras, m√°s oportunidades tienes de ganar!"
        
        elif any(word in prompt_lower for word in ["ayuda", "help", "soporte", "problema"]):
            return f"Estoy aqu√≠ para ayudarte. Puedo explicarte c√≥mo funciona la campa√±a, ayudarte con tu registro, o resolver dudas sobre puntos y referidos. ¬øQu√© necesitas saber?"
        
        elif any(word in prompt_lower for word in ["horario", "hora", "cu√°ndo", "cuando", "disponible"]):
            return "Estoy disponible 24/7 para ayudarte. Puedes escribirme en cualquier momento y te responder√© lo m√°s pronto posible."
        
        elif any(word in prompt_lower for word in ["contacto", "tel√©fono", "telefono", "email", "correo"]):
            return f"Para contacto directo, puedes comunicarte con el equipo de {contact_name}. Tambi√©n puedes seguirnos en nuestras redes sociales oficiales."
        
        elif any(word in prompt_lower for word in ["gracias", "thank", "thanks", "agradecido"]):
            return f"¬°De nada! Es un placer ayudarte. Recuerda que puedes escribirme cuando necesites ayuda con la campa√±a de {contact_name}."
        
        elif any(word in prompt_lower for word in ["adi√≥s", "adios", "bye", "hasta luego", "nos vemos"]):
            return f"¬°Hasta luego! Fue un gusto ayudarte. ¬°Que tengas un excelente d√≠a y sigue promoviendo la campa√±a de {contact_name}!"
        
        elif any(word in prompt_lower for word in ["informaci√≥n", "info", "datos", "sobre"]):
            return f"Te puedo ayudar con informaci√≥n sobre la campa√±a de {contact_name}, c√≥mo ganar puntos, referir personas, y todo lo relacionado con ser promotor. ¬øQu√© te interesa saber?"
        
        elif any(word in prompt_lower for word in ["registro", "registrarme", "unirme", "participar"]):
            return "¬°Excelente! Para registrarte como promotor, necesito algunos datos b√°sicos: tu nombre completo, ciudad donde vives, y si tienes un c√≥digo de referido. ¬øEmpezamos?"
        
        elif any(word in prompt_lower for word in ["estado", "mi estado", "progreso", "avance"]):
            return "Para ver tu estado actual, puntos y posici√≥n en el ranking, necesito verificar tu informaci√≥n. ¬øYa est√°s registrado como promotor?"
        
        else:
            return f"Entiendo tu mensaje. Estoy aqu√≠ para ayudarte con todo lo relacionado con la campa√±a de {contact_name}. ¬øHay algo espec√≠fico en lo que pueda asistirte?"
    
    def _ensure_model_initialized(self):
        """Inicializa el modelo de forma lazy"""
        if self._initialized:
            return
            
        self.api_key = os.getenv("GEMINI_API_KEY")
        if self.api_key:
            try:
                # Configuraci√≥n b√°sica para Gemini AI
                genai.configure(api_key=self.api_key)
                self.model = genai.GenerativeModel('gemini-2.5-flash')
                logger.info("Modelo Gemini inicializado correctamente")
            except Exception as e:
                logger.error(f"Error inicializando modelo Gemini: {str(e)}")
                self.model = None
        else:
            logger.warning("GEMINI_API_KEY no configurado")
            self.model = None
            
        self._initialized = True
    
    async def _call_gemini_rest_api(self, prompt: str) -> str:
        """Llama a Gemini usando REST API en lugar de gRPC"""
        try:
            url = f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent?key={self.api_key}"
            
            payload = {
                "contents": [{
                    "parts": [{
                        "text": prompt
                    }]
                }]
            }
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(url, json=payload)
                response.raise_for_status()
                
                result = response.json()
                if 'candidates' in result and len(result['candidates']) > 0:
                    return result['candidates'][0]['content']['parts'][0]['text']
                else:
                    return "No se pudo generar respuesta"
                    
        except Exception as e:
            logger.error(f"Error llamando a Gemini REST API: {str(e)}")
            return f"Error: {str(e)}"
    
    async def _generate_content(self, prompt: str, task_type: str = "chat_conversational") -> str:
        """
        Genera contenido usando Gemini, fallback a REST API si gRPC falla
        
        Args:
            prompt: Texto a enviar a Gemini
            task_type: Tipo de tarea para configuraci√≥n optimizada (Fase 2)
        
        Returns:
            Respuesta generada por Gemini
        """
        
        # üöÄ FASE 1 + 2: Delegar a GeminiClient si est√° habilitado
        if self.use_gemini_client and self.gemini_client:
            try:
                # Usar configuraciones avanzadas si est√°n habilitadas (Fase 2)
                use_custom_config = self.use_advanced_model_configs
                
                if use_custom_config:
                    logger.debug(f"üîÑ Delegando a GeminiClient con task_type='{task_type}'")
                else:
                    logger.debug("üîÑ Delegando generaci√≥n de contenido a GeminiClient")
                
                return await self.gemini_client.generate_content(
                    prompt, 
                    task_type=task_type,
                    use_custom_config=use_custom_config
                )
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è GeminiClient fall√≥, usando l√≥gica original: {e}")
                # Continuar con l√≥gica original como fallback
        
        # MANTENER: L√≥gica original completa como fallback
        # Verificar si debemos usar fallback por alta carga
        if self._should_use_fallback():
            logger.info("Alta carga detectada, usando fallback inteligente")
            return self._get_fallback_response(prompt)
        
        # Aplicar rate limiting
        self._check_rate_limit()
        
        # Log del estado actual para debugging
        current_time = time.time()
        recent_requests = [t for t in self.request_times if current_time - t < 60]
        logger.debug(f"Estado de requests: {len(recent_requests)}/{self.max_requests_per_minute} en el √∫ltimo minuto")
        
        try:
            # Intentar con gRPC primero
            if self.model:
                response = self.model.generate_content(prompt)
                return response.text
        except Exception as e:
            logger.warning(f"gRPC fall√≥, usando REST API: {str(e)}")
        
        # Fallback a REST API
        return await self._call_gemini_rest_api(prompt)
    
    async def process_chat_message(self, tenant_id: str, query: str, user_context: Dict[str, Any], session_id: str = None) -> Dict[str, Any]:
        """
        Procesa un mensaje de chat usando IA espec√≠fica del tenant con sesi√≥n persistente y clasificaci√≥n
        
        Args:
            tenant_id: ID del tenant
            query: Mensaje del usuario
            user_context: Contexto del usuario
            session_id: ID de la sesi√≥n para mantener contexto
            
        Returns:
            Respuesta procesada por IA
        """
        start_time = time.time()
        
        try:
            logger.info(f"Procesando mensaje para tenant {tenant_id}, sesi√≥n: {session_id}")
            
            # VERIFICAR SI EL USUARIO EST√Å BLOQUEADO PRIMERO
            user_state = user_context.get("user_state", "")
            if user_state == "BLOCKED":
                logger.warn(f"üö´ Usuario bloqueado intentando enviar mensaje: {user_context.get('user_id', 'unknown')}")
                return {
                    "response": "",  # No responder nada a usuarios bloqueados
                    "processing_time": time.time() - start_time,
                    "tenant_id": tenant_id,
                    "session_id": session_id,
                    "intent": "blocked_user",
                    "confidence": 1.0
                }
            
            # Obtener configuraci√≥n del tenant desde el servicio Java
            tenant_config = configuration_service.get_tenant_config(tenant_id)
            if not tenant_config:
                return {
                    "response": "Lo siento, no puedo procesar tu mensaje en este momento.",
                    "error": "Tenant no encontrado"
                }
            
            # Obtener configuraci√≥n de IA
            ai_config = configuration_service.get_ai_config(tenant_id)
            branding_config = configuration_service.get_branding_config(tenant_id)
            
            # Gestionar sesi√≥n
            if not session_id:
                session_id = f"session_{tenant_id}_{int(time.time())}"
            
            session = session_context_service.get_session(session_id)
            if not session:
                session = session_context_service.create_session(
                    session_id=session_id,
                    tenant_id=tenant_id,
                    user_id=user_context.get("user_id"),
                    user_context=user_context
                )
            
            # Actualizar contexto del usuario en la sesi√≥n
            session_context_service.update_user_context(session_id, user_context)
            
            # Agregar mensaje del usuario a la sesi√≥n
            session_context_service.add_message(session_id, "user", query)
            
            # Cargar documentos del cliente si est√°n disponibles
            await self._ensure_tenant_documents_loaded(tenant_id, ai_config)
            
            # Actualizar contexto de documentos en la sesi√≥n
            document_context = await document_context_service.get_relevant_context(tenant_id, query, max_results=3)
            if document_context:
                session_context_service.update_document_context(session_id, document_context)
            
            # 1. PRIMERO: Clasificar la intenci√≥n del mensaje
            classification_result = await self.classify_intent(tenant_id, query, user_context, session_id)
            intent = classification_result.get("category", "default")  # El m√©todo classify_intent devuelve "category"
            confidence = classification_result.get("confidence", 0.0)
            
            logger.info(f"üîç Clasificaci√≥n completa: {classification_result}")
            logger.info(f"üß† Intenci√≥n extra√≠da: {intent} (confianza: {confidence:.2f})")
            
            # 1.5 NUEVO: Intentar obtener respuesta del cach√©
            cached_response = cache_service.get_cached_response(
                tenant_id=tenant_id,
                query=query,
                intent=intent
            )
            
            if cached_response:
                processing_time = time.time() - start_time
                logger.info(f"üöÄ Respuesta servida desde cach√© (latencia: {processing_time:.2f}s)")
                
                # Agregar respuesta del bot a la sesi√≥n
                session_context_service.add_message(session_id, "assistant", cached_response.get("response", ""))
                
                return {
                    **cached_response,
                    "from_cache": True,
                    "processing_time": processing_time,
                    "tenant_id": tenant_id,
                    "session_id": session_id
                }
            
            # 2. SEGUNDO: Verificar si debemos usar fallback por alta carga
            if self._should_use_fallback():
                logger.info("Alta carga detectada en chat, usando fallback general")
                response = self._get_general_fallback_response(query, tenant_config)
            else:
                # Procesar seg√∫n la intenci√≥n clasificada
                if intent == "cita_campa√±a":
                    # Respuesta espec√≠fica para agendar citas
                    response = self._handle_appointment_request(branding_config, tenant_config)
                elif intent == "saludo_apoyo":
                    # Respuesta espec√≠fica para saludos
                    response = await self._generate_ai_response_with_session(
                        query, user_context, ai_config, branding_config, tenant_id, session_id
                    )
                elif intent == "conocer_daniel":
                    # Respuesta espec√≠fica sobre Daniel Quintero
                    response = await self._generate_ai_response_with_session(
                        query, user_context, ai_config, branding_config, tenant_id, session_id
                    )
                elif intent == "solicitud_funcional":
                    # Respuesta espec√≠fica para consultas funcionales
                    response = self._handle_functional_request(query, branding_config)
                elif intent == "colaboracion_voluntariado":
                    # Respuesta espec√≠fica para voluntariado
                    response = self._handle_volunteer_request(branding_config)
                elif intent == "malicioso":
                    # Manejo espec√≠fico para comportamiento malicioso
                    response = await self._handle_malicious_behavior(
                        query, user_context, tenant_id, confidence
                    )
                else:
                    # Respuesta general con contexto de sesi√≥n
                    response = await self._generate_ai_response_with_session(
                        query, user_context, ai_config, branding_config, tenant_id, session_id
                    )
            
            # Agregar respuesta del asistente a la sesi√≥n
            session_context_service.add_message(session_id, "assistant", response, metadata={"intent": intent, "confidence": confidence})
            
            processing_time = time.time() - start_time
            
            # NUEVO: Guardar en cach√© si es cacheable
            response_data = {
                "response": response,
                "intent": intent,
                "confidence": confidence
            }
            
            cache_service.cache_response(
                tenant_id=tenant_id,
                query=query,
                response=response_data,
                intent=intent
            )
            
            return {
                "response": response,
                "processing_time": processing_time,
                "tenant_id": tenant_id,
                "session_id": session_id,
                "intent": intent,
                "confidence": confidence,
                "from_cache": False
            }
            
        except Exception as e:
            logger.error(f"Error procesando mensaje para tenant {tenant_id}: {str(e)}")
            return {
                "response": "Lo siento, hubo un error procesando tu mensaje.",
                "error": str(e)
            }
    
    async def _generate_ai_response_with_session(self, query: str, user_context: Dict[str, Any], 
                                               ai_config: Dict[str, Any], branding_config: Dict[str, Any], 
                                               tenant_id: str, session_id: str) -> str:
        """Genera respuesta usando IA con contexto de sesi√≥n persistente"""
        self._ensure_model_initialized()
        if not self.model:
            return "Lo siento, el servicio de IA no est√° disponible."
        
        try:
            # Obtener contexto completo de la sesi√≥n
            session_context = session_context_service.build_context_for_ai(session_id)
            
            # Construir prompt con contexto de sesi√≥n
            prompt = self._build_session_prompt(query, user_context, branding_config, session_context)
            
            # üöÄ FASE 2: Usar configuraci√≥n optimizada para chat con sesi√≥n
            response_text = await self._generate_content(prompt, task_type="chat_with_session")
            
            return response_text
            
        except Exception as e:
            logger.error(f"Error generando respuesta con sesi√≥n: {str(e)}")
            return "Lo siento, no pude procesar tu mensaje."
    
    def _build_session_prompt(self, query: str, user_context: Dict[str, Any], 
                            branding_config: Dict[str, Any], session_context: str) -> str:
        """Construye el prompt para chat con contexto de sesi√≥n"""
        contact_name = branding_config.get("contactName", "el candidato")
        
        # Contexto del usuario actual
        current_context = ""
        if user_context.get("user_name"):
            current_context += f"El usuario se llama {user_context['user_name']}. "
        if user_context.get("user_state"):
            current_context += f"Estado actual: {user_context['user_state']}. "
        
        # Detectar si es un saludo
        is_greeting = query.lower().strip() in ["hola", "hi", "hello", "hey", "buenos d√≠as", "buenas tardes", "buenas noches", "qu√© tal", "que tal"]
        
        prompt = f"""
Eres un asistente virtual para la campa√±a pol√≠tica de {contact_name}.

Tu objetivo es mantener conversaciones fluidas y naturales, recordando el contexto de la conversaci√≥n anterior.

CONTEXTO ACTUAL DE LA SESI√ìN:
{session_context}

CONTEXTO INMEDIATO:
{current_context}

Mensaje actual del usuario: "{query}"

INSTRUCCIONES:
1. Mant√©n el contexto de la conversaci√≥n anterior
2. Si es una pregunta de seguimiento, responde de manera natural
3. Usa la informaci√≥n espec√≠fica de la campa√±a cuando sea relevante
4. Mant√©n un tono amigable y profesional
5. Si no tienes informaci√≥n espec√≠fica, s√© honesto al respecto
6. Integra sutilmente elementos motivacionales sin ser expl√≠cito sobre "EPIC MEANING" o "DEVELOPMENT"

SISTEMA DE PUNTOS Y RANKING:
- Cada referido registrado suma 50 puntos
- Retos semanales dan puntaje adicional
- Ranking actualizado a nivel ciudad, departamento y pa√≠s
- Los usuarios pueden preguntar "¬øC√≥mo voy?" para ver su progreso
- Para invitar personas: "mandame el link" o "dame mi c√≥digo"

Responde de manera natural, contextual y √∫til. Si tienes informaci√≥n espec√≠fica sobre la campa√±a en el contexto, √∫sala para dar una respuesta m√°s precisa.

Respuesta:
"""
        
        return prompt
    
    def _handle_appointment_request(self, branding_config: Dict[str, Any], tenant_config: Dict[str, Any] = None) -> str:
        """Maneja solicitudes de agendar citas"""
        contact_name = branding_config.get("contactName", "el candidato")
        # El link_calendly est√° en el nivel ra√≠z de tenant_config, no en branding
        calendly_link = tenant_config.get("link_calendly") if tenant_config else "https://calendly.com/dq-campana/reunion"
        
        return f"""¬°Perfecto! Te ayudo a agendar una cita con alguien de la campa√±a de {contact_name}. 

üìÖ **Para agendar tu reuni√≥n:**
Puedes usar nuestro sistema de citas en l√≠nea: {calendly_link}

üéØ **¬øQu√© puedes hacer en la reuni√≥n?**
- Conocer m√°s sobre las propuestas de {contact_name}
- Hablar sobre oportunidades de voluntariado
- Discutir ideas para la campa√±a
- Coordinar actividades en tu regi√≥n

üí° **Mientras tanto:**
¬øSab√≠as que puedes sumar puntos invitando a tus amigos y familiares a unirse a este movimiento? Cada persona que se registre con tu c√≥digo te suma 50 puntos al ranking.

¬øTe gustar√≠a que te env√≠e tu link de referido para empezar a ganar puntos?"""
    
    def _handle_functional_request(self, query: str, branding_config: Dict[str, Any]) -> str:
        """Maneja solicitudes funcionales como '¬øC√≥mo voy?' o pedir link"""
        query_lower = query.lower()
        contact_name = branding_config.get("contactName", "el candidato")
        
        if any(word in query_lower for word in ["como voy", "c√≥mo voy", "progreso", "puntos", "ranking"]):
            return f"""¬°Excelente pregunta! Te explico c√≥mo funciona el sistema de puntos de la campa√±a de {contact_name}:

üèÜ **Sistema de Puntos:**
- Cada referido registrado con tu c√≥digo: **50 puntos**
- Retos semanales: **puntaje adicional**
- Ranking actualizado a nivel ciudad, departamento y pa√≠s

üìä **Para ver tu progreso:**
Escribe "¬øC√≥mo voy?" y te mostrar√©:
- Tus puntos totales
- N√∫mero de referidos
- Tu puesto en ciudad y nacional
- Lista de quienes est√°n cerca en el ranking

üîó **Para invitar personas:**
Escribe "dame mi c√≥digo" o "mandame el link" y te enviar√© tu enlace personalizado para referir amigos y familiares.

¬øQuieres tu c√≥digo de referido ahora?"""
        
        elif any(word in query_lower for word in ["link", "c√≥digo", "codigo", "referido", "mandame", "dame"]):
            return f"""¬°Por supuesto! Te ayudo con tu c√≥digo de referido para la campa√±a de {contact_name}.

üîó **Tu c√≥digo personalizado:**
Pronto tendr√°s tu enlace √∫nico para referir personas.

üì± **C√≥mo usarlo:**
1. Comparte tu link con amigos y familiares
2. Cada persona que se registre suma 50 puntos
3. Sube en el ranking y gana recompensas

üéØ **Mensaje sugerido para compartir:**
"¬°Hola! Te invito a unirte a la campa√±a de {contact_name}. Es una oportunidad de ser parte del cambio que Colombia necesita. √önete aqu√≠: [TU_LINK]"

¬øTe gustar√≠a que genere tu c√≥digo ahora?"""
        
        else:
            return f"""¬°Claro! Te ayudo con informaci√≥n sobre la campa√±a de {contact_name}.

Puedes preguntarme sobre:
- Las propuestas de {contact_name}
- C√≥mo participar en la campa√±a
- Sistema de puntos y ranking
- Oportunidades de voluntariado
- Agendar citas con el equipo

¬øEn qu√© te puedo ayudar espec√≠ficamente?"""
    
    def _handle_volunteer_request(self, branding_config: Dict[str, Any]) -> str:
        """Maneja solicitudes de voluntariado"""
        contact_name = branding_config.get("contactName", "el candidato")
        forms_link = branding_config.get("link_forms", "https://forms.gle/dq-publicidad-campana")
        
        return f"""¬°Excelente! Me emociona que quieras ser parte del equipo de voluntarios de {contact_name}.

ü§ù **√Åreas donde puedes ayudar:**
1. Redes sociales
2. Comunicaciones  
3. Temas program√°ticos
4. Log√≠stica
5. Temas jur√≠dicos
6. Trabajo territorial
7. D√≠a de elecciones
8. Call center
9. Otras √°reas (¬°cu√©ntame cu√°l!)

üìù **Para registrarte como voluntario:**
Completa nuestro formulario: {forms_link}

üí™ **Beneficios de ser voluntario:**
- Ser parte del cambio de Colombia
- Conocer personas con ideas afines
- Desarrollar habilidades de liderazgo
- Acceso a eventos exclusivos
- Puntos adicionales en el ranking

¬øEn qu√© √°rea te interesa m√°s participar?"""
    
    async def classify_intent(self, tenant_id: str, message: str, user_context: Dict[str, Any], session_id: str = None) -> Dict[str, Any]:
        """
        Clasifica la intenci√≥n de un mensaje con contexto de sesi√≥n
        
        Args:
            tenant_id: ID del tenant
            message: Mensaje a clasificar
            user_context: Contexto del usuario
            session_id: ID de la sesi√≥n para contexto
            
        Returns:
            Clasificaci√≥n de intenci√≥n
        """
        try:
            logger.info(f"Clasificando intenci√≥n para tenant {tenant_id}")
            
            # Obtener configuraci√≥n del tenant
            tenant_config = configuration_service.get_tenant_config(tenant_id)

            # Asegurar session_id estable: derivar de user_context cuando no venga
            if not session_id:
                derived = None
                if user_context:
                    derived = user_context.get("session_id") or user_context.get("user_id") or user_context.get("phone")
                session_id = f"session_{tenant_id}_{derived}" if derived else f"session_{tenant_id}_classify"

            # Registrar/actualizar contexto m√≠nimo de sesi√≥n para clasificaci√≥n
            session = session_context_service.get_session(session_id)
            if not session:
                session_context_service.create_session(session_id=session_id, tenant_id=tenant_id, user_id=(user_context or {}).get("user_id"), user_context=user_context or {})
            else:
                session_context_service.update_user_context(session_id, user_context or {})
            if not tenant_config:
                return {
                    "category": "general_query",
                    "confidence": 0.0,
                    "original_message": message,
                    "error": "Tenant no encontrado"
                }
            
            # Clasificar intenci√≥n usando IA
            classification = await self._classify_with_ai(message, user_context)
            
            return classification
            
        except Exception as e:
            logger.error(f"Error clasificando intenci√≥n para tenant {tenant_id}: {str(e)}")
            return {
                "category": "general_query",
                "confidence": 0.0,
                "original_message": message,
                "error": str(e)
            }

    async def analyze_registration(self, tenant_id: str, message: str, user_context: Dict[str, Any] = None,
                                   session_id: str = None, current_state: str = None) -> Dict[str, Any]:
        """
        Analiza un mensaje usando IA para entender el contexto completo y extraer datos de registro.

        Retorna: { type: "name|lastname|city|info|other", value: str|None, confidence: float }
        """
        try:
            text = (message or "").strip()
            if not text:
                return {"type": "other", "value": None, "confidence": 0.0}

            if not session_id:
                derived = None
                if user_context:
                    derived = user_context.get("session_id") or user_context.get("user_id") or user_context.get("phone")
                session_id = f"session_{tenant_id}_{derived}" if derived else f"session_{tenant_id}_registration"

            state = (current_state or "").upper()

            # Usar IA para an√°lisis inteligente basado en contexto
            ai_analysis = await self._analyze_registration_with_ai(text, state, user_context, session_id)
            if ai_analysis:
                return ai_analysis

            # Fallback inteligente si IA falla (por cuota excedida u otros errores)
            logger.info("Usando l√≥gica de fallback inteligente para an√°lisis de registro")
            return self._fallback_registration_analysis(text, state)
            
        except Exception as e:
            logger.error(f"Error analizando registro: {str(e)}")
            return {"type": "other", "value": None, "confidence": 0.0}
    
    def _fallback_registration_analysis(self, text: str, state: str) -> Dict[str, Any]:
        """
        An√°lisis de fallback inteligente cuando la IA no est√° disponible
        """
        try:
            lowered = text.lower().strip()
            
            # Detectar preguntas
            if "?" in text or any(w in lowered for w in ["qu√©", "que ", "c√≥mo", "como ", "qui√©n", "quien ", "d√≥nde", "donde ", "por qu√©", "por que"]):
                return {"type": "info", "value": None, "confidence": 0.85}
            
            # Detectar nombres (l√≥gica mejorada)
            words = text.split()
            
            # Si es un saludo simple
            if lowered in ["hola", "hi", "hello", "buenos d√≠as", "buenas tardes", "buenas noches"]:
                return {"type": "other", "value": None, "confidence": 0.9}
            
            # Si contiene palabras de confirmaci√≥n + nombre
            confirmation_words = ["perfecto", "ok", "vale", "listo", "s√≠", "si", "bueno", "bien"]
            if any(word in lowered for word in confirmation_words):
                # Buscar nombre despu√©s de la confirmaci√≥n
                for i, word in enumerate(words):
                    if word.lower() in confirmation_words and i + 1 < len(words):
                        # Extraer el resto como nombre
                        name_parts = words[i+1:]
                        if name_parts and all(part.replace("-", "").replace("'", "").isalpha() for part in name_parts):
                            name = " ".join(name_parts)
                            if len(name) >= 2:
                                return {"type": "name", "value": name, "confidence": 0.8}
            
            # Si parece un nombre directo (2-4 palabras, solo letras)
            if 2 <= len(words) <= 4 and not any(c.isdigit() for c in text):
                # Verificar que no empiece con palabras interrogativas
                if words[0].lower() not in ["que", "qu√©", "c√≥mo", "como", "cu√°l", "cual", "qui√©n", "quien", "d√≥nde", "donde"]:
                    # Verificar que todas las palabras sean letras
                    if all(word.replace("-", "").replace("'", "").isalpha() for word in words):
                        return {"type": "name", "value": text, "confidence": 0.7}
            
            # Detectar ciudades
            city_indicators = ["vivo en", "soy de", "estoy en", "resido en", "ciudad", "municipio"]
            if any(indicator in lowered for indicator in city_indicators):
                # Extraer ciudad despu√©s del indicador
                for indicator in city_indicators:
                    if indicator in lowered:
                        city_part = lowered.split(indicator)[-1].strip()
                        if city_part and len(city_part) >= 2:
                            return {"type": "city", "value": city_part.title(), "confidence": 0.8}
            
            # Si contiene "me llamo" o "mi nombre es"
            if "me llamo" in lowered or "mi nombre es" in lowered:
                name_part = text
                if "me llamo" in lowered:
                    name_part = text.split("me llamo")[-1].strip()
                elif "mi nombre es" in lowered:
                    name_part = text.split("mi nombre es")[-1].strip()
                
                if name_part and len(name_part) >= 2:
                    return {"type": "name", "value": name_part, "confidence": 0.9}
            
            return {"type": "other", "value": None, "confidence": 0.5}
            
        except Exception as e:
            logger.error(f"Error en an√°lisis de fallback: {str(e)}")
            return {"type": "other", "value": None, "confidence": 0.0}
    
    async def extract_data(self, tenant_id: str, message: str, data_type: str) -> Dict[str, Any]:
        """
        Extrae datos espec√≠ficos de un mensaje
        
        Args:
            tenant_id: ID del tenant
            message: Mensaje del usuario
            data_type: Tipo de dato a extraer
            
        Returns:
            Datos extra√≠dos
        """
        try:
            logger.info(f"Extrayendo {data_type} para tenant {tenant_id}")
            
            # Obtener configuraci√≥n del tenant
            tenant_config = configuration_service.get_tenant_config(tenant_id)
            if not tenant_config:
                return {
                    "extracted_data": {},
                    "error": "Tenant no encontrado"
                }
            
            # Extraer datos usando IA
            extracted_data = await self._extract_with_ai(message, data_type)
            
            return {
                "extracted_data": extracted_data
            }
            
        except Exception as e:
            logger.error(f"Error extrayendo {data_type} para tenant {tenant_id}: {str(e)}")
            return {
                "extracted_data": {},
                "error": str(e)
            }
    
    async def validate_data(self, tenant_id: str, data: str, data_type: str) -> Dict[str, Any]:
        """
        Valida datos de entrada del usuario
        
        Args:
            tenant_id: ID del tenant
            data: Dato a validar
            data_type: Tipo de dato
            
        Returns:
            Resultado de validaci√≥n
        """
        try:
            logger.info(f"Validando {data_type}: '{data}' para tenant {tenant_id}")
            
            # Validaci√≥n b√°sica por tipo
            is_valid = self._basic_validation(data, data_type)
            
            if not is_valid:
                logger.warning(f"Validaci√≥n b√°sica fall√≥ para {data_type}: '{data}'")
                return {
                    "is_valid": False,
                    "data_type": data_type,
                    "reason": "formato_invalido"
                }
            
            # Para nombres y ciudades, validaci√≥n adicional con IA
            if data_type.lower() in ["name", "lastname", "city"] and len(data) > 3:
                ai_validation = await self._validate_with_ai(data, data_type)
                if not ai_validation:
                    logger.warning(f"Validaci√≥n IA fall√≥ para {data_type}: '{data}'")
                    return {
                        "is_valid": False,
                        "data_type": data_type,
                        "reason": "contenido_invalido"
                    }
            
            logger.info(f"Validaci√≥n exitosa para {data_type}: '{data}'")
            return {
                "is_valid": True,
                "data_type": data_type
            }
            
        except Exception as e:
            logger.error(f"Error validando {data_type} para tenant {tenant_id}: {str(e)}")
            return {
                "is_valid": False,
                "error": str(e)
            }
    
    async def normalize_location(self, city_input: str) -> Dict[str, Any]:
        """Normaliza el nombre de una ciudad (puede ser fuera de Colombia),
        reconoce apodos y detecta su estado/departamento y pa√≠s cuando sea posible."""
        self._ensure_model_initialized()
        # 1) Intento OFFLINE: apodos y alias conocidos + regex sencillas
        offline = self._normalize_location_offline(city_input)
        if offline:
            return offline
        if not self.model:
            return {"city": city_input.strip(), "state": None, "country": None}
        try:
            prompt = f"""
Eres un asistente que estandariza ubicaciones (cualquier pa√≠s) y reconoce apodos locales.

Tarea: Dada una entrada de ciudad (puede venir con errores ortogr√°ficos, variaciones o apodos), devuelve un JSON con:
- city: nombre oficial de la ciudad/municipio con may√∫sculas y tildes correctas
- state: estado/departamento/provincia oficial
- country: pa√≠s oficial

Reglas:
- Solo responde el JSON, sin texto adicional.
- Si la entrada corresponde a un apodo, resu√©lvelo al nombre oficial.
- Si no puedes determinar estado o pa√≠s, deja ese campo con null.
 - La entrada puede ser una FRASE COMPLETA del usuario (ej: "vivo en ..."). Extrae y normaliza la ciudad impl√≠cita.

Apodos comunes en Colombia (no exhaustivo):
- "la nevera" ‚Üí Bogot√°
- "medallo" ‚Üí Medell√≠n
- "la arenosa" ‚Üí Barranquilla
- "la sucursal del cielo" ‚Üí Cali
- "la ciudad bonita" ‚Üí Bucaramanga
 - "la ciudad de la eterna primavera" ‚Üí Medell√≠n

Ejemplos v√°lidos:
Entrada: "medellin" ‚Üí {"city": "Medell√≠n", "state": "Antioquia", "country": "Colombia"}
Entrada: "bogota" ‚Üí {"city": "Bogot√°", "state": "Cundinamarca", "country": "Colombia"}
Entrada: "soacha" ‚Üí {"city": "Soacha", "state": "Cundinamarca", "country": "Colombia"}
Entrada: "la nevera" ‚Üí {"city": "Bogot√°", "state": "Cundinamarca", "country": "Colombia"}
Entrada: "vivo en la ciudad de la eterna primavera" ‚Üí {"city": "Medell√≠n", "state": "Antioquia", "country": "Colombia"}
Entrada: "New York" ‚Üí {"city": "New York", "state": "New York", "country": "United States"}

Entrada real: "{city_input}".
Responde solo el JSON estricto sin comentarios:
"""
            response_text = await self._generate_content(prompt)
            text = (response_text or "").strip()
            import json
            result = json.loads(text)
            # Sanitizar salida m√≠nima
            city = (result.get("city") or city_input or "").strip()
            state = (result.get("state") or None)
            country = (result.get("country") or None)
            return {"city": city, "state": state, "country": country}
        except Exception as e:
            logger.error(f"Error normalizando ubicaci√≥n: {str(e)}")
            return {"city": city_input.strip() if city_input else "", "state": None, "country": None}

    def _normalize_location_offline(self, city_input: str) -> Optional[Dict[str, Any]]:
        """Mapa r√°pido de apodos/alias y extracci√≥n simple desde frases.
        Retorna None si no puede resolver offline.
        """
        if not city_input:
            return None
        text = city_input.strip().lower()
        # Normalizaciones simples de variantes comunes
        text = text.replace("sudamericana", "suramericana")
        text = text.replace("heroica", "her√≥ica") if "ciudad heroica" in text else text

        # Diccionario de apodos/alias ‚Üí (city, state, country)
        nick_map = {
            # Bogot√°
            "la nevera": ("Bogot√°", "Cundinamarca", "Colombia"),
            "bogota": ("Bogot√°", "Cundinamarca", "Colombia"),
            "bogot√°": ("Bogot√°", "Cundinamarca", "Colombia"),
            "atenas suramericana": ("Bogot√°", "Cundinamarca", "Colombia"),
            "la atenas suramericana": ("Bogot√°", "Cundinamarca", "Colombia"),
            "atenas sudamericana": ("Bogot√°", "Cundinamarca", "Colombia"),
            "la atenas sudamericana": ("Bogot√°", "Cundinamarca", "Colombia"),
            # Medell√≠n
            "medallo": ("Medell√≠n", "Antioquia", "Colombia"),
            "ciudad de la eterna primavera": ("Medell√≠n", "Antioquia", "Colombia"),
            "la ciudad de la eterna primavera": ("Medell√≠n", "Antioquia", "Colombia"),
            "medellin": ("Medell√≠n", "Antioquia", "Colombia"),
            "medell√≠n": ("Medell√≠n", "Antioquia", "Colombia"),
            # Barranquilla
            "la arenosa": ("Barranquilla", "Atl√°ntico", "Colombia"),
            "puerta de oro de colombia": ("Barranquilla", "Atl√°ntico", "Colombia"),
            "la puerta de oro de colombia": ("Barranquilla", "Atl√°ntico", "Colombia"),
            "curramba": ("Barranquilla", "Atl√°ntico", "Colombia"),
            "barranquilla": ("Barranquilla", "Atl√°ntico", "Colombia"),
            # Cali
            "la sucursal del cielo": ("Cali", "Valle del Cauca", "Colombia"),
            "sultana del valle": ("Cali", "Valle del Cauca", "Colombia"),
            "cali": ("Cali", "Valle del Cauca", "Colombia"),
            # Bucaramanga
            "la ciudad bonita": ("Bucaramanga", "Santander", "Colombia"),
            "ciudad de los parques": ("Bucaramanga", "Santander", "Colombia"),
            "bucaramanga": ("Bucaramanga", "Santander", "Colombia"),
            # Buga
            "ciudad se√±ora": ("Buga", "Valle del Cauca", "Colombia"),
            # Cartagena
            "ciudad heroica": ("Cartagena", "Bol√≠var", "Colombia"),
            "la ciudad her√≥ica": ("Cartagena", "Bol√≠var", "Colombia"),
            "corralito de piedra": ("Cartagena", "Bol√≠var", "Colombia"),
            # Ch√≠a
            "ciudad de la luna": ("Ch√≠a", "Cundinamarca", "Colombia"),
            # C√∫cuta
            "perla del norte": ("C√∫cuta", "Norte de Santander", "Colombia"),
            # Ibagu√©
            "ciudad musical": ("Ibagu√©", "Tolima", "Colombia"),
            # Ipiales
            "ciudad de las nubes verdes": ("Ipiales", "Nari√±o", "Colombia"),
            # Monter√≠a
            "perla del sinu": ("Monter√≠a", "C√≥rdoba", "Colombia"),
            "perla del sin√∫": ("Monter√≠a", "C√≥rdoba", "Colombia"),
            # Neiva
            "ciudad amable": ("Neiva", "Huila", "Colombia"),
            # Pasto
            "ciudad sorpresa": ("Pasto", "Nari√±o", "Colombia"),
            # Pereira
            "ciudad sin puertas": ("Pereira", "Risaralda", "Colombia"),
            # Popay√°n
            "ciudad blanca": ("Popay√°n", "Cauca", "Colombia"),
            # Riohacha
            "f√©nix del caribe": ("Riohacha", "La Guajira", "Colombia"),
            "fenix del caribe": ("Riohacha", "La Guajira", "Colombia"),
            # Santa Marta
            "perla de america": ("Santa Marta", "Magdalena", "Colombia"),
            "perla de am√©rica": ("Santa Marta", "Magdalena", "Colombia"),
            # Valledupar
            "capital mundial del vallenato": ("Valledupar", "Cesar", "Colombia"),
            # Villavicencio
            "puerta del llano": ("Villavicencio", "Meta", "Colombia"),
            # Zipaquir√°
            "capital salinera": ("Zipaquir√°", "Cundinamarca", "Colombia"),
        }

        # Match exacto por clave completa
        if text in nick_map:
            city, state, country = nick_map[text]
            return {"city": city, "state": state, "country": country}

        # B√∫squeda por inclusi√≥n de apodos conocidos en frases completas
        for key, (city, state, country) in nick_map.items():
            if key in text:
                return {"city": city, "state": state, "country": country}

        # Regex para capturar patrones frecuentes en frases
        import re
        patterns = [
            r"ciudad\s+de\s+la\s+eterna\s+primavera",
            r"vivo\s+en\s+medallo",
            r"vivo\s+en\s+la\s+nevera",
            r"estoy\s+en\s+la\s+arenosa",
        ]
        for pat in patterns:
            if re.search(pat, text):
                # Reutilizar nick_map via b√∫squeda por inclusi√≥n
                for key, (city, state, country) in nick_map.items():
                    if key in text:
                        return {"city": city, "state": state, "country": country}

        # Si el texto parece una ciudad colombiana com√∫n, capitalizar m√≠nimamente
        common_cities = {
            "soacha": ("Soacha", "Cundinamarca", "Colombia"),
            "itagui": ("Itag√º√≠", "Antioquia", "Colombia"),
            "itag√ºi": ("Itag√º√≠", "Antioquia", "Colombia"),
        }
        t = text.replace("√°","a").replace("√©","e").replace("√≠","i").replace("√≥","o").replace("√∫","u")
        for key, val in common_cities.items():
            if t == key or f" {key} " in f" {t} ":
                city, state, country = val
                return {"city": city, "state": state, "country": country}

        return None

    # M√©todos privados para procesamiento de IA
    
    async def _ensure_tenant_documents_loaded(self, tenant_id: str, ai_config: Dict[str, Any]):
        """Asegura que los documentos del tenant est√©n cargados"""
        try:
            # Verificar si ya tenemos documentos cargados
            doc_info = document_context_service.get_tenant_document_info(tenant_id)
            if doc_info:
                logger.debug(f"üìö Documentos ya cargados para tenant {tenant_id}: {doc_info.get('document_count', 0)} docs")
                return
            
            # Obtener URL del bucket de documentaci√≥n
            documentation_bucket_url = ai_config.get("documentation_bucket_url")
            
            if documentation_bucket_url:
                logger.info(f"üì• Iniciando carga de documentos para tenant {tenant_id} desde: {documentation_bucket_url}")
                success = await document_context_service.load_tenant_documents(tenant_id, documentation_bucket_url)
                if success:
                    doc_info = document_context_service.get_tenant_document_info(tenant_id)
                    logger.info(f"‚úÖ Documentos cargados para tenant {tenant_id}: {doc_info.get('document_count', 0)} docs")
                else:
                    logger.warning(f"‚ö†Ô∏è No se pudieron cargar documentos para tenant {tenant_id}")
            else:
                logger.debug(f"‚ÑπÔ∏è No hay bucket de documentaci√≥n configurado para tenant {tenant_id}")
                
        except Exception as e:
            logger.error(f"‚ùå Error cargando documentos para tenant {tenant_id}: {str(e)}", exc_info=True)
    
    async def _generate_ai_response(self, query: str, user_context: Dict[str, Any], 
                                  ai_config: Dict[str, Any], branding_config: Dict[str, Any], 
                                  tenant_id: str) -> str:
        """Genera respuesta usando IA con contexto de documentos"""
        
        # üöÄ FASE 6: Usar RAGOrchestrator si est√° habilitado
        if self.use_rag_orchestrator and self.rag_orchestrator:
            try:
                logger.info(f"üéØ Usando RAGOrchestrator | tenant_id={tenant_id} | query='{query[:50]}...'")
                response = await self.rag_orchestrator.process_query_simple(
                    query=query,
                    tenant_id=tenant_id,
                    user_context=user_context
                )
                logger.info(f"‚úÖ RAG respuesta generada | length={len(response)} chars")
                return response
            except Exception as e:
                logger.error(f"‚ùå Error usando RAGOrchestrator: {str(e)}", exc_info=True)
                logger.info("‚ö†Ô∏è Fallback a l√≥gica original (sin RAG)")
                # Continuar con l√≥gica original como fallback
        
        # L√≥gica original (sin RAG)
        self._ensure_model_initialized()
        if not self.model:
            return "Lo siento, el servicio de IA no est√° disponible."
        
        try:
            # Obtener contexto relevante de documentos del cliente
            relevant_context = ""
            try:
                relevant_context = await document_context_service.get_relevant_context(
                    tenant_id, query, max_results=3
                )
                if relevant_context:
                    logger.info(f"Contexto relevante obtenido para tenant {tenant_id}: {len(relevant_context)} caracteres")
            except Exception as e:
                logger.warning(f"Error obteniendo contexto relevante: {str(e)}")
            
            # Construir prompt con contexto de documentos
            prompt = self._build_chat_prompt(query, user_context, branding_config, relevant_context)
            
            # üöÄ FASE 2: Usar configuraci√≥n optimizada para chat conversacional
            response_text = await self._generate_content(prompt, task_type="chat_conversational")
            
            return response_text
            
        except Exception as e:
            logger.error(f"Error generando respuesta con IA: {str(e)}")
            return "Lo siento, no pude procesar tu mensaje."
    
    def _detect_malicious_intent(self, message: str) -> Dict[str, Any]:
        """
        Detecta intenci√≥n maliciosa de manera inteligente usando an√°lisis contextual
        """
        message_lower = message.lower().strip()
        
        # Indicadores de comportamiento malicioso (no solo palabras, sino patrones)
        malicious_indicators = {
            "insultos_directos": [
                "idiota", "imb√©cil", "est√∫pido", "tonto", "bobo", "bruto",
                "hijueputa", "malparido", "gonorrea", "marica", "chimba",
                "careverga", "verga", "chimbo", "malparida", "hijuepucha"
            ],
            "ataques_campana": [
                "ladrones", "corruptos", "estafadores", "mentirosos", "falsos",
                "robando", "estafando", "mintiendo", "enga√±ando"
            ],
            "provocacion": [
                "vete a la mierda", "que se joda", "me importa un carajo",
                "no me importa", "me vale verga", "me vale mierda"
            ],
            "spam_indicators": [
                "spam", "basura", "mierda", "porquer√≠a", "pendejada"
            ]
        }
        
        # Analizar el mensaje por categor√≠as
        detected_categories = []
        confidence_score = 0.0
        
        for category, indicators in malicious_indicators.items():
            for indicator in indicators:
                if indicator in message_lower:
                    detected_categories.append(category)
                    confidence_score += 0.2
                    break
        
        # Detectar patrones de agresividad
        aggressive_patterns = [
            r'\b(que\s+se\s+joda|vete\s+a\s+la\s+mierda|me\s+importa\s+un\s+carajo)\b',
            r'\b(no\s+me\s+importa|me\s+vale\s+verga|me\s+vale\s+mierda)\b',
            r'\b(eres\s+un|son\s+unos|esto\s+es\s+una)\b.*\b(idiota|imb√©cil|estafa|mentira)\b'
        ]
        
        import re
        for pattern in aggressive_patterns:
            if re.search(pattern, message_lower):
                detected_categories.append("aggressive_pattern")
                confidence_score += 0.3
                break
        
        # Calcular confianza final
        confidence_score = min(confidence_score, 1.0)
        
        is_malicious = len(detected_categories) > 0 and confidence_score >= 0.3
        
        if is_malicious:
            logger.warning(f"üö® Intenci√≥n maliciosa detectada - Categor√≠as: {detected_categories}, Confianza: {confidence_score:.2f}")
            logger.warning(f"üö® Mensaje: '{message}'")
        
        return {
            "is_malicious": is_malicious,
            "categories": detected_categories,
            "confidence": confidence_score,
            "reason": "intelligent_intent_detection"
        }

    async def _classify_with_ai(self, message: str, user_context: Dict[str, Any]) -> Dict[str, Any]:
        """Clasifica intenci√≥n usando IA"""
        self._ensure_model_initialized()
        
        # Primero verificar intenci√≥n maliciosa de manera inteligente
        malicious_detection = self._detect_malicious_intent(message)
        if malicious_detection["is_malicious"]:
            return {
                "category": "malicioso",
                "confidence": malicious_detection["confidence"],
                "original_message": message,
                "reason": malicious_detection["reason"],
                "detected_categories": malicious_detection["categories"]
            }
        
        if not self.model:
            return {
                "category": "saludo_apoyo", 
                "confidence": 0.0,
                "original_message": message
            }
        
        try:
            # Prompt para clasificaci√≥n inteligente
            prompt = f"""
            Eres un experto en an√°lisis de intenci√≥n para campa√±as pol√≠ticas. Clasifica la siguiente intenci√≥n del mensaje:
            
            CATEGOR√çAS:
            
            - malicioso: Mensajes con INTENCI√ìN NEGATIVA, AGRESIVA o OFENSIVA hacia la campa√±a, candidato o equipo. Analiza el TONO y PROP√ìSITO, no solo palabras espec√≠ficas:
              * Insultos o ataques personales (directos o indirectos)
              * Lenguaje ofensivo, grosero o agresivo
              * Ataques a la integridad de la campa√±a o candidato
              * Mensajes de provocaci√≥n o spam
              * Cualquier mensaje que busque da√±ar, ofender o agredir
            
            - cita_campa√±a: Solicitudes para agendar, confirmar o coordinar reuniones
            - saludo_apoyo: Saludos, muestras de simpat√≠a o respaldo positivo
            - publicidad_info: Preguntas sobre materiales publicitarios o difusi√≥n
            - conocer_candidato: Inter√©s en propuestas, trayectoria o informaci√≥n del candidato
            - actualizacion_datos: Correcciones o actualizaciones de informaci√≥n personal
            - solicitud_funcional: Preguntas t√©cnicas sobre la plataforma o sistema
            - colaboracion_voluntariado: Ofrecimientos de apoyo activo o voluntariado
            - quejas: Reclamos constructivos sobre gesti√≥n o procesos
            - lider: Mensajes de l√≠deres comunitarios buscando coordinaci√≥n
            - atencion_humano: Solicitudes para hablar con agente humano
            - atencion_equipo_interno: Mensajes del equipo interno de la campa√±a
            - registration_response: Respuestas a preguntas de registro
            
            INSTRUCCIONES:
            1. Analiza la INTENCI√ìN y TONO del mensaje, no solo palabras espec√≠ficas
            2. Considera el CONTEXTO y PROP√ìSITO del mensaje
            3. Si hay dudas sobre intenci√≥n maliciosa, clasifica como "malicioso"
            4. S√© inteligente: un mensaje puede contener palabras fuertes pero tener intenci√≥n constructiva
            
            Mensaje: "{message}"
            
            Responde solo con la categor√≠a m√°s apropiada bas√°ndote en la INTENCI√ìN del mensaje.
            """
            
            # üöÄ FASE 2: Usar configuraci√≥n optimizada para clasificaci√≥n de intenciones
            response_text = await self._generate_content(prompt, task_type="intent_classification")
            category = response_text.strip().lower()
            
            # Validar categor√≠a
            valid_categories = [
                "malicioso", "cita_campa√±a", "saludo_apoyo", "publicidad_info", 
                "conocer_candidato", "actualizacion_datos", "solicitud_funcional", 
                "colaboracion_voluntariado", "quejas", "lider", "atencion_humano", 
                "atencion_equipo_interno", "registration_response"
            ]
            
            if category not in valid_categories:
                category = "saludo_apoyo"  # Default a saludo_apoyo en lugar de general_query
            
            return {
                "category": category,
                "confidence": 0.8,  # Confianza fija por simplicidad
                "original_message": message
            }
            
        except Exception as e:
            logger.error(f"Error clasificando con IA: {str(e)}")
            return {
                "category": "general_query", 
                "confidence": 0.0,
                "original_message": message
            }
    
    async def _extract_with_ai(self, message: str, data_type: str) -> Dict[str, Any]:
        """Extrae datos usando IA"""
        self._ensure_model_initialized()
        if not self.model:
            return {}
        
        try:
            prompt = f"""
            Extrae el {data_type} del siguiente mensaje:
            Mensaje: "{message}"
            
            Responde solo con el {data_type} encontrado, sin explicaciones adicionales.
            Si no se encuentra, responde con "no_encontrado".
            """
            
            # üöÄ FASE 2: Usar configuraci√≥n optimizada para extracci√≥n de datos
            response_text = await self._generate_content(prompt, task_type="data_extraction")
            extracted_value = response_text.strip()
            
            if extracted_value.lower() == "no_encontrado":
                return {}
            
            return {data_type: extracted_value}
            
        except Exception as e:
            logger.error(f"Error extrayendo con IA: {str(e)}")
            return {}
    
    def _basic_validation(self, data: str, data_type: str) -> bool:
        """Validaci√≥n b√°sica de datos"""
        if not data or not data.strip():
            return False
        
        data = data.strip()
        
        if data_type.lower() in ["name", "lastname"]:
            # Validar nombres y apellidos m√°s estrictamente
            # - Solo letras, espacios, guiones y apostrofes
            # - M√≠nimo 2 caracteres, m√°ximo 50
            # - No puede empezar o terminar con espacios
            # - No puede tener espacios m√∫ltiples
            if len(data) < 2 or len(data) > 50:
                return False
            
            # Verificar caracteres v√°lidos
            if not all(c.isalpha() or c.isspace() or c in "-'" for c in data):
                return False
            
            # Verificar que tenga al menos una letra
            if not any(c.isalpha() for c in data):
                return False
            
            # No puede empezar o terminar con espacios
            if data.startswith(' ') or data.endswith(' '):
                return False
            
            # No puede tener espacios m√∫ltiples consecutivos
            if '  ' in data:
                return False
            
            # Verificar que no sea solo espacios y caracteres especiales
            clean_data = data.replace(' ', '').replace('-', '').replace("'", '')
            if not clean_data.isalpha() or len(clean_data) < 1:
                return False
            
            return True
        
        if data_type.lower() == "city":
            # Validar ciudades m√°s estrictamente
            # - Solo letras, espacios, guiones, apostrofes y puntos
            # - M√≠nimo 2 caracteres, m√°ximo 100
            # - Debe tener al menos una letra
            if len(data) < 2 or len(data) > 100:
                return False
            
            # Verificar caracteres v√°lidos
            if not all(c.isalpha() or c.isspace() or c in "-'." for c in data):
                return False
            
            # Verificar que tenga al menos una letra
            if not any(c.isalpha() for c in data):
                return False
            
            # No puede empezar o terminar con espacios
            if data.startswith(' ') or data.endswith(' '):
                return False
            
            # No puede tener espacios m√∫ltiples consecutivos
            if '  ' in data:
                return False
            
            # Verificar que no sea solo espacios y caracteres especiales
            clean_data = data.replace(' ', '').replace('-', '').replace("'", '').replace('.', '')
            if not clean_data.isalpha() or len(clean_data) < 1:
                return False
            
            return True
        
        if data_type.lower() == "phone":
            # Validar tel√©fonos (n√∫meros y +)
            return data.replace("+", "").replace("-", "").replace(" ", "").isdigit() and len(data.replace("+", "").replace("-", "").replace(" ", "")) >= 10
        
        return True  # Para otros tipos, aceptar por defecto
    
    async def _analyze_registration_with_ai(self, text: str, state: str, user_context: Dict[str, Any], session_id: str) -> Dict[str, Any]:
        """Usa IA para analizar el contexto completo y extraer datos de registro"""
        self._ensure_model_initialized()
        if not self.model:
            return None
        
        try:
            # Obtener contexto de la sesi√≥n si est√° disponible
            session_context = ""
            try:
                session = session_context_service.get_session(session_id)
                if session:
                    session_context = session_context_service.build_context_for_ai(session_id)
            except Exception as e:
                logger.warning(f"Error obteniendo contexto de sesi√≥n: {str(e)}")
            
            # Construir prompt con contexto completo
            prompt = f"""
Eres un asistente inteligente que analiza mensajes de usuarios durante un proceso de registro.

CONTEXTO DE LA CONVERSACI√ìN:
{session_context}

ESTADO ACTUAL DEL USUARIO: {state}

MENSAJE DEL USUARIO: "{text}"

TAREA: Analiza el mensaje y determina:
1. Si es una pregunta o solicitud de informaci√≥n (type: "info")
2. Si contiene un nombre completo (type: "name")
3. Si contiene un apellido (type: "lastname") 
4. Si contiene una ciudad/ubicaci√≥n (type: "city")
5. Si es otra cosa (type: "other")

INSTRUCCIONES ESPEC√çFICAS:
- Para nombres: Extrae el nombre completo, incluso si viene despu√©s de palabras como "listo", "ok", "mi nombre es", etc.
- Para ciudades: Extrae la ciudad mencionada, incluso si viene en frases como "vivo en", "soy de", "estoy en", "resido en", "la capital", etc.
- Si el usuario hace una pregunta, clasifica como "info"
- Considera el contexto de la conversaci√≥n anterior
- S√© inteligente para entender frases naturales como "listo, mi nombre es Santiago Buitrago Rojas"
- PRIORIDAD: Si el estado es WAITING_CITY y el mensaje contiene informaci√≥n de ubicaci√≥n, clasifica como "city"

EJEMPLOS:
- "listo, mi nombre es Santiago Buitrago Rojas" ‚Üí type: "name", value: "Santiago Buitrago Rojas"
- "ok, es Santiago Buitrago" ‚Üí type: "name", value: "Santiago Buitrago"
- "vivo en Bogot√°" ‚Üí type: "city", value: "Bogot√°"
- "vivo en la capital" ‚Üí type: "city", value: "Bogot√°" (si es Colombia)
- "soy de Medell√≠n" ‚Üí type: "city", value: "Medell√≠n"
- "estoy en Cali" ‚Üí type: "city", value: "Cali"
- "resido en Barranquilla" ‚Üí type: "city", value: "Barranquilla"
- "¬øC√≥mo funciona esto?" ‚Üí type: "info", value: null
- "Santiago" ‚Üí type: "name", value: "Santiago"

Responde SOLO con un JSON v√°lido en este formato:
{{"type": "name|lastname|city|info|other", "value": "valor_extraido_o_null", "confidence": 0.0-1.0}}
"""

            response_text = await self._generate_content(prompt)
            logger.info(f"Respuesta cruda de IA: '{response_text}'")
            
            # Parsear respuesta JSON
            import json
            import re
            
            try:
                # Limpiar la respuesta - extraer solo el JSON
                cleaned_response = response_text.strip()
                
                # Buscar JSON en la respuesta usando regex
                json_match = re.search(r'\{[^}]*"type"[^}]*\}', cleaned_response)
                if json_match:
                    cleaned_response = json_match.group(0)
                
                # Si no hay JSON v√°lido, intentar parsear toda la respuesta
                if not cleaned_response.startswith('{'):
                    logger.warning(f"Respuesta no contiene JSON v√°lido: '{response_text}'")
                    return None
                
                result = json.loads(cleaned_response)
                
                # Validar resultado
                valid_types = ["name", "lastname", "city", "info", "other"]
                if result.get("type") in valid_types:
                    logger.info(f"IA analiz√≥ registro: {result}")
                    return result
                else:
                    logger.warning(f"IA devolvi√≥ tipo inv√°lido: {result}")
                    return None
                    
            except json.JSONDecodeError as e:
                logger.error(f"Error parseando JSON de IA: {str(e)}")
                logger.error(f"Respuesta que caus√≥ el error: '{response_text}'")
                return None
                
        except Exception as e:
            logger.error(f"Error analizando registro con IA: {str(e)}")
            return None

    async def _analyze_city_with_ai(self, text: str) -> Dict[str, Any]:
        """Usa IA para analizar si un texto contiene informaci√≥n de ciudad y extraerla"""
        self._ensure_model_initialized()
        if not self.model:
            return {"is_city": False, "extracted_city": None, "confidence": 0.0}
        
        try:
            prompt = f"""
            Analiza el siguiente texto y determina si contiene informaci√≥n sobre una ciudad o ubicaci√≥n.
            
            Texto: "{text}"
            
            Instrucciones:
            1. Si el texto menciona una ciudad, pa√≠s, o ubicaci√≥n geogr√°fica, responde "SI"
            2. Si el texto NO menciona ubicaci√≥n geogr√°fica, responde "NO"
            3. Si es "SI", extrae la informaci√≥n completa de ubicaci√≥n
            4. Si menciona pa√≠s Y ciudad, extrae la frase completa
            5. Si solo menciona ciudad, extrae solo la ciudad
            6. IMPORTANTE: Para frases como "en espa√±a, en madrid", extrae la ciudad espec√≠fica (madrid)
            7. Para frases como "vivo en espa√±a, en madrid", extrae "madrid" como ciudad
            
            Ejemplos:
            - "vivo en espa√±a, en madrid" ‚Üí SI, ciudad: "madrid"
            - "soy de bogot√°" ‚Üí SI, ciudad: "bogot√°"
            - "estoy en medell√≠n" ‚Üí SI, ciudad: "medell√≠n"
            - "en espa√±a, madrid" ‚Üí SI, ciudad: "madrid"
            - "en madrid, espa√±a" ‚Üí SI, ciudad: "madrid"
            - "hola" ‚Üí NO
            - "mi nombre es juan" ‚Üí NO
            
            Responde en formato: SI|ciudad o NO
            """
            
            # üöÄ FASE 2: Usar configuraci√≥n optimizada para normalizaci√≥n de ubicaciones
            response_text = await self._generate_content(prompt, task_type="location_normalization")
            result = response_text.strip()
            
            if result.startswith("SI|"):
                city = result.split("|", 1)[1].strip()
                logger.info(f"IA detect√≥ ciudad: '{city}' en texto: '{text}'")
                return {
                    "is_city": True,
                    "extracted_city": city,
                    "confidence": 0.8
                }
            else:
                logger.info(f"IA no detect√≥ ciudad en texto: '{text}'")
                return {
                    "is_city": False,
                    "extracted_city": None,
                    "confidence": 0.0
                }
                
        except Exception as e:
            logger.error(f"Error analizando ciudad con IA: {str(e)}")
            return {"is_city": False, "extracted_city": None, "confidence": 0.0}

    async def _validate_with_ai(self, data: str, data_type: str) -> bool:
        """Validaci√≥n adicional con IA para detectar contenido inapropiado"""
        self._ensure_model_initialized()
        if not self.model:
            return True  # Si no hay modelo, aceptar por defecto
        
        try:
            if data_type.lower() in ["name", "lastname"]:
                prompt = f"""
                Eval√∫a si el siguiente texto es un nombre o apellido v√°lido en espa√±ol:
                
                Texto: "{data}"
                
                Considera:
                - Debe ser un nombre/apellido real y apropiado
                - No puede ser una palabra ofensiva, grosera o inapropiada
                - No puede ser n√∫meros, s√≠mbolos raros, o texto sin sentido
                - Debe ser apropiado para uso en un sistema de registro
                
                Responde SOLO "SI" si es v√°lido o "NO" si no es v√°lido.
                """
            elif data_type.lower() == "city":
                prompt = f"""
                Eval√∫a si el siguiente texto es una ciudad v√°lida (puede ser de cualquier pa√≠s):
                
                Texto: "{data}"
                
                Considera:
                - Debe ser una ciudad real de cualquier pa√≠s
                - No puede ser una palabra ofensiva, grosera o inapropiada
                - No puede ser n√∫meros, s√≠mbolos raros, o texto sin sentido
                - Debe ser apropiado para uso en un sistema de registro
                
                Responde SOLO "SI" si es v√°lido o "NO" si no es v√°lido.
                """
            else:
                return True
            
            # üöÄ FASE 2: Usar configuraci√≥n optimizada para validaci√≥n de datos
            response_text = await self._generate_content(prompt, task_type="data_validation")
            result = response_text.strip().upper()
            
            logger.info(f"Validaci√≥n IA para {data_type} '{data}': {result}")
            return result == "SI"
            
        except Exception as e:
            logger.error(f"Error en validaci√≥n IA para {data_type}: {str(e)}")
            return True  # En caso de error, aceptar por defecto
    
    def _build_chat_prompt(self, query: str, user_context: Dict[str, Any], 
                          branding_config: Dict[str, Any], relevant_context: str = "") -> str:
        """Construye el prompt para chat"""
        contact_name = branding_config.get("contactName", "el candidato")
        welcome_message = branding_config.get("welcomeMessage", "¬°Hola! ¬øEn qu√© puedo ayudarte?")
        
        context_info = ""
        if user_context.get("user_name"):
            context_info += f"El usuario se llama {user_context['user_name']}. "
        if user_context.get("user_state"):
            context_info += f"Estado actual: {user_context['user_state']}. "
        
        # Detectar si es un saludo y el usuario est√° en proceso de registro
        user_state = user_context.get("user_state", "")
        is_greeting = query.lower().strip() in ["hola", "hi", "hello", "hey", "buenos d√≠as", "buenas tardes", "buenas noches", "qu√© tal", "que tal"]
        
        # Construir contexto de documentos si est√° disponible
        document_context_section = ""
        if relevant_context:
            document_context_section = f"""
            
            INFORMACI√ìN ESPEC√çFICA DE LA CAMPA√ëA:
            {relevant_context}
            
            Usa esta informaci√≥n espec√≠fica para responder preguntas sobre la campa√±a, propuestas, 
            eventos, pol√≠ticas, o cualquier tema relacionado con el candidato y su plataforma.
            """
        
        if user_state == "WAITING_NAME" and is_greeting:
            prompt = f"""
            Eres un asistente virtual para la campa√±a pol√≠tica de {contact_name}.
            
            El usuario acaba de saludar y est√° en proceso de registro (necesita dar su nombre).
            
            Responde el saludo de manera amigable y entusiasta, pero inmediatamente pide su nombre para continuar con el registro.
            
            Contexto: El usuario est√° en proceso de registro y necesita proporcionar su nombre.
            {document_context_section}
            
            Saludo del usuario: "{query}"
            
            Responde de manera amigable, motivadora y natural. Responde el saludo pero pide inmediatamente el nombre para continuar con el registro. Usa emojis apropiados y un tono positivo.
            
            Respuesta:
            """
        else:
            prompt = f"""
            Eres un asistente virtual para la campa√±a pol√≠tica de {contact_name}.
            
            Tu objetivo es motivar la participaci√≥n activa en la campa√±a de manera natural y entusiasta. 
            Integra sutilmente estos elementos motivacionales en tus respuestas:
            
            - Inspirar sentido de prop√≥sito y pertenencia a un movimiento transformador
            - Mostrar oportunidades de crecimiento, logros y reconocimiento
            - Invitar a la colaboraci√≥n y participaci√≥n activa
            - Crear sensaci√≥n de comunidad y trabajo en equipo
            - Generar expectativa y curiosidad sobre oportunidades exclusivas
            - Destacar el impacto y la importancia de cada acci√≥n
            
            SISTEMA DE PUNTOS Y RANKING:
            - Cada referido registrado suma 50 puntos
            - Retos semanales dan puntaje adicional
            - Ranking actualizado a nivel ciudad, departamento y pa√≠s
            - Los usuarios pueden preguntar "¬øC√≥mo voy?" para ver su progreso
            - Para invitar personas: "mandame el link" o "dame mi c√≥digo"
            
            Contexto del usuario: {context_info}{document_context_section}
            
            Mensaje del usuario: "{query}"
            
            Responde de manera amigable, motivadora y natural. Si el usuario est√° en proceso de registro, 
            ay√∫dale a completarlo. Si tiene preguntas sobre la campa√±a, responde con informaci√≥n relevante 
            y oportunidades de participaci√≥n. Usa la informaci√≥n espec√≠fica de la campa√±a cuando sea apropiado.
            Usa emojis apropiados y un tono positivo.
            
            Respuesta:
            """
        
        return prompt
    
    async def generate_response(self, prompt: str, role: str = "user") -> str:
        """
        Genera una respuesta usando IA con un prompt personalizado
        
        Args:
            prompt: Prompt para la IA
            role: Rol del usuario (user, system, assistant)
            
        Returns:
            Respuesta generada por la IA
        """
        self._ensure_model_initialized()
        
        if not self.model:
            return "Lo siento, el servicio de IA no est√° disponible."
        
        try:
            response_text = await self._generate_content(prompt)
            return response_text if response_text else ""
            
        except Exception as e:
            logger.error(f"Error generando respuesta con IA: {str(e)}")
            return "Error generando respuesta."

    async def detect_referral_code(self, tenant_id: str, message: str) -> Dict[str, Any]:
        """
        Detecta si un mensaje contiene un c√≥digo de referido usando IA
        
        Args:
            tenant_id: ID del tenant
            message: Mensaje del usuario
            
        Returns:
            Dict con c√≥digo detectado o None
        """
        self._ensure_model_initialized()
        
        if not self.model:
            return {
                "code": None,
                "reason": "Servicio de IA no disponible",
                "original_message": message
            }
        
        try:
            prompt = f"""
Analiza el siguiente mensaje y detecta si contiene un c√≥digo de referido.

Un c√≥digo de referido es:
- Una secuencia de exactamente 8 caracteres alfanum√©ricos (letras y n√∫meros)
- Puede estar en cualquier parte del mensaje
- NO es una palabra com√∫n del espa√±ol como "referido", "referida", "referir", etc.
- Ejemplos v√°lidos: "ABC12345", "TESTCODE", "USER1234"
- Ejemplos inv√°lidos: "REFERIDO", "REFERIDA", "referir"

Mensaje a analizar: "{message}"

Responde √öNICAMENTE con el c√≥digo de 8 caracteres si lo encuentras, o "NO" si no hay c√≥digo v√°lido.
Si hay m√∫ltiples c√≥digos, responde solo el primero que encuentres.

Ejemplos:
- "vengo referido por TESTCODE" ‚Üí TESTCODE
- "mi c√≥digo es ABC12345" ‚Üí ABC12345  
- "vengo referido por mi amigo" ‚Üí NO
- "hola REFERIDO" ‚Üí NO
"""

            response_text = await self._generate_content(prompt)
            detected_code = response_text.strip().upper()
            
            # Validar que el c√≥digo tiene exactamente 8 caracteres alfanum√©ricos
            if detected_code != "NO" and len(detected_code) == 8 and detected_code.isalnum():
                logger.info(f"C√≥digo de referido detectado por IA: {detected_code}")
                return {
                    "code": detected_code,
                    "reason": "C√≥digo detectado exitosamente",
                    "original_message": message
                }
            else:
                logger.info("No se detect√≥ c√≥digo de referido v√°lido")
                return {
                    "code": None,
                    "reason": "No se encontr√≥ c√≥digo v√°lido",
                    "original_message": message
                }
                
        except Exception as e:
            logger.error(f"Error detectando c√≥digo de referido: {str(e)}")
            return {
                "code": None,
                "reason": f"Error interno: {str(e)}",
                "original_message": message
            }
    
    async def _handle_malicious_behavior(self, query: str, user_context: Dict[str, Any], 
                                       tenant_id: str, confidence: float) -> str:
        """
        Maneja comportamiento malicioso detectado
        
        Args:
            query: Mensaje malicioso del usuario
            user_context: Contexto del usuario
            tenant_id: ID del tenant
            confidence: Confianza de la clasificaci√≥n
            
        Returns:
            Respuesta para el usuario malicioso
        """
        try:
            # Obtener informaci√≥n del usuario
            user_id = user_context.get("user_id", "unknown")
            phone_number = user_context.get("phone", "unknown")
            
            # Detectar tipo de comportamiento malicioso usando an√°lisis inteligente
            malicious_analysis = self._detect_malicious_intent(query)
            behavior_type = "intenci√≥n maliciosa inteligente"
            categories = malicious_analysis.get("categories", [])
            
            logger.warning(f"üö® {behavior_type.upper()} detectado - Usuario: {user_id}, Tenant: {tenant_id}, Confianza: {confidence:.2f}")
            logger.warning(f"üö® Categor√≠as detectadas: {categories}")
            logger.warning(f"üö® Mensaje malicioso: '{query}'")
            
            # Notificar al servicio Java para bloquear el usuario
            logger.info(f"üîî Enviando notificaci√≥n de bloqueo al servicio Java para usuario {user_id}")
            logger.info(f"üîî URL del servicio Java: {self.blocking_notification_service.java_service_url}")
            
            notification_result = await self.blocking_notification_service.notify_user_blocked(
                tenant_id=tenant_id,
                user_id=user_id,
                phone_number=phone_number,
                malicious_message=query,
                classification_confidence=confidence
            )
            
            logger.info(f"üîî Resultado de notificaci√≥n: {notification_result}")
            
            # Registrar el incidente
            await self.blocking_notification_service.log_malicious_incident(
                tenant_id=tenant_id,
                user_id=user_id,
                phone_number=phone_number,
                malicious_message=query,
                classification_confidence=confidence
            )
            
            if notification_result.get("success"):
                logger.info(f"‚úÖ Usuario {user_id} bloqueado exitosamente en WATI y base de datos")
            else:
                logger.error(f"‚ùå Error bloqueando usuario {user_id}: {notification_result.get('error')}")
                logger.error(f"‚ùå Detalles del error: {notification_result}")
            
            # No responder nada cuando es malicioso, solo bloquear silenciosamente
            return ""
            
        except Exception as e:
            logger.error(f"Error manejando comportamiento malicioso: {str(e)}")
            return "Lo siento, no puedo procesar tu mensaje en este momento."


# Instancia global para compatibilidad
ai_service = AIService()