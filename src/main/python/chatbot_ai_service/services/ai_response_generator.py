"""
Servicios de generaciÃ³n de respuestas usando IA
"""
import logging
import json
import re

logger = logging.getLogger(__name__)

def generate_contextual_response(prompt: str, tenant_context: dict) -> str:
    """
    Genera una respuesta contextualizada usando IA.
    
    Args:
        prompt: El prompt del usuario
        tenant_context: Contexto del tenant (documentaciÃ³n, branding, etc.)
        
    Returns:
        Respuesta generada por la IA
    """
    try:
        logger.info(f"DEBUG - Generando respuesta contextual para prompt: '{prompt}'")
        
        # Crear un prompt enriquecido con el contexto del tenant
        enriched_prompt = create_enriched_prompt(prompt, tenant_context)
        
        # Simular respuesta de IA (en un sistema real usarÃ­as GPT o similar)
        response = process_response_generation_with_ai(enriched_prompt, tenant_context)
        
        logger.info(f"DEBUG - Respuesta generada: '{response}'")
        return response
        
    except Exception as e:
        logger.error(f"Error generando respuesta contextual: {str(e)}")
        return "Lo siento, no pude procesar tu solicitud en este momento."

def create_enriched_prompt(prompt: str, tenant_context: dict) -> str:
    """
    Crea un prompt enriquecido con el contexto del tenant.
    """
    try:
        # Obtener informaciÃ³n del tenant
        tenant_name = tenant_context.get("tenant_name", "el candidato")
        candidate_name = tenant_context.get("candidate_name", "el candidato")
        campaign_info = tenant_context.get("campaign_info", "")
        documentation = tenant_context.get("documentation", "")
        
        # Crear el prompt enriquecido
        enriched_prompt = f"""
Eres un asistente virtual especializado en campaÃ±as polÃ­ticas para {tenant_name}.
Tu objetivo es ayudar a los ciudadanos con informaciÃ³n sobre la campaÃ±a de {candidate_name}.

CONTEXTO DE LA CAMPAÃ‘A:
{campaign_info}

DOCUMENTACIÃ“N DISPONIBLE:
{documentation}

PROMPT DEL USUARIO:
{prompt}

INSTRUCCIONES:
- Responde de manera profesional, amigable y contextualizada
- Usa la informaciÃ³n de la campaÃ±a para personalizar tu respuesta
- Si no tienes informaciÃ³n especÃ­fica, sÃ© honesto pero mantÃ©n el tono positivo
- Incluye detalles relevantes sobre {candidate_name} y sus propuestas
- MantÃ©n un tono que inspire confianza y apoyo

RESPUESTA:
"""
        
        return enriched_prompt
        
    except Exception as e:
        logger.error(f"Error creando prompt enriquecido: {str(e)}")
        return prompt

def process_response_generation_with_ai(enriched_prompt: str, tenant_context: dict) -> str:
    """
    Procesa la generaciÃ³n de respuestas usando IA.
    En un sistema real, aquÃ­ conectarÃ­as con GPT, Claude, o similar.
    """
    try:
        logger.info(f"DEBUG - Procesando generaciÃ³n de respuesta con contexto del tenant")
        
        # Extraer el prompt original del usuario
        user_prompt = ""
        if "PROMPT DEL USUARIO:" in enriched_prompt:
            start = enriched_prompt.find("PROMPT DEL USUARIO:") + len("PROMPT DEL USUARIO:")
            end = enriched_prompt.find("\n\nINSTRUCCIONES:", start)
            if end > start:
                user_prompt = enriched_prompt[start:end].strip()
        
        if not user_prompt:
            user_prompt = enriched_prompt
        
        logger.info(f"DEBUG - Prompt del usuario extraÃ­do: '{user_prompt}'")
        
        # Obtener informaciÃ³n del tenant
        tenant_name = tenant_context.get("tenant_name", "el candidato")
        candidate_name = tenant_context.get("candidate_name", "el candidato")
        campaign_info = tenant_context.get("campaign_info", "")
        
        # LÃ³gica simple de generaciÃ³n de respuestas basada en patrones
        user_prompt_lower = user_prompt.lower()
        
        # Respuestas para saludos
        if any(word in user_prompt_lower for word in ["hola", "hi", "hello", "buenos", "buenas"]):
            return f"Â¡Hola! ğŸ‘‹ Â¡Muchas gracias por tu apoyo a la campaÃ±a de {candidate_name}! " \
                   f"Tu respaldo es fundamental para lograr el cambio que necesitamos. " \
                   f"Â¿En quÃ© puedo ayudarte hoy?"
        
        # Respuestas para informaciÃ³n sobre el candidato
        if any(word in user_prompt_lower for word in ["candidato", "conocer", "trayectoria", "propuestas", "quiÃ©n es", "quien es"]):
            return f"Â¡Genial! ğŸ¤– AquÃ­ tienes informaciÃ³n sobre {candidate_name}:\n\n" \
                   f"{campaign_info}\n\n" \
                   f"Â¿Te gustarÃ­a conocer mÃ¡s sobre sus propuestas especÃ­ficas?"
        
        # Respuestas para citas
        if any(word in user_prompt_lower for word in ["cita", "agendar", "reuniÃ³n", "calendly"]):
            calendly_link = tenant_context.get("calendly_link", "Link no disponible")
            return f"Â¡Perfecto! ğŸ“… AquÃ­ tienes el link para agendar tu cita:\n\n{calendly_link}"
        
        # Respuestas para material publicitario
        if any(word in user_prompt_lower for word in ["publicidad", "material", "volantes", "pancartas"]):
            forms_link = tenant_context.get("forms_link", "Link no disponible")
            return f"Â¡Perfecto! ğŸ“‹ AquÃ­ tienes el formulario para solicitar material publicitario:\n\n{forms_link}"
        
        # Respuestas para voluntariado
        if any(word in user_prompt_lower for word in ["voluntario", "ayudar", "colaborar", "participar"]):
            return f"Â¡Excelente! ğŸ™Œ Nos encanta que quieras ser parte del equipo de {candidate_name}. " \
                   f"Â¿En quÃ© Ã¡rea te gustarÃ­a colaborar? " \
                   f"Tenemos oportunidades en redes sociales, comunicaciones, logÃ­stica y territorial."
        
        # Respuestas para quejas
        if any(word in user_prompt_lower for word in ["queja", "reclamo", "problema", "mal servicio"]):
            return f"Lamento mucho que hayas tenido una experiencia negativa. ğŸ˜” " \
                   f"Tu feedback es muy importante para nosotros. " \
                   f"Â¿PodrÃ­as contarme mÃ¡s detalles sobre el problema para poder ayudarte mejor?"
        
        # Respuestas para lÃ­deres
        if any(word in user_prompt_lower for word in ["lÃ­der", "liderazgo", "comunidad", "barrio", "vereda"]):
            return f"Â¡FantÃ¡stico! ğŸ† Como lÃ­der comunitario, tu apoyo es crucial para la campaÃ±a de {candidate_name}. " \
                   f"Â¿Te gustarÃ­a coordinar alguna actividad en tu comunidad o necesitas material especÃ­fico?"
        
        # Respuestas para atenciÃ³n humana
        if any(word in user_prompt_lower for word in ["humano", "persona", "agente", "operador"]):
            return f"Entiendo que prefieres hablar con una persona. ğŸ‘¥ " \
                   f"Te voy a conectar con uno de nuestros voluntarios del equipo de {candidate_name}. " \
                   f"Â¿PodrÃ­as esperar un momento?"
        
        # Respuestas para informaciÃ³n funcional
        if any(word in user_prompt_lower for word in ["cÃ³mo voy", "mis puntos", "mi tribu", "referidos"]):
            return f"Â¡Perfecto! ğŸ“Š Te ayudo con la informaciÃ³n de tu cuenta. " \
                   f"Â¿Te gustarÃ­a saber sobre tus puntos, tu tribu o tus referidos?"
        
        # Respuesta genÃ©rica
        return f"Â¡Gracias por tu consulta! ğŸ˜Š " \
               f"Estoy aquÃ­ para ayudarte con informaciÃ³n sobre la campaÃ±a de {candidate_name}. " \
               f"Â¿Hay algo especÃ­fico en lo que pueda asistirte?"
        
    except Exception as e:
        logger.error(f"Error en procesamiento de generaciÃ³n de respuesta: {str(e)}")
        return "Lo siento, no pude procesar tu solicitud en este momento."

def generate_intent_response(intent: str, tenant_context: dict) -> str:
    """
    Genera una respuesta especÃ­fica para una intenciÃ³n detectada.
    
    Args:
        intent: La intenciÃ³n detectada
        tenant_context: Contexto del tenant
        
    Returns:
        Respuesta generada para la intenciÃ³n
    """
    try:
        logger.info(f"DEBUG - Generando respuesta para intenciÃ³n: '{intent}'")
        
        # Obtener informaciÃ³n del tenant
        candidate_name = tenant_context.get("candidate_name", "el candidato")
        
        # Mapeo de intenciones a respuestas
        intent_responses = {
            "saludo_apoyo": f"Â¡Hola! ğŸ‘‹ Â¡Muchas gracias por tu apoyo a la campaÃ±a de {candidate_name}! " \
                           f"Tu respaldo es fundamental para lograr el cambio que necesitamos. " \
                           f"Â¿En quÃ© puedo ayudarte hoy?",
            
            "conocer_candidato": f"Â¡Genial! ğŸ¤– AquÃ­ tienes informaciÃ³n sobre {candidate_name}:\n\n" \
                                f"{tenant_context.get('campaign_info', 'InformaciÃ³n no disponible')}\n\n" \
                                f"Â¿Te gustarÃ­a conocer mÃ¡s sobre sus propuestas especÃ­ficas?",
            
            "cita_campaÃ±a": f"Â¡Perfecto! ğŸ“… AquÃ­ tienes el link para agendar tu cita:\n\n" \
                           f"{tenant_context.get('calendly_link', 'Link no disponible')}",
            
            "publicidad_info": f"Â¡Perfecto! ğŸ“‹ AquÃ­ tienes el formulario para solicitar material publicitario:\n\n" \
                              f"{tenant_context.get('forms_link', 'Link no disponible')}",
            
            "colaboracion_voluntariado": f"Â¡Excelente! ğŸ™Œ Nos encanta que quieras ser parte del equipo de {candidate_name}. " \
                                        f"Â¿En quÃ© Ã¡rea te gustarÃ­a colaborar? " \
                                        f"Tenemos oportunidades en redes sociales, comunicaciones, logÃ­stica y territorial.",
            
            "quejas": f"Lamento mucho que hayas tenido una experiencia negativa. ğŸ˜” " \
                     f"Tu feedback es muy importante para nosotros. " \
                     f"Â¿PodrÃ­as contarme mÃ¡s detalles sobre el problema para poder ayudarte mejor?",
            
            "lider": f"Â¡FantÃ¡stico! ğŸ† Como lÃ­der comunitario, tu apoyo es crucial para la campaÃ±a de {candidate_name}. " \
                    f"Â¿Te gustarÃ­a coordinar alguna actividad en tu comunidad o necesitas material especÃ­fico?",
            
            "atencion_humano": f"Entiendo que prefieres hablar con una persona. ğŸ‘¥ " \
                              f"Te voy a conectar con uno de nuestros voluntarios del equipo de {candidate_name}. " \
                              f"Â¿PodrÃ­as esperar un momento?",
            
            "solicitud_funcional": f"Â¡Perfecto! ğŸ“Š Te ayudo con la informaciÃ³n de tu cuenta. " \
                                  f"Â¿Te gustarÃ­a saber sobre tus puntos, tu tribu o tus referidos?",
            
            "actualizacion_datos": f"Â¡Por supuesto! ğŸ“ Te ayudo a actualizar tu informaciÃ³n. " \
                                  f"Â¿QuÃ© datos necesitas modificar?",
            
            "atencion_equipo_interno": f"Entiendo que necesitas informaciÃ³n interna. ğŸ”’ " \
                                      f"Voy a validar tus permisos y conectar contigo con el BackOffice.",
            
            "malicioso": f"Lo siento, pero no puedo ayudarte con ese tipo de solicitudes. " \
                        f"Si tienes alguna consulta legÃ­tima sobre la campaÃ±a de {candidate_name}, estarÃ© encantado de ayudarte.",
            
            "general_query": f"Â¡Gracias por tu consulta! ğŸ˜Š " \
                            f"Estoy aquÃ­ para ayudarte con informaciÃ³n sobre la campaÃ±a de {candidate_name}. " \
                            f"Â¿Hay algo especÃ­fico en lo que pueda asistirte?"
        }
        
        # Obtener la respuesta para la intenciÃ³n
        response = intent_responses.get(intent, intent_responses["general_query"])
        
        logger.info(f"DEBUG - Respuesta generada para intenciÃ³n '{intent}': '{response}'")
        return response
        
    except Exception as e:
        logger.error(f"Error generando respuesta para intenciÃ³n: {str(e)}")
        return "Lo siento, no pude procesar tu solicitud en este momento."

def generate_registration_prompt(user_state: str, tenant_context: dict) -> str:
    """
    Genera un prompt de registro contextualizado segÃºn el estado del usuario.
    
    Args:
        user_state: El estado actual del usuario en el registro
        tenant_context: Contexto del tenant
        
    Returns:
        Prompt de registro generado
    """
    try:
        logger.info(f"DEBUG - Generando prompt de registro para estado: '{user_state}'")
        
        # Obtener informaciÃ³n del tenant
        candidate_name = tenant_context.get("candidate_name", "el candidato")
        
        # Mapeo de estados a prompts
        state_prompts = {
            "WAITING_NAME": f"Â¡Hola! ğŸ‘‹ Bienvenido al chatbot de {candidate_name}.\n\n" \
                           f"Para comenzar, necesito algunos datos bÃ¡sicos:\n\n" \
                           f"Â¿CuÃ¡l es tu nombre?",
            
            "WAITING_LASTNAME": f"Perfecto! ğŸ˜Š\n\n" \
                               f"Ahora necesito tu apellido:",
            
            "WAITING_CITY": f"Excelente! ğŸ‘\n\n" \
                           f"Â¿En quÃ© ciudad vives?",
            
            "WAITING_REFERRAL_CODE": f"Â¡Genial! ğŸ“\n\n" \
                                    f"Â¿Tienes un cÃ³digo de referido?",
            
            "WAITING_REFERRAL_CODE_INPUT": f"Â¡Perfecto! ğŸ¯\n\n" \
                                          f"Por favor escribe tu cÃ³digo de referido:",
            
            "WAITING_TERMS_ACCEPTANCE": f"Â¡Perfecto! ğŸ¯\n\n" \
                                       f"Â¿Aceptas los tÃ©rminos y condiciones?"
        }
        
        # Obtener el prompt para el estado
        prompt = state_prompts.get(user_state, state_prompts["WAITING_NAME"])
        
        logger.info(f"DEBUG - Prompt de registro generado: '{prompt}'")
        return prompt
        
    except Exception as e:
        logger.error(f"Error generando prompt de registro: {str(e)}")
        return "Â¡Hola! Â¿En quÃ© puedo ayudarte?"
